# Dataset Analysis Configuration (Minimal Starter)
# Usage: oumi analyze --config configs/examples/analyze/analyze.yaml
#
# This is a minimal config with just the length analyzer.
# For more analyzers, see analyze_comprehensive.yaml and uncomment what you need.
#
# Available configs:
#   - analyze.yaml: This file (minimal starter)
#   - analyze_comprehensive.yaml: ALL 22 analyzers (uncomment what you need)
#   - analyze_fixing_it_in_post.yaml: Magpie "Fixing It in Post" data curation
#   - analyze_evol_instruct.yaml: DEITA/Evol-Instruct quality scoring
#   - analyze_dedup.yaml: Duplicate detection (semantic + fuzzy)
#   - analyze_deita.yaml: DEITA-style quality scoring (simpler)
#   - analyze_alpaca.yaml: Streamlined Alpaca quality analysis
#
# Programmatic presets: from oumi.core.analyze.presets import get_preset
#   - get_preset("sft_quality"): Length, diversity, format, quality
#   - get_preset("sft_comprehensive"): Above + training_quality + cost
#   - get_preset("sft_fast"): Fast heuristic-only analysis
#
# Output files:
#   - message_analysis.csv: Per-message metrics
#   - conversation_analysis.csv: Per-conversation aggregated metrics
#   - analysis_summary.json: Statistical summary

dataset_name: yahma/alpaca-cleaned
split: train
sample_count: 100

# Or use a local file:
# dataset_path: ./my_dataset.jsonl

output_path: ./analysis_output

analyzers:
  - id: length
    params:
      token_count: true  # Uses tiktoken o200k_base (GPT-4o/GPT-5 encoding)
