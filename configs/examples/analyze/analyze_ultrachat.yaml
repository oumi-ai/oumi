# Analysis configuration for UltraChat dataset
# UltraChat is a large-scale conversational dataset for training chat models
# This config focuses on detecting common issues in conversational datasets:
# - Duplicates (semantic and exact)
# - Quality issues (PII, encoding, repetition)
# - Safety concerns
# - Format inconsistencies
# - Diversity and redundancy
# - Response quality and helpfulness
#
# SPECIFIC ISSUES TARGETED:
# 1. Synthetic style homogenization - Similar phrasing across conversations
# 2. Excessive politeness - Overuse of hedging language
# 3. Roleplay bleeding - Assistant invents personas unprompted
# 4. Reasoning leakage - Long chain-of-thought when not requested
# 5. Repetitive turns - Same idea restated across turns

dataset_name: "HuggingFaceH4/ultrachat_200k" # Registered dataset name
split: "train_sft"
output_path: ./analysis_output/ultrachat

analyzers:
  # ---------------------------------------------------------------------------
  # BASIC METRICS - Length, diversity, format
  # ---------------------------------------------------------------------------
  # Length analyzer - counts chars, words, tokens
  - id: length
    params:
      token_count: true
      tiktoken_encoding: o200k_base # GPT-4o/GPT-5 encoding

  # Diversity analyzer - vocabulary richness
  - id: diversity
    params:
      unique_words_ratio: true
      case_sensitive: false

  # Format analyzer - structured content detection
  - id: format
    params:
      detect_markdown: true
      detect_json: true
      detect_code_blocks: true
      detect_urls: true
      detect_emails: true
      compute_complexity: true

  # ---------------------------------------------------------------------------
  # QUALITY CHECKS - PII, encoding, repetition
  # ---------------------------------------------------------------------------
  # Quality analyzer - detects privacy and quality issues
  - id: quality
    params:
      detect_pii: true
      detect_emails: true
      detect_phones: true
      detect_ssn: true
      detect_credit_cards: true
      detect_api_keys: true
      detect_encoding_issues: true
      detect_repetition: true
      repetition_ngram_size: 3
      repetition_threshold: 0.3

  # Content pattern analyzer - AI-specific quality issues
  - id: content_pattern
    params:
      detect_placeholders: true # [Name], [Company], etc.
      detect_hallucinated_experiences: true # Fabricated stories
      detect_nooutput: true # <nooutput>, N/A, etc.
      detect_refusals: true # "I cannot provide..."
      check_output_only: false # Check all messages

  # ---------------------------------------------------------------------------
  # DUPLICATE DETECTION - Semantic and fuzzy duplicates
  # ---------------------------------------------------------------------------
  # Embedding analyzer - semantic duplicate detection
  # Requires: pip install 'oumi[analyze_advanced]'
  - id: embedding
    params:
      model_name: all-MiniLM-L6-v2 # Fast, 384 dims
      detect_duplicates: true
      duplicate_threshold: 0.95 # Cosine similarity (0.9-0.99)
      detect_fuzzy_duplicates: true # MinHash LSH (fast)
      fuzzy_threshold: 0.8
      fuzzy_ngram_size: 3
      cluster_samples: false
      batch_size: 32
      store_embeddings: false

  # Question diversity analyzer - detect if user questions are too similar
  - id: question_diversity
    params:
      cluster_questions: true
      clustering_method: dbscan
      eps: 0.15 # ~99% cosine similarity
      min_samples: 2
      model_name: all-MiniLM-L6-v2
      batch_size: 32
      compute_entropy: true
      compute_concentration: true
      flag_concentrated_clusters: true
      concentration_threshold: 0.5

  # Representation diversity analyzer - DEITA-style embedding diversity
  - id: repr_diversity
    params:
      model_name: sentence-transformers/all-MiniLM-L6-v2
      k_neighbors: 5
      diversity_threshold: 0.3
      # Use role-specific thresholds to avoid system prompt inflation
      role_specific_thresholds:
        system: null # Exclude system prompts (typically identical)
        user: 0.25 # Strict diversity for user messages
        assistant: 0.30 # Standard diversity for responses
      embed_field: all # "all", "user", or "assistant"
      batch_size: 32

  # ---------------------------------------------------------------------------
  # CONVERSATION ANALYSIS - Structure and completeness
  # ---------------------------------------------------------------------------
  # Conversation structure analyzer - turn pattern analysis
  - id: conversation_structure
    params:
      single_turn_threshold: 2
      compute_length_stats: true

  # Response completeness analyzer - truncation detection
  - id: response_completeness
    params:
      analyze_assistant_only: true
      strict_mode: false
      include_truncation_type: true

  # Training quality analyzer - SFT effectiveness metrics
  - id: training_quality
    params:
      compute_response_completeness: true
      min_response_words: 5

  # ---------------------------------------------------------------------------
  # TASK AND SAFETY CLASSIFICATION
  # ---------------------------------------------------------------------------
  # Task category analyzer - instruction type classification
  - id: task_category
    params:
      min_confidence: 0.3
      default_category: other
      analyze_user_only: true

  # Safety analyzer - safety and risk classification
  - id: safety
    params:
      strict_mode: false
      include_categories: true

  # Difficulty analyzer - instruction complexity estimation
  - id: difficulty
    params:
      analyze_user_only: true
      include_component_scores: true

  # ---------------------------------------------------------------------------
  # QUALITY SCORING (Magpie framework)
  # ---------------------------------------------------------------------------
  # Input quality analyzer - instruction quality rating
  - id: input_quality
    params:
      analyze_user_only: true
      include_component_flags: true

  # Instruct reward analyzer - response quality scoring
  - id: instruct_reward
    params:
      min_response_words: 10
      max_response_words: 2000
      analyze_assistant_only: true
      include_component_scores: true

  # ---------------------------------------------------------------------------
  # COST ANALYSIS - Training cost estimation
  # ---------------------------------------------------------------------------
  # Cost analyzer - estimates API costs for different context windows
  - id: cost
    params:
      target_context_windows: [4096, 8192, 16384, 32768]
      compute_packing_efficiency: true
      packing_overhead_tokens: 10

  # ---------------------------------------------------------------------------
  # LLM JUDGES - High-quality evaluation (optional, requires API keys)
  # ---------------------------------------------------------------------------
  # LLM Judge: Helpfulness (conversation-level)
  # Evaluates overall conversation helpfulness
  - id: llm_judge
    instance_id: helpfulness
    params:
      prompt: |
        Evaluate how helpful this conversation is as training data for a chat model (0-10).

        Conversation to evaluate:
        {text}

        Evaluation criteria for helpfulness:
        - Is the assistant's response helpful and relevant to the user's query?
        - Does the conversation demonstrate good instruction-following?
        - Is the response accurate and well-structured?
        - Would this conversation help train a better chat model?

        Scoring guide:
        - 10: Excellent conversation, highly helpful, well-structured
        - 7-9: Good conversation, helpful and relevant
        - 4-6: Mediocre, somewhat helpful but has issues
        - 1-3: Poor conversation, not helpful or low quality
        - 0: Very poor or harmful conversation

        Respond with JSON:
        - "score": 0-10 (10 = maximally helpful)
        - "label": "very_helpful", "helpful", "somewhat_helpful", "not_helpful"
        - "reasoning": brief explanation of why this conversation is/isn't helpful

        JSON response:
      analyze_message_level: false
      analyze_conversation_level: true
      inference_config:
        model_name: gpt-4o-mini
        engine: openai
        temperature: 0.1
        max_tokens: 256
        remote_params:
          num_workers: 200
          politeness_policy: 1.0
          use_adaptive_concurrency: true
      batch_size: 1000
      max_text_length: 8000
      parse_json_response: true

  # LLM Judge: Instruction Quality (message-level)
  # Evaluates clarity and quality of user instructions
  - id: llm_judge
    instance_id: instruction_quality
    params:
      prompt_preset: instruction_quality
      filter_role: user
      analyze_message_level: true
      analyze_conversation_level: false
      inference_config:
        model_name: gpt-4o-mini
        engine: openai
        temperature: 0.1
        max_tokens: 256
        remote_params:
          num_workers: 200
          politeness_policy: 1.0
          use_adaptive_concurrency: true
      batch_size: 1000
      parse_json_response: true

  # LLM Judge: Response Quality (message-level)
  # Evaluates assistant response quality
  - id: llm_judge
    instance_id: response_quality
    params:
      prompt: |
        Evaluate this assistant's response quality (0-10).

        Assistant response to evaluate:
        {text}

        Evaluation criteria:
        - Is the response helpful and relevant?
        - Is it well-structured and coherent?
        - Does it demonstrate good language understanding?
        - Is it appropriate and safe?

        Scoring guide:
        - 10: Excellent response, highly helpful and well-structured
        - 7-9: Good response, helpful and relevant
        - 4-6: Mediocre response, has some issues
        - 1-3: Poor response, not helpful or low quality
        - 0: Very poor or harmful response

        Respond with JSON:
        - "score": 0-10 (10 = perfect response)
        - "label": "excellent", "good", "needs_improvement", "poor"
        - "reasoning": brief explanation

        JSON response:
      filter_role: assistant
      analyze_message_level: true
      analyze_conversation_level: false
      inference_config:
        model_name: gpt-4o-mini
        engine: openai
        temperature: 0.1
        max_tokens: 256
        remote_params:
          num_workers: 200
          politeness_policy: 1.0
          use_adaptive_concurrency: true
      batch_size: 1000
      max_text_length: 4000
      parse_json_response: true

  # ---------------------------------------------------------------------------
  # ISSUE-SPECIFIC LLM JUDGES - Target specific UltraChat problems
  # ---------------------------------------------------------------------------
  # LLM Judge: Excessive Politeness (message-level)
  # Detects overuse of hedging language and excessive politeness
  - id: llm_judge
    instance_id: excessive_politeness
    params:
      prompt: |
        Evaluate if this assistant response uses excessive politeness or hedging language (0-10).
        Score HIGHER (8-10) for excessive hedging, LOWER (0-3) for direct, natural responses.

        Assistant response to evaluate:
        {text}

        Look for:
        - Excessive hedging: "I think", "perhaps", "might", "could", "may", "possibly"
        - Over-politeness: "I apologize", "I hope this helps", "Please let me know"
        - Uncertainty markers: "I'm not entirely sure", "I believe", "It seems"
        - Repetitive politeness phrases across the response

        Scoring guide:
        - 8-10: Excessive hedging/politeness, sounds overly cautious or synthetic
        - 5-7: Moderate hedging, acceptable but noticeable
        - 2-4: Minimal hedging, natural and direct
        - 0-1: Very direct, no hedging detected

        Respond with JSON:
        - "score": 0-10 (higher = more excessive politeness)
        - "label": "excessive", "moderate", "minimal", "none"
        - "reasoning": brief explanation of hedging patterns found

        JSON response:
      filter_role: assistant
      analyze_message_level: true
      analyze_conversation_level: false
      inference_config:
        model_name: gpt-4o-mini
        engine: openai
        temperature: 0.1
        max_tokens: 256
        remote_params:
          num_workers: 200
          politeness_policy: 1.0
          use_adaptive_concurrency: true
      batch_size: 1000
      max_text_length: 4000
      parse_json_response: true

  # LLM Judge: Roleplay Bleeding (conversation-level)
  # Detects when assistant invents personas or roleplays unprompted
  - id: llm_judge
    instance_id: roleplay_bleeding
    params:
      prompt: |
        Evaluate if the assistant invents a persona or roleplays without being asked (0-10).
        Score HIGHER (8-10) for unwanted roleplay, LOWER (0-2) for natural responses.

        Conversation to evaluate:
        {text}

        Look for:
        - Assistant claiming to be someone/something (e.g., "As a doctor...", "I'm a teacher...")
        - Invented personal experiences or background
        - Roleplay when user didn't request it
        - First-person narratives that seem fabricated
        - Assistant speaking as if it has a specific profession/identity

        Scoring guide:
        - 8-10: Clear roleplay bleeding, assistant invents persona unprompted
        - 5-7: Some roleplay elements, but may be contextually appropriate
        - 2-4: Minimal roleplay, mostly natural responses
        - 0-1: No roleplay, natural assistant responses

        Respond with JSON:
        - "score": 0-10 (higher = more roleplay bleeding)
        - "label": "severe", "moderate", "minimal", "none"
        - "reasoning": brief explanation of roleplay elements found

        JSON response:
      analyze_message_level: false
      analyze_conversation_level: true
      inference_config:
        model_name: gpt-4o-mini
        engine: openai
        temperature: 0.1
        max_tokens: 256
        remote_params:
          num_workers: 200
          politeness_policy: 1.0
          use_adaptive_concurrency: true
      batch_size: 1000
      max_text_length: 8000
      parse_json_response: true

  # LLM Judge: Reasoning Leakage (message-level)
  # Detects long chain-of-thought reasoning when not requested
  - id: llm_judge
    instance_id: reasoning_leakage
    params:
      prompt: |
        Evaluate if this assistant response contains excessive reasoning/chain-of-thought when not requested (0-10).
        Score HIGHER (8-10) for unwanted reasoning steps, LOWER (0-2) for direct answers.

        Assistant response to evaluate:
        {text}

        Look for:
        - Long step-by-step reasoning when user asked a simple question
        - "Let me think...", "First, I need to...", "Let me break this down..."
        - Excessive explanation of the thinking process
        - Chain-of-thought that wasn't requested
        - Over-explaining simple answers

        Note: If user explicitly asked for reasoning/explanation, this is NOT leakage.

        Scoring guide:
        - 8-10: Severe reasoning leakage, excessive step-by-step when not needed
        - 5-7: Moderate reasoning, some unnecessary steps
        - 2-4: Minimal reasoning, mostly direct answers
        - 0-1: No reasoning leakage, appropriately direct

        Respond with JSON:
        - "score": 0-10 (higher = more reasoning leakage)
        - "label": "severe", "moderate", "minimal", "none"
        - "reasoning": brief explanation of reasoning patterns found

        JSON response:
      filter_role: assistant
      analyze_message_level: true
      analyze_conversation_level: false
      inference_config:
        model_name: gpt-4o-mini
        engine: openai
        temperature: 0.1
        max_tokens: 256
        remote_params:
          num_workers: 200
          politeness_policy: 1.0
          use_adaptive_concurrency: true
      batch_size: 1000
      max_text_length: 4000
      parse_json_response: true

  # LLM Judge: Synthetic Style Homogenization (conversation-level)
  # Detects similar phrasing patterns across conversations (dataset-level issue, checked per conversation)
  - id: llm_judge
    instance_id: style_homogenization
    params:
      prompt: |
        Evaluate if this conversation uses generic, homogenized phrasing that sounds synthetic (0-10).
        Score HIGHER (8-10) for generic/synthetic style, LOWER (0-2) for natural, varied language.

        Conversation to evaluate:
        {text}

        Look for:
        - Generic opening phrases: "I'd be happy to...", "Certainly!", "Of course!"
        - Repetitive response structures across turns
        - Overly formal or template-like language
        - Lack of natural variation in phrasing
        - Responses that sound like they came from a template
        - Similar sentence structures repeated

        Scoring guide:
        - 8-10: Severe homogenization, very generic/synthetic style
        - 5-7: Moderate homogenization, some generic patterns
        - 2-4: Minimal homogenization, mostly natural
        - 0-1: Natural, varied language with no homogenization

        Respond with JSON:
        - "score": 0-10 (higher = more homogenized style)
        - "label": "severe", "moderate", "minimal", "none"
        - "reasoning": brief explanation of homogenization patterns found

        JSON response:
      analyze_message_level: false
      analyze_conversation_level: true
      inference_config:
        model_name: gpt-4o-mini
        engine: openai
        temperature: 0.1
        max_tokens: 256
        remote_params:
          num_workers: 200
          politeness_policy: 1.0
          use_adaptive_concurrency: true
      batch_size: 1000
      max_text_length: 8000
      parse_json_response: true

  # LLM Judge: Repetitive Turns (conversation-level)
  # Detects when the same idea is restated across multiple turns
  - id: llm_judge
    instance_id: repetitive_turns
    params:
      prompt: |
        Evaluate if this conversation has repetitive turns where the same idea is restated (0-10).
        Score HIGHER (8-10) for high repetition, LOWER (0-2) for varied conversation.

        Conversation to evaluate:
        {text}

        Look for:
        - Same information repeated across multiple assistant turns
        - Restating the same point in different words
        - Circular conversations that don't progress
        - Assistant repeating what it already said
        - Lack of new information in later turns

        Scoring guide:
        - 8-10: Severe repetition, same ideas restated multiple times
        - 5-7: Moderate repetition, some redundant turns
        - 2-4: Minimal repetition, conversation progresses naturally
        - 0-1: No repetition, each turn adds new value

        Respond with JSON:
        - "score": 0-10 (higher = more repetitive turns)
        - "label": "severe", "moderate", "minimal", "none"
        - "reasoning": brief explanation of repetitive patterns found

        JSON response:
      analyze_message_level: false
      analyze_conversation_level: true
      inference_config:
        model_name: gpt-4o-mini
        engine: openai
        temperature: 0.1
        max_tokens: 256
        remote_params:
          num_workers: 200
          politeness_policy: 1.0
          use_adaptive_concurrency: true
      batch_size: 1000
      max_text_length: 8000
      parse_json_response: true

# Optional: Generate recommendations based on analysis
generate_recommendations: true
outlier_threshold: 3.0

# Optional: Generate HTML report with visualizations
generate_report: yes
