# Embedding Analyzer Configuration
# Semantic analysis using sentence embeddings for duplicate detection and clustering
#
# Usage: oumi analyze --config configs/examples/analyze/analyze_embedding.yaml
#
# IMPORTANT: Requires optional dependencies:
#   pip install "oumi[analyze_advanced]"
#
# Metrics computed:
#   - {column}_embedding_duplicate_group: Group ID for semantic duplicates
#   - {column}_embedding_has_semantic_duplicate: Boolean flag for duplicates
#   - {column}_embedding_cluster: Cluster label (if clustering enabled)
#
# Use cases:
#   - Find near-duplicate samples with different wording
#   - Cluster similar conversations for quality analysis
#   - Identify repetitive patterns in training data

# Dataset configuration
dataset_name: yahma/alpaca-cleaned
split: train
sample_count: 100  # Limit samples for quick analysis

# Or use a local file:
# dataset_path: data/dataset_examples/oumi_format.jsonl

output_path: ./analysis_output

# Recommendations and report settings
generate_recommendations: true
outlier_threshold: 3.0

analyzers:
  # Length analyzer for baseline metrics (uses tiktoken o200k_base by default)
  - id: length
    params:
      char_count: false
      word_count: false
      sentence_count: false
      token_count: true  # Uses tiktoken o200k_base (GPT-4o/GPT-5 encoding)

  # Embedding analyzer for semantic analysis
  - id: embedding
    params:
      # Model selection (sentence-transformers models)
      model_name: all-MiniLM-L6-v2  # Fast and effective (384 dims)
      # Alternatives:
      # model_name: all-mpnet-base-v2     # Higher quality (768 dims)
      # model_name: paraphrase-MiniLM-L6-v2  # Paraphrase-focused

      # Semantic duplicate detection
      detect_duplicates: true
      duplicate_threshold: 0.95  # Cosine similarity threshold (0.9-0.99)

      # Clustering (optional)
      cluster_samples: false           # Set true to enable clustering
      clustering_method: dbscan        # "dbscan" (auto clusters) or "kmeans"
      # n_clusters: 10                 # Required for kmeans
      eps: 0.5                         # DBSCAN: max distance between samples
      min_samples: 2                   # DBSCAN: min samples per cluster

      # Performance settings
      batch_size: 32                   # Batch size for embedding computation
      # device: cuda                   # "cuda", "cpu", or null for auto

      # Storage (warning: increases memory usage)
      store_embeddings: false          # Store raw embeddings in output
