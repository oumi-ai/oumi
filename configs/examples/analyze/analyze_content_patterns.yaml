# Content Pattern Analysis Configuration
# Detects AI-specific quality issues in training datasets
#
# Usage: oumi analyze --config configs/examples/analyze/analyze_content_patterns.yaml
#
# This configuration runs content pattern detection to identify:
# - Placeholder text ([Name], [Product Name], [Your...], etc.)
# - AI hallucinated experiences (fabricated first-person stories)
# - Nooutput markers (<nooutput>, N/A, etc.)
# - AI refusals ("I cannot provide...", "I'm unable to...")
# - Suspicious/potentially fake URLs
#
# Requirements:
#   pip install 'oumi[analyze]'
#
# Output files:
#   - message_analysis.csv: Per-message metrics with content pattern flags
#   - conversation_analysis.csv: Per-conversation aggregated metrics
#   - analysis_summary.json: Statistical summary with pattern counts
#   - analysis_report.html: Interactive HTML report

# Dataset configuration - Alpaca dataset
dataset_name: tatsu-lab/alpaca
split: train
# sample_count: 1000  # Uncomment to limit to subset for testing

# Output configuration
output_path: ./analysis_output/content_patterns
generate_report: true
report_title: "Content Pattern Quality Analysis"

# Recommendation settings
generate_recommendations: true
outlier_threshold: 3.0

analyzers:
  # ==========================================================================
  # CONTENT PATTERN ANALYZER - AI-specific quality issues
  # ==========================================================================
  - id: content_pattern
    params:
      # ----- Placeholder Detection -----
      # Catches: [Name], [Company Name], [Your...], [Insert...], etc.
      # Common in AI-generated template responses
      detect_placeholders: true
      # Optional whitelist for legitimate placeholders (e.g., code variables)
      # placeholder_whitelist:
      #   - "[INPUT]"
      #   - "[OUTPUT]"

      # ----- AI Hallucinated Experiences -----
      # Catches: "When I was working as a project manager..."
      # Fabricated first-person stories that LLMs shouldn't produce
      detect_hallucinated_experiences: true

      # ----- Nooutput/NA Detection -----
      # Catches: <nooutput>, N/A, None, empty responses
      detect_nooutput: true

      # ----- AI Refusal Detection -----
      # Catches: "I cannot provide...", "I'm unable to..."
      detect_refusals: true

      # ----- Suspicious URL Detection -----
      # Catches: Potentially fake/hallucinated URLs
      # Off by default (can have false positives)
      detect_suspicious_urls: false

      # ----- Role-Aware Analysis -----
      # If true, only analyze assistant/output messages
      # Useful to avoid flagging placeholders in user instructions
      check_output_only: false

      # ----- Composite Score -----
      compute_content_pattern_score: true

  # ==========================================================================
  # LENGTH ANALYZER - Token counts for context
  # ==========================================================================
  - id: length
    params:
      word_count: true
      token_count: true

  # ==========================================================================
  # QUALITY ANALYZER - Additional quality checks
  # ==========================================================================
  - id: quality
    params:
      detect_pii: true
      detect_encoding_issues: true
      detect_special_tokens: true  # Also catches <nooutput> via special tokens
      detect_repetition: true
      repetition_threshold: 0.3
      compute_quality_score: true

  # ==========================================================================
  # TRAINING QUALITY ANALYZER - Instruction/response quality
  # ==========================================================================
  - id: training_quality
    params:
      compute_instruction_clarity: true
      compute_response_completeness: true
      compute_turn_quality: true

# ==========================================================================
# OUTPUT COLUMNS REFERENCE
# ==========================================================================
#
# Content pattern detection:
#   - text_content_content_pattern_has_placeholder: Boolean
#   - text_content_content_pattern_placeholder_count: Integer count
#   - text_content_content_pattern_placeholder_types: Comma-separated types
#   - text_content_content_pattern_has_hallucinated_experience: Boolean
#   - text_content_content_pattern_has_nooutput: Boolean
#   - text_content_content_pattern_has_refusal: Boolean
#   - text_content_content_pattern_has_suspicious_url: Boolean
#   - text_content_content_pattern_suspicious_url_count: Integer count
#   - text_content_content_pattern_content_pattern_score: 0-1 (higher = cleaner)
#
# ==========================================================================
# FILTERING RESULTS
# ==========================================================================
#
# After running analysis, filter with pandas:
#
# import pandas as pd
# df = pd.read_csv("analysis_output/content_patterns/message_analysis.csv")
#
# # Remove all problematic samples
# filtered = df[
#     (df["text_content_content_pattern_has_placeholder"] == False) &
#     (df["text_content_content_pattern_has_hallucinated_experience"] == False) &
#     (df["text_content_content_pattern_has_nooutput"] == False) &
#     (df["text_content_content_pattern_has_refusal"] == False) &
#     (df["text_content_content_pattern_content_pattern_score"] >= 0.7)
# ]
#
# ==========================================================================
# EXPECTED RESULTS FOR ALPACA
# ==========================================================================
#
# Based on manual review of tatsu-lab/alpaca:
#   - ~227 samples with placeholder text
#   - ~148 samples with AI hallucinated experiences
#   - ~29 samples with nooutput markers
#   - Additional samples with refusals and suspicious URLs
#
# Total estimated: 5-10% of dataset may have content pattern issues
