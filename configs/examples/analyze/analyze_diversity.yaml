# Diversity Analysis Configuration
# Measures vocabulary diversity, text richness, and question distribution
#
# Usage: oumi analyze --config configs/examples/analyze/analyze_diversity.yaml
#
# This config analyzes two types of diversity:
# 1. Vocabulary diversity: Word-level metrics (TTR, unique words ratio)
# 2. Question diversity: Cluster-based distribution analysis of user messages
#
# Requirements:
#   pip install 'oumi[analyze]'  # Includes sentence-transformers for clustering
#
# Output files:
#   - message_analysis.csv: Per-message metrics
#   - conversation_analysis.csv: Per-conversation aggregated metrics
#   - analysis_summary.json: Statistical summary with diversity metrics
#   - analysis_report.html: Interactive HTML report

# Dataset configuration
dataset_name: tatsu-lab/alpaca
split: train
# sample_count: 500 # Reasonable size for diversity analysis

# Or use a local file:
# dataset_path: data/dataset_examples/oumi_format.jsonl

output_path: ./analysis_output/diversity
generate_report: true
report_title: "Dataset Diversity Analysis"

# Recommendations and report settings
generate_recommendations: true
outlier_threshold: 3.0 # Standard deviations for outlier detection

analyzers:
  # ==========================================================================
  # LENGTH ANALYZER - Token counts for context analysis
  # ==========================================================================
  - id: length
    params:
      char_count: false
      word_count: true
      sentence_count: false
      token_count: true # Uses tiktoken o200k_base (GPT-4o/GPT-5 encoding)

  # ==========================================================================
  # DIVERSITY ANALYZER - Vocabulary richness metrics
  # ==========================================================================
  - id: diversity
    params:
      unique_words_ratio: true # Ratio of unique to total words
      type_token_ratio: true # Classic TTR metric
      vocabulary_richness: true # Log-adjusted TTR (better for varying lengths)
      hapax_legomena_ratio: true # Words appearing only once
      case_sensitive: false # Treat "Hello" and "hello" as same word

  # ==========================================================================
  # QUESTION DIVERSITY ANALYZER - Cluster-based distribution analysis
  # ==========================================================================
  # This analyzer answers: "Are my user questions too similar to each other?"
  # and "Is the distribution of questions too narrow?"
  # Note: Only analyzes user messages (role="user"), ignores system prompts.
  - id: question_diversity
    params:
      # Clustering configuration
      cluster_questions: true
      clustering_method: dbscan # Auto-determines number of clusters
      eps: 0.15 # Neighborhood size (0.15 = ~99% cosine similarity)
      min_samples: 2 # Minimum samples to form a cluster

      # Embedding model
      model_name: all-MiniLM-L6-v2 # Fast and effective
      batch_size: 32
      device: null # Auto-detect (GPU if available)

      # Distribution analysis
      compute_entropy: true # Shannon entropy (higher = more diverse)
      compute_concentration: true # Gini coefficient (0=uniform, 1=concentrated)
      flag_concentrated_clusters: true
      concentration_threshold: 0.5 # Flag if >50% in one cluster

# ==========================================================================
# OUTPUT COLUMNS REFERENCE
# ==========================================================================
#
# Vocabulary diversity (per-message):
#   - text_content_diversity_unique_words_ratio: 0-1 (higher = more unique words)
#   - text_content_diversity_type_token_ratio: 0-1 (classic TTR)
#   - text_content_diversity_vocabulary_richness: Log-adjusted TTR
#   - text_content_diversity_hapax_legomena_ratio: Rare words ratio
#
# Question diversity (per-message, user messages only):
#   - text_content_question_diversity_cluster_id: Which cluster this belongs to
#   - text_content_question_diversity_cluster_size: Size of the cluster
#   - text_content_question_diversity_is_concentrated: True if in large cluster
#
# Dataset-level metrics (in analysis_summary.json):
#   - num_question_clusters: Total number of question clusters
#   - question_entropy: Shannon entropy of distribution
#   - question_gini: Gini coefficient (0=uniform, 1=concentrated)
#   - largest_cluster_ratio: Fraction in largest cluster
#   - diversity_rating: "low", "medium", or "high"

# ==========================================================================
# INTERPRETING RESULTS
# ==========================================================================
#
# Vocabulary Diversity:
#   - unique_words_ratio < 0.3: Low vocabulary diversity
#   - type_token_ratio < 0.5: Repetitive language
#   - hapax_legomena_ratio > 0.5: Many rare words (possibly typos/jargon)
#
# Question Diversity:
#   - diversity_rating = "low": User questions are too similar
#   - largest_cluster_ratio > 0.5: One question type dominates
#   - question_gini > 0.6: Highly uneven distribution
#
# Recommendations:
#   - Low vocabulary diversity: Expand response variety
#   - Low question diversity: Add more diverse question types
#   - Concentrated clusters: Balance question categories
