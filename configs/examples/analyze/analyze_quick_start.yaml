# Quick Start Configuration for Typed Analyzer Framework
# =========================================================
#
# This config uses a public HuggingFace dataset so anyone can run it
# without needing local data files.
#
# INSTALLATION:
#   pip install -e ".[analyze]"
#
# USAGE:
#   # Basic run (no API key needed)
#   oumi analyze --config configs/examples/analyze/analyze_quick_start.yaml --typed
#
#   # List available metrics
#   oumi analyze --config configs/examples/analyze/analyze_quick_start.yaml --typed --list-metrics
#
# This example runs the length and quality analyzers (no LLM API calls required).
# For LLM-based analysis, see typed_llm_analyzer_example.yaml

# Dataset configuration - using public HuggingFace dataset with multi-turn conversations
dataset_name: HuggingFaceH4/ultrachat_200k
split: train_sft
sample_count: 50  # Analyze 50 conversations

# Output configuration
output_path: ./analysis_output/quickstart

# Analyzers to run (both are fast, non-LLM analyzers)
analyzers:
  # Length analyzer - computes token counts
  - id: length
    params:
      tiktoken_encoding: cl100k_base  # GPT-4 tokenizer for accurate counts
      compute_role_stats: true        # Compute per-role statistics

  # Quality analyzer - basic data quality checks (fast, no LLM needed)
  - id: quality
    params:
      check_turn_pattern: true      # Check for alternating user-assistant turns
      check_empty_content: true     # Check for empty messages
      check_invalid_values: true    # Check for NaN, null, None as strings
      check_truncation: true        # Check for abruptly cut-off conversations
      check_refusals: true          # Check for policy refusal patterns
      check_tags: true              # Check for unbalanced think/code tags

# Custom metrics (optional - demonstrates the feature)
custom_metrics:
  # Check if assistant gives short or long responses
  - id: response_length_category
    scope: conversation
    description: "Categorizes response length"
    depends_on:
      - length
    output_schema:
      - name: category
        type: str
        description: "short, medium, or long"
      - name: avg_tokens_per_message
        type: float
        description: "Average tokens per message"
    function: |
      def compute(conversation, results, index):
          length_result = results["length"][index]
          total = getattr(length_result, "total_tokens", 0) or 0
          num_msgs = getattr(length_result, "num_messages", 1) or 1
          avg = total / num_msgs
          
          if avg < 100:
              cat = "short"
          elif avg < 500:
              cat = "medium"
          else:
              cat = "long"
          
          return {"category": cat, "avg_tokens_per_message": round(avg, 1)}

# Validation tests
tests:
  # ============================================================
  # Length-based tests
  # ============================================================
  - id: reasonable_length
    type: threshold
    metric: length.total_tokens
    operator: ">"
    value: 4096
    max_percentage: 10.0
    severity: medium
    title: "Reasonable conversation length"
    description: "Most conversations should fit in 4K context"

  - id: not_empty
    type: threshold
    metric: length.total_tokens
    operator: "<"
    value: 10
    max_percentage: 1.0
    severity: high
    title: "Non-empty conversations"
    description: "Conversations should have meaningful content"

  - id: multi_turn
    type: threshold
    metric: length.num_messages
    operator: "<"
    value: 2
    max_percentage: 5.0
    severity: low
    title: "Multi-turn conversations"
    description: "Most should have at least 2 messages"

  # ============================================================
  # Quality-based tests (using the quality analyzer)
  # ============================================================
  - id: alternating_turns
    type: percentage
    metric: quality.has_alternating_turns
    condition: "== True"
    min_percentage: 95.0
    severity: high
    title: "Proper turn structure"
    description: "Conversations should have alternating user-assistant turns"

  - id: no_empty_messages
    type: percentage
    metric: quality.has_empty_turns
    condition: "== False"
    min_percentage: 100.0
    severity: high
    title: "No empty messages"
    description: "All messages should have content"

  - id: no_truncation
    type: percentage
    metric: quality.appears_truncated
    condition: "== False"
    min_percentage: 95.0
    severity: medium
    title: "Complete conversations"
    description: "Conversations should not appear truncated"

  - id: low_refusal_rate
    type: percentage
    metric: quality.has_policy_refusal
    condition: "== False"
    min_percentage: 90.0
    severity: medium
    title: "Low policy refusal rate"
    description: "Most conversations should not contain policy refusals"

  - id: passes_quality
    type: percentage
    metric: quality.passes_basic_quality
    condition: "== True"
    min_percentage: 85.0
    severity: medium
    title: "Overall quality"
    description: "Most conversations should pass all basic quality checks"
