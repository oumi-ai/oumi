# VERL GRPO VLM training config on Geometry3K dataset.
#
# Requirements:
#   - Log into WandB (`wandb login`) or disable `enable_wandb`
#
# Usage:
#   oumi train -c configs/examples/grpo_verl_geometry3k/train.yaml
#
# See Also:
#   - Documentation: https://oumi.ai/docs/en/latest/user_guides/train/train.html
#   - Config class: oumi.core.configs.TrainingConfig
#   - Config source: https://github.com/oumi-ai/oumi/blob/main/src/oumi/core/configs/training_config.py
#   - Other training configs: configs/**/pretraining/, configs/**/sft/, configs/**/dpo/

model:
  model_name: "Qwen/Qwen2.5-VL-7B-Instruct"

data:
  train:
    datasets:
      - dataset_name: "hiyouga/geometry3k"
        split: "train"
        shuffle: True
        seed: 42
        transform_num_workers: "auto"
        dataset_kwargs:
          return_conversations: True
          processor_name: "Qwen/Qwen2.5-VL-7B-Instruct"
          # limit: 4096 # Uncomment to limit dataset size!
          return_tensors: True
  validation:
    datasets:
      - dataset_name: "hiyouga/geometry3k"
        split: "validation"
        shuffle: True
        seed: 42
        transform_num_workers: "auto"
        dataset_kwargs:
          return_conversations: True
          processor_name: "Qwen/Qwen2.5-VL-7B-Instruct"
          # limit: 4096 # Uncomment to limit dataset size!
          return_tensors: True

training:
  trainer_type: "VERL_GRPO"
  num_train_epochs: 5
  save_steps: 150
  eval_strategy: "steps"
  eval_steps: 12

  learning_rate: 1.0e-6
  enable_gradient_checkpointing: True

  reward_functions: [] # Use built-in reward func for data_source=="hiyouga/geometry3k".

  grpo:
    max_completion_length: 1024
    use_vllm: True
    temperature: 0.6
    vllm_gpu_memory_utilization: 0.6

  # from https://github.com/volcengine/verl/blob/main/examples/grpo_trainer/run_qwen2_5_vl-7b.sh
  verl_config_overrides:
    data:
      # train_files: "/home/cmu/countdown-curriculum/data/countdown/train-3-3.parquet"
      # val_files: "/home/cmu/countdown-curriculum/data/countdown/test-3-10.parquet"
      train_batch_size: 512
      val_batch_size: 512
      max_prompt_length: 1024
      # max_extrapolation_length: 2048
      # shuffle: False
      max_response_length: 2048
      filter_overlong_prompts: True
      truncation: "error"
      image_key: "images"
    algorithm:
      use_kl_in_reward: False
    actor_rollout_ref:
      model:
        use_remove_padding: True
      actor:
        ppo_mini_batch_size: 128
        ppo_micro_batch_size_per_gpu: 10
        use_kl_loss: True
        kl_loss_coef: 0.01
        kl_loss_type: "low_var_kl"
        entropy_coeff: 0
        param_offload: False
        optimizer_offload: False
        # use_dynamic_bsz: True
        # gradients: "normal"
        fsdp_config:
          param_offload: False
          optimizer_offload: False
      rollout:
        tensor_model_parallel_size: 2
        log_prob_micro_batch_size_per_gpu: 10 # 20
        n: 5
        enforce_eager: False
        free_cache_engine: False
        enable_chunked_prefill: False
        # max_num_batched_tokens: 16384
      ref:
        log_prob_micro_batch_size_per_gpu: 10 #20
        fsdp_config:
          param_offload: True
    trainer:
      n_gpus_per_node: 4
      nnodes: 1

  output_dir: "output/grpo-verl-vlm-geom3k"
  enable_wandb: True
