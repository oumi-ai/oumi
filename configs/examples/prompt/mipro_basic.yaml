# Basic MIPRO (Multi-prompt Instruction PRoposal Optimizer) configuration
# This example uses a small model for quick experimentation

model:
  model_name: "HuggingFaceTB/SmolLM2-135M"
  trust_remote_code: true
  torch_dtype_str: "bfloat16"
  tokenizer_kwargs:
    pad_token: "<|endoftext|>"

generation:
  max_new_tokens: 128
  temperature: 0.7
  use_sampling: true

optimization:
  optimizer: "mipro"
  num_trials: 50
  max_bootstrapped_demos: 4
  max_labeled_demos: 16
  optimize_instructions: true
  optimize_demos: true
  optimize_hyperparameters: false
  save_intermediate_results: true
  verbose: true
  seed: 42

# Dataset paths (example datasets provided)
train_dataset_path: "configs/examples/prompt/datasets/qa_train.jsonl"
val_dataset_path: "configs/examples/prompt/datasets/qa_val.jsonl"

# Optional initial prompt to start optimization from
# initial_prompt: "You are a helpful assistant that answers questions accurately."

# Output directory for optimized prompts and results
output_dir: "./prompt_optimization_results/mipro"

# Evaluation metric
metric: "accuracy"

# Inference engine to use during optimization
engine: NATIVE
