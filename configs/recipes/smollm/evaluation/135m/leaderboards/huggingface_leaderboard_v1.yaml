model:
  model_name: "HuggingFaceTB/SmolLM2-135M-Instruct"
  model_max_length: 2048
  torch_dtype_str: "bfloat16"
  attn_implementation: "sdpa"
  load_pretrained_weights: True
  trust_remote_code: True

generation:
  batch_size: 4

############################## HuggingFace Leaderboard V1 ##############################
# https://huggingface.co/spaces/open-llm-leaderboard-old/open_llm_leaderboard          #
#                                                                                      #
# Benchmarks:                                                                          #
# - MMLU (Massive Multitask Language Understanding): mmlu                              #
# - ARC (AI2 Reasoning Challenge): arc_challenge                                       #
# - Winogrande (Adversarial Winograd Schema Challenge at Scale): winogrande            #
# - HellaSwag: hellaswag                                                               #
# - TruthfulQA (Measuring How Models Mimic Human Falsehoods): truthfulqa_mc2           #
# - GSM 8K (Grade School Math): gsm8k                                                  #
########################################################################################

tasks:
  - evaluation_platform: lm_harness
    task_name: mmlu
    eval_kwargs:
      num_fewshot: 5
  - evaluation_platform: lm_harness
    task_name: arc_challenge
    eval_kwargs:
      num_fewshot: 25
  - evaluation_platform: lm_harness
    task_name: winogrande
    eval_kwargs:
      num_fewshot: 5
  - evaluation_platform: lm_harness
    task_name: hellaswag
    eval_kwargs:
      num_fewshot: 10
  - evaluation_platform: lm_harness
    task_name: truthfulqa_mc2
    eval_kwargs:
      num_fewshot: 0
  - evaluation_platform: lm_harness
    task_name: gsm8k
    eval_kwargs:
      num_fewshot: 5

output_dir: "./huggingface_leaderboard_v1"
