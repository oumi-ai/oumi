model:
  model_name: "o1-preview"

inference_engine: OPENAI

generation:
  max_new_tokens: 8192
  temperature: 1.0

tasks:
  - evaluation_backend: custom
    task_name: my_custom_eval_function
