{
  "version": "1.0.0",
  "generated_at": "2025-12-21T10:13:46.980802",
  "configs": {
    "llama4-scout:train": {
      "alias": "llama4-scout",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama4/sft/scout_base_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama4-scout:job": {
      "alias": "llama4-scout",
      "alias_type": "job",
      "path": "oumi://configs/recipes/llama4/sft/scout_base_full/gcp_job.yaml",
      "config_type": "job",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama4-scout-instruct-lora": {
      "alias": "llama4-scout-instruct-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama4/sft/scout_instruct_lora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama4-scout-instruct-qlora": {
      "alias": "llama4-scout-instruct-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama4/sft/scout_instruct_qlora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama4-scout-instruct:train": {
      "alias": "llama4-scout-instruct",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama4/sft/scout_instruct_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama4-scout-instruct:infer": {
      "alias": "llama4-scout-instruct",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/llama4/inference/scout_instruct_infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama4-scout-instruct:job": {
      "alias": "llama4-scout-instruct",
      "alias_type": "job",
      "path": "oumi://configs/recipes/llama4/sft/scout_instruct_full/gcp_job.yaml",
      "config_type": "job",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama4-scout-instruct:eval": {
      "alias": "llama4-scout-instruct",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/llama4/evaluation/scout_instruct_eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama4-maverick": {
      "alias": "llama4-maverick",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/llama4/inference/maverick_instruct_together_infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-30b-a3b:infer": {
      "alias": "qwen3-30b-a3b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/qwen3/inference/30b_a3b_infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 30.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-30b-a3b:eval": {
      "alias": "qwen3-30b-a3b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/qwen3/evaluation/30b_a3b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "qwen",
      "model_size_billions": 30.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-30b-a3b-lora:train": {
      "alias": "qwen3-30b-a3b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/qwen3/sft/30b_a3b_lora/train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 30.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-30b-a3b-lora:job": {
      "alias": "qwen3-30b-a3b-lora",
      "alias_type": "job",
      "path": "oumi://configs/recipes/qwen3/sft/30b_a3b_lora/gcp_job.yaml",
      "config_type": "job",
      "model_family": "qwen",
      "model_size_billions": 30.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-32b:infer": {
      "alias": "qwen3-32b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/qwen3/inference/32b_infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 32.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-32b:eval": {
      "alias": "qwen3-32b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/qwen3/evaluation/32b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "qwen",
      "model_size_billions": 32.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-32b-lora:train": {
      "alias": "qwen3-32b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/qwen3/sft/32b_lora/train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 32.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-32b-lora:job": {
      "alias": "qwen3-32b-lora",
      "alias_type": "job",
      "path": "oumi://configs/recipes/qwen3/sft/32b_lora/gcp_job.yaml",
      "config_type": "job",
      "model_family": "qwen",
      "model_size_billions": 32.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-next-80b-a3b:infer": {
      "alias": "qwen3-next-80b-a3b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/qwen3_next/inference/80b_a3b_infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 80.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-next-80b-a3b:eval": {
      "alias": "qwen3-next-80b-a3b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/qwen3_next/evaluation/80b_a3b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "qwen",
      "model_size_billions": 80.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-next-80b-a3b-instruct": {
      "alias": "qwen3-next-80b-a3b-instruct",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/qwen3_next/inference/80b_a3b_instruct_infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 80.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-next-80b-a3b-lora": {
      "alias": "qwen3-next-80b-a3b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/qwen3_next/sft/80b_a3b_lora/train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 80.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-4b:train": {
      "alias": "gemma3-4b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/gemma3/sft/4b_full/train.yaml",
      "config_type": "training",
      "model_family": "gemma",
      "model_size_billions": 4.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-4b:infer": {
      "alias": "gemma3-4b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/gemma3/inference/4b_instruct_infer.yaml",
      "config_type": "inference",
      "model_family": "gemma",
      "model_size_billions": 4.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-4b:eval": {
      "alias": "gemma3-4b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/gemma3/evaluation/4b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "gemma",
      "model_size_billions": 4.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-12b:infer": {
      "alias": "gemma3-12b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/gemma3/inference/12b_instruct_infer.yaml",
      "config_type": "inference",
      "model_family": "gemma",
      "model_size_billions": 12.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-12b:eval": {
      "alias": "gemma3-12b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/gemma3/evaluation/12b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "gemma",
      "model_size_billions": 12.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-12b-lora": {
      "alias": "gemma3-12b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/gemma3/sft/12b_lora/train.yaml",
      "config_type": "training",
      "model_family": "gemma",
      "model_size_billions": 12.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-27b:infer": {
      "alias": "gemma3-27b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/gemma3/inference/27b_instruct_infer.yaml",
      "config_type": "inference",
      "model_family": "gemma",
      "model_size_billions": 27.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-27b:eval": {
      "alias": "gemma3-27b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/gemma3/evaluation/27b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "gemma",
      "model_size_billions": 27.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemma3-27b-lora": {
      "alias": "gemma3-27b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/gemma3/sft/27b_lora/train.yaml",
      "config_type": "training",
      "model_family": "gemma",
      "model_size_billions": 27.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "olmo3-7b:train": {
      "alias": "olmo3-7b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/olmo3/sft/7b_full/train.yaml",
      "config_type": "training",
      "model_family": "olmo",
      "model_size_billions": 7.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "olmo3-7b:infer": {
      "alias": "olmo3-7b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/olmo3/inference/7b_infer.yaml",
      "config_type": "inference",
      "model_family": "olmo",
      "model_size_billions": 7.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "olmo3-7b:eval": {
      "alias": "olmo3-7b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/olmo3/evaluation/7b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "olmo",
      "model_size_billions": 7.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "olmo3-32b:infer": {
      "alias": "olmo3-32b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/olmo3/inference/32b_infer.yaml",
      "config_type": "inference",
      "model_family": "olmo",
      "model_size_billions": 32.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "olmo3-32b:eval": {
      "alias": "olmo3-32b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/olmo3/evaluation/32b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "olmo",
      "model_size_billions": 32.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "olmo3-32b-lora": {
      "alias": "olmo3-32b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/olmo3/sft/32b_lora/train.yaml",
      "config_type": "training",
      "model_family": "olmo",
      "model_size_billions": 32.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwen3-vl-2b": {
      "alias": "qwen3-vl-2b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/qwen3_vl_2b/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 2.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen3-vl-4b": {
      "alias": "qwen3-vl-4b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/qwen3_vl_4b/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 4.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen3-vl-8b": {
      "alias": "qwen3-vl-8b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/qwen3_vl_8b/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 8.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "phi4-reasoning-plus:train": {
      "alias": "phi4-reasoning-plus",
      "alias_type": "train",
      "path": "oumi://configs/recipes/phi4/sft/reasoning_plus/full_train.yaml",
      "config_type": "training",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "phi4-reasoning-plus:job": {
      "alias": "phi4-reasoning-plus",
      "alias_type": "job",
      "path": "oumi://configs/recipes/phi4/sft/reasoning_plus/full_gcp_job.yaml",
      "config_type": "job",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "phi4-reasoning-plus:infer": {
      "alias": "phi4-reasoning-plus",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/phi4/inference/reasoning_plus_infer.yaml",
      "config_type": "inference",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "phi4-reasoning-plus:eval": {
      "alias": "phi4-reasoning-plus",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/phi4/evaluation/reasoning_plus_eval.yaml",
      "config_type": "evaluation",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "phi4-reasoning-plus-lora:train": {
      "alias": "phi4-reasoning-plus-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/phi4/sft/reasoning_plus/lora_train.yaml",
      "config_type": "training",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "phi4-reasoning-plus-lora:job": {
      "alias": "phi4-reasoning-plus-lora",
      "alias_type": "job",
      "path": "oumi://configs/recipes/phi4/sft/reasoning_plus/lora_gcp_job.yaml",
      "config_type": "job",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "phi4-reasoning-plus-qlora:train": {
      "alias": "phi4-reasoning-plus-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/phi4/sft/reasoning_plus/qlora_train.yaml",
      "config_type": "training",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "phi4-reasoning-plus-qlora:job": {
      "alias": "phi4-reasoning-plus-qlora",
      "alias_type": "job",
      "path": "oumi://configs/recipes/phi4/sft/reasoning_plus/qlora_gcp_job.yaml",
      "config_type": "job",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_0_5b:train": {
      "alias": "falcon_h1_0_5b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_0_5b/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_0_5b:infer": {
      "alias": "falcon_h1_0_5b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/falcon_h1/inference/0_5b_infer.yaml",
      "config_type": "inference",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_0_5b:eval": {
      "alias": "falcon_h1_0_5b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_h1/evaluation/falcon_h1_0_5b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_0_5b:job": {
      "alias": "falcon_h1_0_5b",
      "alias_type": "job",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_0_5b/full_lambda_job.yaml",
      "config_type": "job",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_1_5b:train": {
      "alias": "falcon_h1_1_5b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_1_5b/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_1_5b:infer": {
      "alias": "falcon_h1_1_5b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/falcon_h1/inference/1_5b_infer.yaml",
      "config_type": "inference",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_1_5b:eval": {
      "alias": "falcon_h1_1_5b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_h1/evaluation/falcon_h1_1_5b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_1_5b:job": {
      "alias": "falcon_h1_1_5b",
      "alias_type": "job",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_1_5b/full_lambda_job.yaml",
      "config_type": "job",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_1_5b_deep:train": {
      "alias": "falcon_h1_1_5b_deep",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_1_5b_deep/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_1_5b_deep:infer": {
      "alias": "falcon_h1_1_5b_deep",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/falcon_h1/inference/1_5b_deep_infer.yaml",
      "config_type": "inference",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_1_5b_deep:eval": {
      "alias": "falcon_h1_1_5b_deep",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_h1/evaluation/falcon_h1_1_5b_deep/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_1_5b_deep:job": {
      "alias": "falcon_h1_1_5b_deep",
      "alias_type": "job",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_1_5b_deep/full_lambda_job.yaml",
      "config_type": "job",
      "model_family": "falcon",
      "model_size_billions": 5.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_3b:train": {
      "alias": "falcon_h1_3b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_3b/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_3b:infer": {
      "alias": "falcon_h1_3b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/falcon_h1/inference/3b_infer.yaml",
      "config_type": "inference",
      "model_family": "falcon",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_3b:eval": {
      "alias": "falcon_h1_3b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_h1/evaluation/falcon_h1_3b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_3b:job": {
      "alias": "falcon_h1_3b",
      "alias_type": "job",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_3b/full_lambda_job.yaml",
      "config_type": "job",
      "model_family": "falcon",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_7b:train": {
      "alias": "falcon_h1_7b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_7b/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 7.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_7b:infer": {
      "alias": "falcon_h1_7b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/falcon_h1/inference/7b_infer.yaml",
      "config_type": "inference",
      "model_family": "falcon",
      "model_size_billions": 7.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_7b:eval": {
      "alias": "falcon_h1_7b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_h1/evaluation/falcon_h1_7b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 7.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_7b:job": {
      "alias": "falcon_h1_7b",
      "alias_type": "job",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_7b/full_lambda_job.yaml",
      "config_type": "job",
      "model_family": "falcon",
      "model_size_billions": 7.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_34b:train": {
      "alias": "falcon_h1_34b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_34b/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 34.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_34b:infer": {
      "alias": "falcon_h1_34b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/falcon_h1/inference/34b_infer.yaml",
      "config_type": "inference",
      "model_family": "falcon",
      "model_size_billions": 34.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_34b:eval": {
      "alias": "falcon_h1_34b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_h1/evaluation/falcon_h1_34b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 34.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon_h1_34b:job": {
      "alias": "falcon_h1_34b",
      "alias_type": "job",
      "path": "oumi://configs/recipes/falcon_h1/sft/falcon_h1_34b/full_lambda_job.yaml",
      "config_type": "job",
      "model_family": "falcon",
      "model_size_billions": 34.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon-e-1b:train": {
      "alias": "falcon-e-1b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_e/sft/falcon_e_1b/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 1.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon-e-1b:eval": {
      "alias": "falcon-e-1b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_e/evaluation/falcon_e_1b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 1.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon-e-1b-instruct:train": {
      "alias": "falcon-e-1b-instruct",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_e/sft/falcon_e_1b_instruct/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 1.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon-e-1b-instruct:eval": {
      "alias": "falcon-e-1b-instruct",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_e/evaluation/falcon_e_1b_instruct/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 1.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon-e-3b:train": {
      "alias": "falcon-e-3b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_e/sft/falcon_e_3b/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon-e-3b:eval": {
      "alias": "falcon-e-3b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_e/evaluation/falcon_e_3b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon-e-3b-instruct:train": {
      "alias": "falcon-e-3b-instruct",
      "alias_type": "train",
      "path": "oumi://configs/recipes/falcon_e/sft/falcon_e_3b_instruct/full_train.yaml",
      "config_type": "training",
      "model_family": "falcon",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "falcon-e-3b-instruct:eval": {
      "alias": "falcon-e-3b-instruct",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/falcon_e/evaluation/falcon_e_3b_instruct/eval.yaml",
      "config_type": "evaluation",
      "model_family": "falcon",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-8b:train": {
      "alias": "deepseek-r1-distill-llama-8b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_llama_8b/full_train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-8b:infer": {
      "alias": "deepseek-r1-distill-llama-8b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/deepseek_r1/inference/distill_llama_8b/infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-8b:eval": {
      "alias": "deepseek-r1-distill-llama-8b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/deepseek_r1/evaluation/distill_llama_8b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-8b-lora": {
      "alias": "deepseek-r1-distill-llama-8b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_llama_8b/lora_train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-8b-qlora": {
      "alias": "deepseek-r1-distill-llama-8b-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_llama_8b/qlora_train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-70b:train": {
      "alias": "deepseek-r1-distill-llama-70b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_llama_70b/full_train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-70b:infer": {
      "alias": "deepseek-r1-distill-llama-70b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/deepseek_r1/inference/distill_llama_70b/infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-70b:eval": {
      "alias": "deepseek-r1-distill-llama-70b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/deepseek_r1/evaluation/distill_llama_70b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-70b-lora": {
      "alias": "deepseek-r1-distill-llama-70b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_llama_70b/lora_train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-llama-70b-qlora": {
      "alias": "deepseek-r1-distill-llama-70b-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_llama_70b/qlora_train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-qwen-1.5b:train": {
      "alias": "deepseek-r1-distill-qwen-1.5b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_qwen_1_5b/full_train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 5.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-qwen-1.5b:infer": {
      "alias": "deepseek-r1-distill-qwen-1.5b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/deepseek_r1/inference/distill_qwen_1_5b/infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-qwen-1.5b:eval": {
      "alias": "deepseek-r1-distill-qwen-1.5b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/deepseek_r1/evaluation/distill_qwen_1_5b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "qwen",
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-qwen-1.5b-lora": {
      "alias": "deepseek-r1-distill-qwen-1.5b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_qwen_1_5b/lora_train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 5.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-qwen-32b:infer": {
      "alias": "deepseek-r1-distill-qwen-32b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/deepseek_r1/inference/distill_qwen_32b/infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 32.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-qwen-32b:eval": {
      "alias": "deepseek-r1-distill-qwen-32b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/deepseek_r1/evaluation/distill_qwen_32b/eval.yaml",
      "config_type": "evaluation",
      "model_family": "qwen",
      "model_size_billions": 32.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-distill-qwen-32b-lora": {
      "alias": "deepseek-r1-distill-qwen-32b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/deepseek_r1/sft/distill_qwen_32b/lora_train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 32.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "deepseek-r1-671b": {
      "alias": "deepseek-r1-671b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/deepseek_r1/inference/671b_together/infer.yaml",
      "config_type": "inference",
      "model_family": "deepseek",
      "model_size_billions": 671.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-8b:train": {
      "alias": "llama3.1-8b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/8b_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-8b:infer": {
      "alias": "llama3.1-8b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/llama3_1/inference/8b_infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-8b:eval": {
      "alias": "llama3.1-8b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/llama3_1/evaluation/8b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-8b-lora": {
      "alias": "llama3.1-8b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/8b_lora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-8b-qlora": {
      "alias": "llama3.1-8b-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/8b_qlora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 8.0,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-70b:train": {
      "alias": "llama3.1-70b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/70b_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-70b:infer": {
      "alias": "llama3.1-70b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/llama3_1/inference/70b_infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-70b:eval": {
      "alias": "llama3.1-70b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/llama3_1/evaluation/70b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-70b-lora": {
      "alias": "llama3.1-70b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/70b_lora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-70b-qlora": {
      "alias": "llama3.1-70b-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/70b_qlora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-405b": {
      "alias": "llama3.1-405b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/405b_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 405.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-405b-lora": {
      "alias": "llama3.1-405b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/405b_lora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 405.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.1-405b-qlora": {
      "alias": "llama3.1-405b-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_1/sft/405b_qlora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 405.0,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-1b:train": {
      "alias": "llama3.2-1b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_2/sft/1b_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 1.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-1b:infer": {
      "alias": "llama3.2-1b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/llama3_2/inference/1b_infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 1.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-1b:eval": {
      "alias": "llama3.2-1b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/llama3_2/evaluation/1b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 1.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-3b:train": {
      "alias": "llama3.2-3b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_2/sft/3b_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-3b:infer": {
      "alias": "llama3.2-3b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/llama3_2/inference/3b_infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-3b:eval": {
      "alias": "llama3.2-3b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/llama3_2/evaluation/3b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-3b-lora": {
      "alias": "llama3.2-3b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_2/sft/3b_lora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-3b-qlora": {
      "alias": "llama3.2-3b-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_2/sft/3b_qlora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.3-70b:train": {
      "alias": "llama3.3-70b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_3/sft/70b_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.3-70b:infer": {
      "alias": "llama3.3-70b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/llama3_3/inference/70b_infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.3-70b:eval": {
      "alias": "llama3.3-70b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/llama3_3/evaluation/70b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.3-70b-lora": {
      "alias": "llama3.3-70b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_3/sft/70b_lora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.3-70b-qlora": {
      "alias": "llama3.3-70b-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/llama3_3/sft/70b_qlora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwq-32b:train": {
      "alias": "qwq-32b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/qwq/sft/full_train.yaml",
      "config_type": "training",
      "model_family": null,
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwq-32b:infer": {
      "alias": "qwq-32b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/qwq/inference/infer.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwq-32b:eval": {
      "alias": "qwq-32b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/qwq/evaluation/eval.yaml",
      "config_type": "evaluation",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwq-32b-lora": {
      "alias": "qwq-32b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/qwq/sft/lora_train.yaml",
      "config_type": "training",
      "model_family": null,
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "qwq-32b-qlora": {
      "alias": "qwq-32b-qlora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/qwq/sft/qlora_train.yaml",
      "config_type": "training",
      "model_family": null,
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "qlora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "smollm-135m:train": {
      "alias": "smollm-135m",
      "alias_type": "train",
      "path": "oumi://configs/recipes/smollm/sft/135m/train.yaml",
      "config_type": "training",
      "model_family": "smollm",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "smollm-135m:infer": {
      "alias": "smollm-135m",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/smollm/inference/135m_infer.yaml",
      "config_type": "inference",
      "model_family": "smollm",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "smollm-135m:eval": {
      "alias": "smollm-135m",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/smollm/evaluation/135m/eval.yaml",
      "config_type": "evaluation",
      "model_family": "smollm",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "smollm-135m:tune": {
      "alias": "smollm-135m",
      "alias_type": "tune",
      "path": "oumi://configs/recipes/smollm/tuning/135m/tune.yaml",
      "config_type": "training",
      "model_family": "smollm",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt2:train": {
      "alias": "gpt2",
      "alias_type": "train",
      "path": "oumi://configs/recipes/gpt2/pretraining/train.yaml",
      "config_type": "training",
      "model_family": "gpt2",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt2:infer": {
      "alias": "gpt2",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/gpt2/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "gpt2",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-oss-20b": {
      "alias": "gpt-oss-20b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/gpt_oss/inference/20b_infer.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": 20.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-oss-20b-lora": {
      "alias": "gpt-oss-20b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/gpt_oss/sft/20b_lora_single_gpu_train.yaml",
      "config_type": "training",
      "model_family": null,
      "model_size_billions": 20.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-oss-120b": {
      "alias": "gpt-oss-120b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/gpt_oss/inference/120b_infer.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": 120.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama3.2-vision-11b:train": {
      "alias": "llama3.2-vision-11b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/llama3_2_vision/sft/11b_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 11.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "llama3.2-vision-11b:infer": {
      "alias": "llama3.2-vision-11b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/llama3_2_vision/inference/11b_infer.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 11.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "llama3.2-vision-11b:eval": {
      "alias": "llama3.2-vision-11b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/vision/llama3_2_vision/evaluation/11b_eval.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 11.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "llama3.2-vision-11b-lora": {
      "alias": "llama3.2-vision-11b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/llama3_2_vision/sft/11b_lora/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 11.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "llama3.2-vision-90b": {
      "alias": "llama3.2-vision-90b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/llama3_2_vision/sft/90b_full/train.yaml",
      "config_type": "training",
      "model_family": "llama",
      "model_size_billions": 90.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "llava-7b:train": {
      "alias": "llava-7b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/llava_7b/sft/train.yaml",
      "config_type": "training",
      "model_family": "llava",
      "model_size_billions": 7.0,
      "training_method": "sft",
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "llava-7b:infer": {
      "alias": "llava-7b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/llava_7b/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "llava",
      "model_size_billions": 7.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "phi3-vision": {
      "alias": "phi3-vision",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/phi3/sft/full/train.yaml",
      "config_type": "training",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "phi3-vision-lora": {
      "alias": "phi3-vision-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/phi3/sft/lora/train.yaml",
      "config_type": "training",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "phi4-vision:train": {
      "alias": "phi4-vision",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/phi4/sft/full/train.yaml",
      "config_type": "training",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "phi4-vision:infer": {
      "alias": "phi4-vision",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/phi4/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "phi4-vision-lora": {
      "alias": "phi4-vision-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/phi4/sft/lora/train.yaml",
      "config_type": "training",
      "model_family": "phi",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen2-vl-2b:train": {
      "alias": "qwen2-vl-2b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/qwen2_vl_2b/sft/full/train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 2.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen2-vl-2b:infer": {
      "alias": "qwen2-vl-2b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/qwen2_vl_2b/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 2.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen2-vl-2b:eval": {
      "alias": "qwen2-vl-2b",
      "alias_type": "eval",
      "path": "oumi://configs/recipes/vision/qwen2_vl_2b/evaluation/eval.yaml",
      "config_type": "evaluation",
      "model_family": "qwen",
      "model_size_billions": 2.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen2-vl-2b-lora": {
      "alias": "qwen2-vl-2b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/qwen2_vl_2b/sft/lora/train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 2.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen2.5-vl-3b:train": {
      "alias": "qwen2.5-vl-3b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/qwen2_5_vl_3b/sft/full/train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen2.5-vl-3b:infer": {
      "alias": "qwen2.5-vl-3b",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/qwen2_5_vl_3b/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "qwen",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen2.5-vl-3b-lora": {
      "alias": "qwen2.5-vl-3b-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/qwen2_5_vl_3b/sft/lora/train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 3.0,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "qwen2.5-vl-7b": {
      "alias": "qwen2.5-vl-7b",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/qwen2_5_vl_7b/sft/full/train.yaml",
      "config_type": "training",
      "model_family": "qwen",
      "model_size_billions": 7.0,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "smolvlm:train": {
      "alias": "smolvlm",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/smolvlm/sft/full/train.yaml",
      "config_type": "training",
      "model_family": "smollm",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "smolvlm:infer": {
      "alias": "smolvlm",
      "alias_type": "infer",
      "path": "oumi://configs/recipes/vision/smolvlm/inference/infer.yaml",
      "config_type": "inference",
      "model_family": "smollm",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "smolvlm-lora": {
      "alias": "smolvlm-lora",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/smolvlm/sft/lora/train.yaml",
      "config_type": "training",
      "model_family": "smollm",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "lora",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "internvl3": {
      "alias": "internvl3",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/internvl3/sft/full/train.yaml",
      "config_type": "training",
      "model_family": "internvl",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "claude-3-5-sonnet:infer": {
      "alias": "claude-3-5-sonnet",
      "alias_type": "infer",
      "path": "oumi://configs/apis/anthropic/infer_claude_3_5_sonnet.yaml",
      "config_type": "inference",
      "model_family": "anthropic",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "claude-3-5-sonnet:eval": {
      "alias": "claude-3-5-sonnet",
      "alias_type": "eval",
      "path": "oumi://configs/apis/anthropic/eval_claude_3_5_sonnet.yaml",
      "config_type": "evaluation",
      "model_family": "anthropic",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "claude-3-7-sonnet:infer": {
      "alias": "claude-3-7-sonnet",
      "alias_type": "infer",
      "path": "oumi://configs/apis/anthropic/infer_claude_3_7_sonnet.yaml",
      "config_type": "inference",
      "model_family": "anthropic",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "claude-3-7-sonnet:eval": {
      "alias": "claude-3-7-sonnet",
      "alias_type": "eval",
      "path": "oumi://configs/apis/anthropic/eval_claude_3_7_sonnet.yaml",
      "config_type": "evaluation",
      "model_family": "anthropic",
      "model_size_billions": 3.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "claude-opus-4-1": {
      "alias": "claude-opus-4-1",
      "alias_type": "infer",
      "path": "oumi://configs/apis/anthropic/infer_claude_opus_4_1.yaml",
      "config_type": "inference",
      "model_family": "anthropic",
      "model_size_billions": 4.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemini-1-5-pro:infer": {
      "alias": "gemini-1-5-pro",
      "alias_type": "infer",
      "path": "oumi://configs/apis/gemini/infer_gemini_1_5_pro.yaml",
      "config_type": "inference",
      "model_family": "google",
      "model_size_billions": 1.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemini-1-5-pro:eval": {
      "alias": "gemini-1-5-pro",
      "alias_type": "eval",
      "path": "oumi://configs/apis/gemini/eval_gemini_1_5_pro.yaml",
      "config_type": "evaluation",
      "model_family": "google",
      "model_size_billions": 1.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gemini-2-5-pro": {
      "alias": "gemini-2-5-pro",
      "alias_type": "infer",
      "path": "oumi://configs/apis/gemini/infer_gemini_2_5_pro.yaml",
      "config_type": "inference",
      "model_family": "google",
      "model_size_billions": 2.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-4o:infer": {
      "alias": "gpt-4o",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_4o.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-4o:eval": {
      "alias": "gpt-4o",
      "alias_type": "eval",
      "path": "oumi://configs/apis/openai/eval_gpt_4o.yaml",
      "config_type": "evaluation",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-4o-mini": {
      "alias": "gpt-4o-mini",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_4o_mini.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "chatgpt-4o-latest": {
      "alias": "chatgpt-4o-latest",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_chatgpt_4o_latest.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-4-1": {
      "alias": "gpt-4-1",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_4_1.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": 4.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-4-1-mini": {
      "alias": "gpt-4-1-mini",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_4_1_mini.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": 4.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-5": {
      "alias": "gpt-5",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_5.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-5-mini": {
      "alias": "gpt-5-mini",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_5_mini.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-5-nano": {
      "alias": "gpt-5-nano",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_5_nano.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-5-chat-latest": {
      "alias": "gpt-5-chat-latest",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_5_chat_latest.yaml",
      "config_type": "inference",
      "model_family": null,
      "model_size_billions": 5.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-o1-preview:infer": {
      "alias": "gpt-o1-preview",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_gpt_o1_preview.yaml",
      "config_type": "inference",
      "model_family": "openai",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "gpt-o1-preview:eval": {
      "alias": "gpt-o1-preview",
      "alias_type": "eval",
      "path": "oumi://configs/apis/openai/eval_gpt_o1_preview.yaml",
      "config_type": "evaluation",
      "model_family": "openai",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "o1": {
      "alias": "o1",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_o1.yaml",
      "config_type": "inference",
      "model_family": "openai",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "o1-mini": {
      "alias": "o1-mini",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_o1_mini.yaml",
      "config_type": "inference",
      "model_family": "openai",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "o3-mini": {
      "alias": "o3-mini",
      "alias_type": "infer",
      "path": "oumi://configs/apis/openai/infer_o3_mini.yaml",
      "config_type": "inference",
      "model_family": "openai",
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama-3-3-70b:infer": {
      "alias": "llama-3-3-70b",
      "alias_type": "infer",
      "path": "oumi://configs/apis/vertex/infer_llama_3_3_70b.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama-3-3-70b:eval": {
      "alias": "llama-3-3-70b",
      "alias_type": "eval",
      "path": "oumi://configs/apis/vertex/eval_llama_3_3_70b.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 70.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama-3-1-405b:infer": {
      "alias": "llama-3-1-405b",
      "alias_type": "infer",
      "path": "oumi://configs/apis/vertex/infer_llama_3_1_405b.yaml",
      "config_type": "inference",
      "model_family": "llama",
      "model_size_billions": 405.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "llama-3-1-405b:eval": {
      "alias": "llama-3-1-405b",
      "alias_type": "eval",
      "path": "oumi://configs/apis/vertex/eval_llama_3_1_405b.yaml",
      "config_type": "evaluation",
      "model_family": "llama",
      "model_size_billions": 405.0,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "molmo-7b-o": {
      "alias": "molmo-7b-o",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/molmo/sft/molmo_o_full/train.yaml",
      "config_type": "training",
      "model_family": "olmo",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "molmo-7b-d": {
      "alias": "molmo-7b-d",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/molmo/sft/molmo_d_full/train.yaml",
      "config_type": "training",
      "model_family": "olmo",
      "model_size_billions": null,
      "training_method": "sft",
      "finetuning_type": "full",
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "molmo-7b-o-grpo": {
      "alias": "molmo-7b-o-grpo",
      "alias_type": "train",
      "path": "oumi://configs/recipes/vision/molmo/grpo/train.yaml",
      "config_type": "training",
      "model_family": "olmo",
      "model_size_billions": null,
      "training_method": "grpo",
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": true,
      "tags": [],
      "description": null
    },
    "format-compliance": {
      "alias": "format-compliance",
      "alias_type": "judge",
      "path": "oumi://configs/projects/judges/generic/format_compliance.yaml",
      "config_type": "judge",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "instruction-following": {
      "alias": "instruction-following",
      "alias_type": "judge",
      "path": "oumi://configs/projects/judges/generic/instruction_following.yaml",
      "config_type": "judge",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "topic-adherence": {
      "alias": "topic-adherence",
      "alias_type": "judge",
      "path": "oumi://configs/projects/judges/generic/topic_adherence.yaml",
      "config_type": "judge",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "truthfulness": {
      "alias": "truthfulness",
      "alias_type": "judge",
      "path": "oumi://configs/projects/judges/generic/truthfulness.yaml",
      "config_type": "judge",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    },
    "safety": {
      "alias": "safety",
      "alias_type": "judge",
      "path": "oumi://configs/projects/judges/generic/safety.yaml",
      "config_type": "judge",
      "model_family": null,
      "model_size_billions": null,
      "training_method": null,
      "finetuning_type": null,
      "min_vram_gb": null,
      "recommended_gpus": null,
      "is_vision_model": false,
      "tags": [],
      "description": null
    }
  }
}