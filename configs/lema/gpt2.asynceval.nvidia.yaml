evaluation:
  evaluation_framework: "LM_HARNESS"
  output_dir: "" # "/output_dir_gcs/matthew/gpt2.pt.4xA10080GB.5000steps/hellaswag/"
  model:
    model_name: "gpt2"  # 124M params
    # For local testing.
    # model_max_length: 128
    model_max_length: 1024
    torch_dtype_str: "bfloat16"
    attn_implementation: "flash_attention_2"
    trust_remote_code: True

  data:
    datasets:
      - dataset_name: "hellaswag"
      #  - dataset_name: "mmlu"

  generation:
    batch_size: 32

checkpoints_dir: "" # "/output_dir_gcs/nikolai/runs/gpt2.pt.4xA10080GB.5000steps/"
polling_interval: 5
