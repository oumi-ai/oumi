# Task evaluation config for NL2SQL (Natural Language to SQL).
#
# Metrics: Edit Distance / Similarity, Exact Match
#
# NOTE: The test data needs ground truth SQL in the assistant turn.
# If empty, re-run prepare_datasets.py or get properly formatted data.
#
# Usage:
#   # Evaluate baseline model
#   oumi evaluate -c configs/enterprise/evaluation/task_nl2sql.yaml \
#     --model.model_name "Qwen/Qwen3-4B-Instruct"
#
#   # Evaluate fine-tuned model
#   oumi evaluate -c configs/enterprise/evaluation/task_nl2sql.yaml \
#     --model.model_name "output/enterprise/qwen3_4b_nl2sql/best_checkpoint"
#
# See Also:
#   - Documentation: https://oumi.ai/docs/en/latest/user_guides/evaluate/evaluate.html
#   - Config class: oumi.core.configs.EvaluationConfig

model:
  model_name: "Qwen/Qwen3-4B-Instruct"  # Override via CLI
  model_max_length: 8192
  torch_dtype_str: "bfloat16"
  attn_implementation: "sdpa"
  trust_remote_code: true
  tokenizer_kwargs:
    padding_side: "left"  # Required for batch inference with decoder-only models

generation:
  batch_size: 4  # inert when using vLLM
  max_new_tokens: 512  # SQL can be long
  temperature: 0.0

tasks:
  - evaluation_backend: custom
    task_name: enterprise_nl2sql
    eval_kwargs:
      test_data_path: data/enterprise/nl2sql/test.jsonl

inference_engine: VLLM
enable_wandb: true

output_dir: "output/enterprise/evaluation/nl2sql"
