{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334e3fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS has been disabled - forcing CPU-only mode\n",
      "PyTorch device: cpu\n",
      "PyTorch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# IMPORTANT: Set these BEFORE importing torch or any ML libraries\n",
    "# Disable all GPU/MPS backends to prevent crashes with IFD analyzer\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Disable CUDA\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # Disable MPS memory allocation\n",
    "os.environ[\"DISABLE_MPS_COMPAT\"] = \"1\"  # Additional MPS disable flag\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"  # Disable HuggingFace telemetry\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Allow model downloads\n",
    "\n",
    "# Force CPU usage in PyTorch to avoid MPS crashes\n",
    "import torch\n",
    "\n",
    "# Forcefully disable MPS before anything else\n",
    "torch.set_default_device(\"cpu\")\n",
    "if hasattr(torch.backends, \"mps\"):\n",
    "    # Monkey-patch to prevent MPS usage\n",
    "    original_is_available = torch.backends.mps.is_available\n",
    "    torch.backends.mps.is_available = lambda: False\n",
    "    print(\"MPS has been disabled - forcing CPU-only mode\")\n",
    "else:\n",
    "    print(\"Using CPU for all computations\")\n",
    "\n",
    "print(f\"PyTorch device: {torch.get_default_device()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430925a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 18 analyzers: ['length', 'diversity', 'format', 'quality', 'training_quality', 'cost', 'content_pattern', 'question_diversity', 'fasttext', 'ifd', 'repr_diversity', 'task_category', 'safety', 'difficulty', 'instruct_reward', 'input_quality', 'conversation_structure', 'response_completeness']\n",
      "[2025-12-30 10:42:58,644][oumi][rank0][pid:36804][MainThread][INFO]][base_map_dataset.py:91] Creating map dataset (type: TextSftJsonLinesDataset)... dataset_name: 'custom'\n",
      "[2025-12-30 10:42:58,645][oumi.utils.analysis_utils][rank0][pid:36804][MainThread][INFO]][analysis_utils.py:225] Loaded text dataset from: /Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\n",
      "[2025-12-30 10:42:58,645][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:154] Loaded dataset from config: None\n",
      "[2025-12-30 10:42:58,766][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: length\n",
      "[2025-12-30 10:42:58,767][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: diversity\n",
      "[2025-12-30 10:42:58,767][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: format\n",
      "[2025-12-30 10:42:58,767][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: quality\n",
      "[2025-12-30 10:42:58,768][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: training_quality\n",
      "[2025-12-30 10:42:58,769][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: cost\n",
      "[2025-12-30 10:42:58,769][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: content_pattern\n",
      "[2025-12-30 10:42:58,783][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: question_diversity\n",
      "[2025-12-30 10:42:58,783][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: fasttext\n",
      "[2025-12-30 10:42:58,784][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: ifd\n",
      "[2025-12-30 10:42:58,784][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: repr_diversity\n",
      "[2025-12-30 10:42:58,784][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: task_category\n",
      "[2025-12-30 10:42:58,785][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: safety\n",
      "[2025-12-30 10:42:58,785][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: difficulty\n",
      "[2025-12-30 10:42:58,786][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: instruct_reward\n",
      "[2025-12-30 10:42:58,786][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: input_quality\n",
      "[2025-12-30 10:42:58,787][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: conversation_structure\n",
      "[2025-12-30 10:42:58,787][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: response_completeness\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from oumi.core.configs import AnalyzeConfig\n",
    "from oumi.core.analyze.dataset_analyzer import DatasetAnalyzer\n",
    "\n",
    "# Path to the config file\n",
    "config_path = \"/Users/ryanarman/code/oumi/configs/examples/analyze/analyze.yaml\"\n",
    "\n",
    "# Path to your dataset file\n",
    "dataset_path = \"/Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\"\n",
    "\n",
    "# Load the config from YAML\n",
    "config = AnalyzeConfig.from_yaml(\n",
    "    config_path=config_path,\n",
    ")\n",
    "\n",
    "config.sample_count = 10\n",
    "\n",
    "# Override the dataset settings to use your local file\n",
    "config.dataset_path = dataset_path\n",
    "config.dataset_name = None  # Clear dataset_name so it uses dataset_path instead\n",
    "\n",
    "# Optionally update output path\n",
    "config.output_path = \"./analysis_output/banking77\"\n",
    "\n",
    "# IMPORTANT: Disable analyzers that require large model downloads or have issues\n",
    "# IFD requires downloading Qwen model and may cause MPS crashes\n",
    "# fasttext requires additional dependencies\n",
    "# repr_diversity and question_diversity download embedding models\n",
    "print(f\"Running {len(config.analyzers)} analyzers: {[a.id for a in config.analyzers]}\")\n",
    "\n",
    "# Validate the configuration\n",
    "config.finalize_and_validate()\n",
    "\n",
    "# Create the analyzer\n",
    "analyzer = DatasetAnalyzer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0ca499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 10:42:58,798][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:347] Starting analysis of dataset: None\n",
      "[2025-12-30 10:42:58,799][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:348] Using 18 sample analyzers: ['length', 'diversity', 'format', 'quality', 'training_quality', 'cost', 'content_pattern', 'question_diversity', 'fasttext', 'ifd', 'repr_diversity', 'task_category', 'safety', 'difficulty', 'instruct_reward', 'input_quality', 'conversation_structure', 'response_completeness']\n",
      "[2025-12-30 10:42:58,800][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:371] Analyzing 10 of 8002 conversations\n",
      "[2025-12-30 10:42:58,800][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:421] Converting conversation dataset with 8002 items\n",
      "[2025-12-30 10:42:58,801][oumi][rank0][pid:36804][MainThread][INFO]][dataset_analyzer.py:428] Limiting analysis to first 10 items (dataset has 8002 total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Unknown Dataset to DataFrames: 100%|██████████| 10/10 [00:00<00:00, 1885.67item/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 10:42:58,852][oumi][rank0][pid:36804][MainThread][INFO]][question_diversity_analyzer.py:464] Computing embeddings for 10 user questions...\n",
      "[2025-12-30 10:42:58,853][oumi][rank0][pid:36804][MainThread][INFO]][question_diversity_analyzer.py:174] Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 95.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 10:43:00,056][oumi][rank0][pid:36804][MainThread][INFO]][question_diversity_analyzer.py:469] Clustering 10 questions using dbscan...\n",
      "[2025-12-30 10:43:00,270][oumi][rank0][pid:36804][MainThread][INFO]][question_diversity_analyzer.py:487] Found 1 clusters\n",
      "[2025-12-30 10:43:00,286][oumi][rank0][pid:36804][MainThread][INFO]][fasttext_analyzer.py:220] Initialized fast-langdetect for language detection\n",
      "[2025-12-30 10:43:00,288][oumi][rank0][pid:36804][MainThread][INFO]][fasttext_analyzer.py:436] Analyzing language for column: conversation_text_content\n",
      "[2025-12-30 10:43:00,428][oumi][rank0][pid:36804][MainThread][INFO]][ifd_analyzer.py:154] Loading model for IFD analysis: Qwen/Qwen3-0.6B\n",
      "[2025-12-30 10:43:01,670][oumi][rank0][pid:36804][MainThread][INFO]][ifd_analyzer.py:193] Loaded Qwen/Qwen3-0.6B on cpu (dtype: torch.float32)\n",
      "[2025-12-30 10:43:01,671][oumi][rank0][pid:36804][MainThread][INFO]][ifd_analyzer.py:664] Computing IFD scores using instruction='conversation_text_content__question_diversity__cluster_id', response='conversation_text_content__training_quality__response_completeness_score'\n",
      "[2025-12-30 10:43:03,444][oumi][rank0][pid:36804][MainThread][INFO]][ifd_analyzer.py:677] IFD analysis complete. Mean IFD: inf, Min: inf, Max: inf\n",
      "[2025-12-30 10:43:03,445][oumi][rank0][pid:36804][MainThread][INFO]][repr_diversity_analyzer.py:363] Computing diversity scores for 10 samples in column 'conversation_text_content'...\n",
      "[2025-12-30 10:43:03,446][oumi][rank0][pid:36804][MainThread][INFO]][repr_diversity_analyzer.py:165] Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 112.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 10:43:04,574][oumi][rank0][pid:36804][MainThread][INFO]][repr_diversity_analyzer.py:230] Computing nearest neighbor distances for 10 samples (k=5)...\n",
      "[2025-12-30 10:43:04,576][oumi][rank0][pid:36804][MainThread][INFO]][repr_diversity_analyzer.py:556] Column 'conversation_text_content': 10/10 samples (100.0%) are redundant\n",
      "[2025-12-30 10:43:04,719][oumi][rank0][pid:36804][MainThread][INFO]][question_diversity_analyzer.py:464] Computing embeddings for 10 user questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 764.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 10:43:04,735][oumi][rank0][pid:36804][MainThread][INFO]][question_diversity_analyzer.py:469] Clustering 10 questions using dbscan...\n",
      "[2025-12-30 10:43:04,738][oumi][rank0][pid:36804][MainThread][INFO]][question_diversity_analyzer.py:482] Found 0 clusters, 10 unique/diverse questions (not similar to others)\n",
      "[2025-12-30 10:43:04,739][oumi][rank0][pid:36804][MainThread][INFO]][fasttext_analyzer.py:436] Analyzing language for column: text_content\n",
      "[2025-12-30 10:43:04,747][oumi][rank0][pid:36804][MainThread][INFO]][ifd_analyzer.py:643] Detected conversation format. Computing IFD for assistant messages using preceding user messages as instructions.\n",
      "[2025-12-30 10:43:06,884][oumi][rank0][pid:36804][MainThread][INFO]][ifd_analyzer.py:521] IFD analysis complete. Processed 10 assistant messages out of 10 total.\n",
      "[2025-12-30 10:43:06,885][oumi][rank0][pid:36804][MainThread][INFO]][repr_diversity_analyzer.py:363] Computing diversity scores for 30 samples in column 'text_content'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 30/30 [00:00<00:00, 170.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 10:43:07,063][oumi][rank0][pid:36804][MainThread][INFO]][repr_diversity_analyzer.py:230] Computing nearest neighbor distances for 30 samples (k=5)...\n",
      "[2025-12-30 10:43:07,066][oumi][rank0][pid:36804][MainThread][INFO]][repr_diversity_analyzer.py:556] Column 'text_content': 19/30 samples (63.3%) are redundant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanarman/miniconda3/envs/oumi/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/ryanarman/miniconda3/envs/oumi/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total conversations analyzed: 10\n"
     ]
    }
   ],
   "source": [
    "# Run the analysis\n",
    "analyzer.analyze_dataset()\n",
    "\n",
    "# The results are stored in analyzer object\n",
    "if analyzer._analysis_results:\n",
    "    print(\n",
    "        f\"Total conversations analyzed: {analyzer._analysis_results.conversations_analyzed}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a07ae1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(schema): 184\n",
      "len(merged_columns): 184\n"
     ]
    }
   ],
   "source": [
    "schema = analyzer.get_schema()\n",
    "print(f\"len(schema): {len(schema)}\")\n",
    "merged_columns = analyzer.analysis_df.columns\n",
    "print(f\"len(merged_columns): {len(merged_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c2ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer.analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ee896",
   "metadata": {},
   "source": [
    "# Conv level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e34d4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: conversation_text_content__question_diversity__is_concentrated\n",
      "schema[col]: {'type': <ColumnType.BOOL: 'bool'>, 'content_type': <ContentType.BOOLEAN: 'boolean'>, 'description': 'Whether question is in a concentrated cluster (>threshold)'}\n",
      "row[col]: True\n"
     ]
    }
   ],
   "source": [
    "conv_columns = analyzer.conversation_df.columns\n",
    "row = analyzer.conversation_df.iloc[0]\n",
    "col = conv_columns[44]\n",
    "print(f\"col: {col}\")\n",
    "print(f\"schema[col]: {schema[col]}\")\n",
    "print(f\"row[col]: {row[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d56f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer: training_quality\n",
      "\n",
      "Input:\n",
      "SYSTEM: You are a banking intent classifier. Classify the user's query into one of  77 banking intents (output is a single integer ID).\n",
      "\n",
      "IDs:\n",
      "\n",
      "0: activate_my_card\n",
      "1: age_limit\n",
      "2: apple_pay_or_google_pay\n",
      "3: atm_support\n",
      "4: automatic_top_up\n",
      "5: balance_not_updated_after_bank_transfer\n",
      "6: balance_not_updated_after_cheque_or_cash_deposit\n",
      "7: beneficiary_not_allowed\n",
      "8: cancel_transfer\n",
      "9: card_about_to_expire\n",
      "10: card_acceptance\n",
      "11: card_arrival\n",
      "12: card_delivery_estimate\n",
      "13: card_linking\n",
      "14: card_not_working\n",
      "15: card_payment_fee_charged\n",
      "16: card_payment_not_recognised\n",
      "17: card_payment_wrong_exchange_rate\n",
      "18: card_swallowed\n",
      "19: cash_withdrawal_charge\n",
      "20: cash_withdrawal_not_recognised\n",
      "21: change_pin\n",
      "22: compromised_card\n",
      "23: contactless_not_working\n",
      "24: country_support\n",
      "25: declined_card_payment\n",
      "26: declined_cash_withdrawal\n",
      "27: declined_transfer\n",
      "28: direct_debit_payment_not_recognised\n",
      "29: disposable_card_limits\n",
      "30: edit_personal_details\n",
      "31: exchange_charge\n",
      "32: exchange_rate\n",
      "33: exchange_via_app\n",
      "34: extra_charge_on_statement\n",
      "35: failed_transfer\n",
      "36: fiat_currency_support\n",
      "37: get_disposable_virtual_card\n",
      "38: get_physical_card\n",
      "39: getting_spare_card\n",
      "40: getting_virtual_card\n",
      "41: lost_or_stolen_card\n",
      "42: lost_or_stolen_phone\n",
      "43: order_physical_card\n",
      "44: passcode_forgotten\n",
      "45: pending_card_payment\n",
      "46: pending_cash_withdrawal\n",
      "47: pending_top_up\n",
      "48: pending_transfer\n",
      "49: pin_blocked\n",
      "50: receiving_money\n",
      "51: Refund_not_showing_up\n",
      "52: request_refund\n",
      "53: reverted_card_payment?\n",
      "54: supported_cards_and_currencies\n",
      "55: terminate_account\n",
      "56: top_up_by_bank_transfer_charge\n",
      "57: top_up_by_card_charge\n",
      "58: top_up_by_cash_or_cheque\n",
      "59: top_up_failed\n",
      "60: top_up_limits\n",
      "61: top_up_reverted\n",
      "62: topping_up_by_card\n",
      "63: transaction_charged_twice\n",
      "64: transfer_fee_charged\n",
      "65: transfer_into_account\n",
      "66: transfer_not_received_by_recipient\n",
      "67: transfer_timing\n",
      "68: unable_to_verify_identity\n",
      "69: verify_my_identity\n",
      "70: verify_source_of_funds\n",
      "71: verify_top_up\n",
      "72: virtual_card_not_working\n",
      "73: visa_or_mastercard\n",
      "74: why_verify_identity\n",
      "75: wrong_amount_of_cash_received\n",
      "76: wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "CRITICAL INSTRUCTIONS:\n",
      "1. Choose exactly one integer ID (0-76).\n",
      "2. Reply with ONLY that number. No words, no reasoning, no punctuation.\n",
      "Examples: 0, 1, 42\n",
      "\n",
      "EXAMPLES TO HELP DISTINGUISH SIMILAR INTENTS:\n",
      "EXAMPLES TO HELP DISTINGUISH SIMILAR INTENTS:\n",
      "\n",
      "1. card_arrival (ID 11) vs card_delivery_estimate (ID 12):\n",
      "   card_arrival = asking about YOUR specific card that hasn't arrived yet (tracking, status)\n",
      "   card_delivery_estimate = asking about general delivery timeframes/how long it takes\n",
      "   - Query: \"Could you send me and up date on the arrival of my card?\" → 11\n",
      "   - Query: \"My card was supposed to arrive, but hasn't?\" → 11\n",
      "   - Query: \"I have not received my card and it's been a week, what do I do?\" → 11\n",
      "   - Query: \"can you express my card to me?\" → 12\n",
      "   - Query: \"Can I choose the day it's delivered?\" → 12\n",
      "   - Query: \"i need to add express delivery if that's an option\" → 12\n",
      "\n",
      "2. card_linking (ID 13) vs activate_my_card (ID 0) vs lost_or_stolen_card (ID 41):\n",
      "   card_linking = reconnecting a card you found/retrieved\n",
      "   activate_my_card = activating a NEW card for first time\n",
      "   lost_or_stolen_card = reporting a card as lost/stolen\n",
      "   - Query: \"Okay, I found my card, can I put it back in the app?\" → 13\n",
      "   - Query: \"I want to reactivate my card, I thought I had lost it but I found it.\" → 13\n",
      "   - Query: \"What do I need to do for the card activation?\" → 0\n",
      "   - Query: \"Tell me what I need to do to activate my card.\" → 0\n",
      "   - Query: \"I left my card at a restaurant and now its missing.\" → 41\n",
      "   - Query: \"Who can I speak with regarding a lost card?\" → 41\n",
      "\n",
      "3. pin_blocked (ID 49) vs change_pin (ID 21):\n",
      "   pin_blocked = PIN is locked/blocked, need to unlock\n",
      "   change_pin = want to change PIN to a new one\n",
      "   - Query: \"How many times can I enter a wrong PIN before it is blocked?\" → 49\n",
      "   - Query: \"I entered in the wrong PIN.  Please help me unlock my account.\" → 49\n",
      "   - Query: \"Where do I need to go to change my PIN?\" → 21\n",
      "   - Query: \"I really need to know how to change my pin.\" → 21\n",
      "\n",
      "4. pending_cash_withdrawal (ID 46) vs declined_cash_withdrawal (ID 26) vs cash_withdrawal_not_recognised (ID 20):\n",
      "   pending_cash_withdrawal = withdrawal is processing/pending\n",
      "   declined_cash_withdrawal = withdrawal was rejected/declined\n",
      "   cash_withdrawal_not_recognised = withdrawal not showing in account\n",
      "   - Query: \"I tried to get cash at some ATM in the city centre earlier but the machine declined my card. I've seen it still shows up as pending in my account. Please cancel it immediately as I definitely have not received that money!\" → 46\n",
      "   - Query: \"I attempted to get cash in the ATM but it was not authorized\" → 26\n",
      "   - Query: \"My app says I withdraw money from my account from an ATM.\" → 20\n",
      "\n",
      "5. verify_my_identity (ID 69) vs why_verify_identity (ID 74) vs unable_to_verify_identity (ID 68):\n",
      "   verify_my_identity = want to verify/complete verification\n",
      "   why_verify_identity = asking why verification is needed\n",
      "   unable_to_verify_identity = having trouble completing verification\n",
      "   - Query: \"If I'm getting my identity verified, what all do I need?\" → 69\n",
      "   - Query: \"I do not feel comfortable verifying my identity.\" → 74\n",
      "   - Query: \"My identity wasn't verified\" → 68\n",
      "\n",
      "6. card_payment_wrong_exchange_rate (ID 17) vs wrong_exchange_rate_for_cash_withdrawal (ID 76) vs exchange_rate (ID 32):\n",
      "   card_payment_wrong_exchange_rate = wrong rate used for CARD payment\n",
      "   wrong_exchange_rate_for_cash_withdrawal = wrong rate used for CASH withdrawal\n",
      "   exchange_rate = asking about current/general exchange rates\n",
      "   - Query: \"I seem to have been charged to much for my holiday purchases, the exchange rate is wrong.\" → 17\n",
      "   - Query: \"The exchange rate for foreign ATM currency is wrong.\" → 76\n",
      "   - Query: \"How did you guys get your exchange rate?\" → 32\n",
      "\n",
      "7. extra_charge_on_statement (ID 34) vs card_payment_fee_charged (ID 15):\n",
      "   extra_charge_on_statement = unexpected charge on statement\n",
      "   card_payment_fee_charged = fee charged for card payment\n",
      "   - Query: \"I was overcharged one extra pound!\" → 34\n",
      "   - Query: \"There was an extra fee when I paid with my card, why was i charged this extra fee?\" → 15\n",
      "\n",
      "8. getting_virtual_card (ID 40):\n",
      "   - Query: \"Where do I have access to a virtual card?\" → 40\n",
      "   - Query: \"How can I receive a virtual card?\" → 40\n",
      "\n",
      "\n",
      "Remember: Respond with ONLY the numeric ID, nothing else.\n",
      "USER: If I bought something I didn't like, can I get a refund?\n",
      "ASSISTANT: 52\n",
      "\n",
      "metric: response_completeness_score\n",
      "description: Response completeness score (0.0 = incomplete, 1.0 = complete)\n",
      "value: None\n",
      "\n",
      "\n",
      "metric: response_completeness_score\n",
      "description: Whether response has proper sentence ending\n",
      "value: None\n",
      "\n",
      "\n",
      "metric: response_completeness_score\n",
      "description: Whether response has clear structure\n",
      "value: None\n",
      "\n",
      "\n",
      "metric: response_completeness_score\n",
      "description: Word count of response\n",
      "value: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.analyze.column_utils import (\n",
    "    filter_analyzer_columns,\n",
    "    get_analyzer_columns_by_analyzer,\n",
    "    parse_analyzer_column_name,\n",
    ")\n",
    "\n",
    "analyzer_names = [a.id for a in config.analyzers]\n",
    "conv_columns = analyzer.conversation_df.columns\n",
    "row = analyzer.conversation_df.iloc[0]\n",
    "\n",
    "# Then use it directly\n",
    "analyzer_name = analyzer_names[4]\n",
    "print(f\"Analyzer: {analyzer_name}\")\n",
    "\n",
    "filtered_cols = filter_analyzer_columns(conv_columns, analyzer_id=analyzer_name)\n",
    "info = parse_analyzer_column_name(filtered_cols[0])\n",
    "print(\"\\nInput:\")\n",
    "# print(f\"source_column: {info.source_column}\")\n",
    "print(f\"{row[info.source_column]}\\n\")\n",
    "\n",
    "for col in filtered_cols:\n",
    "    print(f\"metric: {info.metric_name}\")\n",
    "    # print(f\"type: {schema[col]['type']}\")\n",
    "    # print(f\"content_type: {schema[col]['content_type']}\")\n",
    "    print(f\"description: {schema[col]['description']}\")\n",
    "    print(f\"value: {row[col]}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abfccb",
   "metadata": {},
   "source": [
    "# Message level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb677ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer: training_quality\n",
      "[assistant]: 52\n",
      "\n",
      "\n",
      "Input:\n",
      "metric: response_completeness_score\n",
      "description: Response completeness score (0.0 = incomplete, 1.0 = complete)\n",
      "value: 0.0\n",
      "\n",
      "\n",
      "metric: response_completeness_score\n",
      "description: Whether response has proper sentence ending\n",
      "value: False\n",
      "\n",
      "\n",
      "metric: response_completeness_score\n",
      "description: Whether response has clear structure\n",
      "value: False\n",
      "\n",
      "\n",
      "metric: response_completeness_score\n",
      "description: Word count of response\n",
      "value: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.analyze.column_utils import (\n",
    "    filter_analyzer_columns,\n",
    "    get_analyzer_columns_by_analyzer,\n",
    "    parse_analyzer_column_name,\n",
    ")\n",
    "\n",
    "analyzer_names = [a.id for a in config.analyzers]\n",
    "row = analyzer.message_df.iloc[2]\n",
    "msg_columns = analyzer.message_df.columns\n",
    "\n",
    "# Then use it directly\n",
    "analyzer_name = analyzer_names[4]\n",
    "print(f\"Analyzer: {analyzer_name}\")\n",
    "\n",
    "filtered_cols = filter_analyzer_columns(msg_columns, analyzer_id=analyzer_name)\n",
    "info = parse_analyzer_column_name(filtered_cols[0])\n",
    "\n",
    "print(f\"[{row['role']}]: {row[info.source_column]}\\n\")\n",
    "print(\"\\nInput:\")\n",
    "# print(f\"source_column: {info.source_column}\")\n",
    "\n",
    "for col in filtered_cols:\n",
    "    print(f\"metric: {info.metric_name}\")\n",
    "    # print(f\"type: {schema[col]['type']}\")\n",
    "    # print(f\"content_type: {schema[col]['content_type']}\")\n",
    "    print(f\"description: {schema[col]['description']}\")\n",
    "    print(f\"value: {row[col]}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782aee00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
