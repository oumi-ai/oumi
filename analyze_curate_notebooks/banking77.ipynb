{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334e3fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available but forcing CPU usage to avoid crashes\n",
      "PyTorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# IMPORTANT: Set these BEFORE importing torch or any ML libraries\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Disable CUDA\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "# Force CPU usage in PyTorch to avoid MPS crashes\n",
    "import torch\n",
    "\n",
    "torch.set_default_device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available but forcing CPU usage to avoid crashes\")\n",
    "else:\n",
    "    print(\"Using CPU for all computations\")\n",
    "\n",
    "print(f\"PyTorch device: {torch.get_default_device()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430925a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 14 analyzers: ['length', 'diversity', 'format', 'quality', 'training_quality', 'cost', 'content_pattern', 'task_category', 'safety', 'difficulty', 'instruct_reward', 'input_quality', 'conversation_structure', 'response_completeness']\n",
      "[2025-12-29 14:42:15,539][oumi][rank0][pid:64160][MainThread][INFO]][base_map_dataset.py:91] Creating map dataset (type: TextSftJsonLinesDataset)... dataset_name: 'custom'\n",
      "[2025-12-29 14:42:15,540][oumi.utils.analysis_utils][rank0][pid:64160][MainThread][INFO]][analysis_utils.py:225] Loaded text dataset from: /Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\n",
      "[2025-12-29 14:42:15,540][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:154] Loaded dataset from config: None\n",
      "[2025-12-29 14:42:15,662][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: length\n",
      "[2025-12-29 14:42:15,663][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: diversity\n",
      "[2025-12-29 14:42:15,663][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: format\n",
      "[2025-12-29 14:42:15,664][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: quality\n",
      "[2025-12-29 14:42:15,665][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: training_quality\n",
      "[2025-12-29 14:42:15,665][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: cost\n",
      "[2025-12-29 14:42:15,666][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: content_pattern\n",
      "[2025-12-29 14:42:15,667][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: task_category\n",
      "[2025-12-29 14:42:15,667][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: safety\n",
      "[2025-12-29 14:42:15,668][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: difficulty\n",
      "[2025-12-29 14:42:15,668][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: instruct_reward\n",
      "[2025-12-29 14:42:15,668][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: input_quality\n",
      "[2025-12-29 14:42:15,669][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: conversation_structure\n",
      "[2025-12-29 14:42:15,670][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: response_completeness\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from oumi.core.configs import AnalyzeConfig\n",
    "from oumi.core.analyze.dataset_analyzer import DatasetAnalyzer\n",
    "\n",
    "# Path to the config file\n",
    "config_path = \"/Users/ryanarman/code/oumi/configs/examples/analyze/analyze.yaml\"\n",
    "\n",
    "# Path to your dataset file\n",
    "dataset_path = \"/Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\"\n",
    "\n",
    "# Load the config from YAML\n",
    "config = AnalyzeConfig.from_yaml(\n",
    "    config_path=config_path,\n",
    ")\n",
    "\n",
    "config.sample_count = 10\n",
    "\n",
    "# Override the dataset settings to use your local file\n",
    "config.dataset_path = dataset_path\n",
    "config.dataset_name = None  # Clear dataset_name so it uses dataset_path instead\n",
    "\n",
    "# Optionally update output path\n",
    "config.output_path = \"./analysis_output/banking77\"\n",
    "\n",
    "# IMPORTANT: Disable analyzers that require large model downloads or have issues\n",
    "# IFD requires downloading Qwen model and may cause MPS crashes\n",
    "# fasttext requires additional dependencies\n",
    "# repr_diversity and question_diversity download embedding models\n",
    "problematic_analyzers = [\"ifd\", \"fasttext\", \"repr_diversity\", \"question_diversity\"]\n",
    "config.analyzers = [a for a in config.analyzers if a.id not in problematic_analyzers]\n",
    "print(f\"Running {len(config.analyzers)} analyzers: {[a.id for a in config.analyzers]}\")\n",
    "\n",
    "# Validate the configuration\n",
    "config.finalize_and_validate()\n",
    "\n",
    "# Create the analyzer\n",
    "analyzer = DatasetAnalyzer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0ca499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 14:42:15,676][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:347] Starting analysis of dataset: None\n",
      "[2025-12-29 14:42:15,677][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:348] Using 14 sample analyzers: ['length', 'diversity', 'format', 'quality', 'training_quality', 'cost', 'content_pattern', 'task_category', 'safety', 'difficulty', 'instruct_reward', 'input_quality', 'conversation_structure', 'response_completeness']\n",
      "[2025-12-29 14:42:15,678][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:371] Analyzing 10 of 8002 conversations\n",
      "[2025-12-29 14:42:15,679][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:421] Converting conversation dataset with 8002 items\n",
      "[2025-12-29 14:42:15,679][oumi][rank0][pid:64160][MainThread][INFO]][dataset_analyzer.py:428] Limiting analysis to first 10 items (dataset has 8002 total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Unknown Dataset to DataFrames: 100%|██████████| 10/10 [00:00<00:00, 1906.59item/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 14:42:15,898][oumi][rank0][pid:64160][MainThread][WARNING]][dataset_analyzer.py:757] Failed to generate recommendations: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "Total conversations analyzed: 10\n"
     ]
    }
   ],
   "source": [
    "# Run the analysis\n",
    "analyzer.analyze_dataset()\n",
    "\n",
    "# The results are stored in analyzer object\n",
    "if analyzer._analysis_results:\n",
    "    print(\n",
    "        f\"Total conversations analyzed: {analyzer._analysis_results.conversations_analyzed}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a02385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SampleAnalyzerParams(id='length', params={'token_count': True}),\n",
       " SampleAnalyzerParams(id='diversity', params={'unique_words_ratio': True, 'case_sensitive': False}),\n",
       " SampleAnalyzerParams(id='format', params={'detect_markdown': True, 'detect_json': True, 'detect_code_blocks': True, 'detect_urls': True, 'detect_emails': True, 'compute_complexity': True}),\n",
       " SampleAnalyzerParams(id='quality', params={'detect_pii': True, 'detect_emails': True, 'detect_phones': True, 'detect_ssn': True, 'detect_credit_cards': True, 'detect_api_keys': True, 'detect_encoding_issues': True, 'detect_repetition': True, 'repetition_ngram_size': 3, 'repetition_threshold': 0.3}),\n",
       " SampleAnalyzerParams(id='training_quality', params={'compute_response_completeness': True, 'min_response_words': 5}),\n",
       " SampleAnalyzerParams(id='cost', params={'target_context_windows': [4096, 8192, 16384, 32768], 'compute_packing_efficiency': True, 'packing_overhead_tokens': 10}),\n",
       " SampleAnalyzerParams(id='content_pattern', params={'detect_placeholders': True, 'detect_hallucinated_experiences': True, 'detect_nooutput': True, 'detect_refusals': True, 'check_output_only': False}),\n",
       " SampleAnalyzerParams(id='task_category', params={'min_confidence': 0.3, 'default_category': 'other', 'analyze_user_only': True}),\n",
       " SampleAnalyzerParams(id='safety', params={'strict_mode': False, 'include_categories': True}),\n",
       " SampleAnalyzerParams(id='difficulty', params={'analyze_user_only': True, 'include_component_scores': True}),\n",
       " SampleAnalyzerParams(id='instruct_reward', params={'min_response_words': 10, 'max_response_words': 2000, 'analyze_assistant_only': True, 'include_component_scores': True}),\n",
       " SampleAnalyzerParams(id='input_quality', params={'analyze_user_only': True, 'include_component_flags': True}),\n",
       " SampleAnalyzerParams(id='conversation_structure', params={'single_turn_threshold': 2, 'compute_length_stats': True}),\n",
       " SampleAnalyzerParams(id='response_completeness', params={'analyze_assistant_only': True, 'strict_mode': False, 'include_truncation_type': True})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07ae1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = analyzer.get_schema()\n",
    "conv_columns = analyzer.conversation_df.columns\n",
    "merged_columns = analyzer.analysis_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e34d4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: conversation_text_content_training_quality_response_completeness_score\n",
      "schema[col]: {'type': <ColumnType.FLOAT: 'float'>, 'content_type': <ContentType.NUMERIC: 'numeric'>, 'description': 'Response completeness score (0.0 = incomplete, 1.0 = complete)'}\n",
      "row[col]: None\n"
     ]
    }
   ],
   "source": [
    "row = analyzer.conversation_df.iloc[0]\n",
    "col = conv_columns[20]\n",
    "print(f\"col: {col}\")\n",
    "print(f\"schema[col]: {schema[col]}\")\n",
    "print(f\"row[col]: {row[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8ef37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
