{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334e3fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local source code from: /Users/ryanarman/code/oumi/src\n",
      "MPS has been disabled - forcing CPU-only mode\n",
      "PyTorch device: cpu\n",
      "PyTorch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# CRITICAL: Add local source to path FIRST to use local changes\n",
    "sys.path.insert(0, \"/Users/ryanarman/code/oumi/src\")\n",
    "print(f\"Using local source code from: /Users/ryanarman/code/oumi/src\")\n",
    "\n",
    "# IMPORTANT: Set these BEFORE importing torch or any ML libraries\n",
    "# Disable all GPU/MPS backends to prevent crashes with IFD analyzer\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Disable CUDA\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # Disable MPS memory allocation\n",
    "os.environ[\"DISABLE_MPS_COMPAT\"] = \"1\"  # Additional MPS disable flag\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"  # Disable HuggingFace telemetry\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Allow model downloads\n",
    "\n",
    "# Force CPU usage in PyTorch to avoid MPS crashes\n",
    "import torch\n",
    "\n",
    "# Forcefully disable MPS before anything else\n",
    "torch.set_default_device(\"cpu\")\n",
    "if hasattr(torch.backends, \"mps\"):\n",
    "    # Monkey-patch to prevent MPS usage\n",
    "    original_is_available = torch.backends.mps.is_available\n",
    "    torch.backends.mps.is_available = lambda: False\n",
    "    print(\"MPS has been disabled - forcing CPU-only mode\")\n",
    "else:\n",
    "    print(\"Using CPU for all computations\")\n",
    "\n",
    "print(f\"PyTorch device: {torch.get_default_device()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430925a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 18 analyzers: ['length', 'diversity', 'format', 'quality', 'training_quality', 'cost', 'content_pattern', 'question_diversity', 'fasttext', 'ifd', 'repr_diversity', 'task_category', 'safety', 'difficulty', 'instruct_reward', 'input_quality', 'conversation_structure', 'response_completeness']\n",
      "[2025-12-29 17:10:11,863][oumi][rank0][pid:90380][MainThread][INFO]][base_map_dataset.py:91] Creating map dataset (type: TextSftJsonLinesDataset)... dataset_name: 'custom'\n",
      "[2025-12-29 17:10:11,864][oumi.utils.analysis_utils][rank0][pid:90380][MainThread][INFO]][analysis_utils.py:225] Loaded text dataset from: /Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\n",
      "[2025-12-29 17:10:11,864][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:154] Loaded dataset from config: None\n",
      "[2025-12-29 17:10:11,987][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: length\n",
      "[2025-12-29 17:10:11,988][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: diversity\n",
      "[2025-12-29 17:10:11,988][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: format\n",
      "[2025-12-29 17:10:11,989][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: quality\n",
      "[2025-12-29 17:10:11,989][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: training_quality\n",
      "[2025-12-29 17:10:11,990][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: cost\n",
      "[2025-12-29 17:10:11,990][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: content_pattern\n",
      "[2025-12-29 17:10:12,005][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: question_diversity\n",
      "[2025-12-29 17:10:12,005][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: fasttext\n",
      "[2025-12-29 17:10:12,006][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: ifd\n",
      "[2025-12-29 17:10:12,006][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: repr_diversity\n",
      "[2025-12-29 17:10:12,006][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: task_category\n",
      "[2025-12-29 17:10:12,006][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: safety\n",
      "[2025-12-29 17:10:12,007][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: difficulty\n",
      "[2025-12-29 17:10:12,008][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: instruct_reward\n",
      "[2025-12-29 17:10:12,009][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: input_quality\n",
      "[2025-12-29 17:10:12,009][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: conversation_structure\n",
      "[2025-12-29 17:10:12,010][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: response_completeness\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from oumi.core.configs import AnalyzeConfig\n",
    "from oumi.core.analyze.dataset_analyzer import DatasetAnalyzer\n",
    "\n",
    "# Path to the config file\n",
    "config_path = \"/Users/ryanarman/code/oumi/configs/examples/analyze/analyze.yaml\"\n",
    "\n",
    "# Path to your dataset file\n",
    "dataset_path = \"/Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\"\n",
    "\n",
    "# Load the config from YAML\n",
    "config = AnalyzeConfig.from_yaml(\n",
    "    config_path=config_path,\n",
    ")\n",
    "\n",
    "config.sample_count = 10\n",
    "\n",
    "# Override the dataset settings to use your local file\n",
    "config.dataset_path = dataset_path\n",
    "config.dataset_name = None  # Clear dataset_name so it uses dataset_path instead\n",
    "\n",
    "# Optionally update output path\n",
    "config.output_path = \"./analysis_output/banking77\"\n",
    "\n",
    "# IMPORTANT: Disable analyzers that require large model downloads or have issues\n",
    "# IFD requires downloading Qwen model and may cause MPS crashes\n",
    "# fasttext requires additional dependencies\n",
    "# repr_diversity and question_diversity download embedding models\n",
    "problematic_analyzers = []\n",
    "# problematic_analyzers = [\"ifd\", \"fasttext\", \"repr_diversity\", \"question_diversity\"]\n",
    "config.analyzers = [a for a in config.analyzers if a.id not in problematic_analyzers]\n",
    "print(f\"Running {len(config.analyzers)} analyzers: {[a.id for a in config.analyzers]}\")\n",
    "\n",
    "# Validate the configuration\n",
    "config.finalize_and_validate()\n",
    "\n",
    "# Create the analyzer\n",
    "analyzer = DatasetAnalyzer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0ca499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 17:10:12,024][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:347] Starting analysis of dataset: None\n",
      "[2025-12-29 17:10:12,025][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:348] Using 18 sample analyzers: ['length', 'diversity', 'format', 'quality', 'training_quality', 'cost', 'content_pattern', 'question_diversity', 'fasttext', 'ifd', 'repr_diversity', 'task_category', 'safety', 'difficulty', 'instruct_reward', 'input_quality', 'conversation_structure', 'response_completeness']\n",
      "[2025-12-29 17:10:12,025][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:371] Analyzing 10 of 8002 conversations\n",
      "[2025-12-29 17:10:12,026][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:421] Converting conversation dataset with 8002 items\n",
      "[2025-12-29 17:10:12,026][oumi][rank0][pid:90380][MainThread][INFO]][dataset_analyzer.py:428] Limiting analysis to first 10 items (dataset has 8002 total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Unknown Dataset to DataFrames: 100%|██████████| 10/10 [00:00<00:00, 2076.49item/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 17:10:12,079][oumi][rank0][pid:90380][MainThread][INFO]][question_diversity_analyzer.py:463] Computing embeddings for 10 user questions...\n",
      "[2025-12-29 17:10:12,080][oumi][rank0][pid:90380][MainThread][INFO]][question_diversity_analyzer.py:173] Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 75.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 17:10:13,238][oumi][rank0][pid:90380][MainThread][INFO]][question_diversity_analyzer.py:468] Clustering 10 questions using dbscan...\n",
      "[2025-12-29 17:10:13,484][oumi][rank0][pid:90380][MainThread][INFO]][question_diversity_analyzer.py:486] Found 1 clusters\n",
      "[2025-12-29 17:10:13,490][oumi][rank0][pid:90380][MainThread][WARNING]][dataframe_analyzer.py:153] Analyzer question_diversity failed: INTEGER\n",
      "[2025-12-29 17:10:13,506][oumi][rank0][pid:90380][MainThread][INFO]][fasttext_analyzer.py:219] Initialized fast-langdetect for language detection\n",
      "[2025-12-29 17:10:13,507][oumi][rank0][pid:90380][MainThread][INFO]][fasttext_analyzer.py:435] Analyzing language for column: conversation_text_content\n",
      "[2025-12-29 17:10:13,597][oumi][rank0][pid:90380][MainThread][INFO]][ifd_analyzer.py:153] Loading model for IFD analysis: Qwen/Qwen3-0.6B\n",
      "[2025-12-29 17:10:15,459][oumi][rank0][pid:90380][MainThread][INFO]][ifd_analyzer.py:192] Loaded Qwen/Qwen3-0.6B on cpu (dtype: torch.float32)\n",
      "[2025-12-29 17:10:15,460][oumi][rank0][pid:90380][MainThread][WARNING]][ifd_analyzer.py:629] Could not find instruction and response columns. For flat format, set instruction_column and response_column, or use columns like 'instruction'/'prompt' and 'response'/'output'. For conversation format, ensure 'text_content' and 'role' exist. Available columns: ['conversation_index', 'conversation_id', 'num_messages', 'conversation_text_content', 'conversation_text_content_length_token_count', 'conversation_text_content_diversity_unique_words_ratio', 'conversation_text_content_format_has_markdown', 'conversation_text_content_format_has_json', 'conversation_text_content_format_has_code_blocks', 'conversation_text_content_format_code_block_count', 'conversation_text_content_format_code_block_languages', 'conversation_text_content_format_has_urls', 'conversation_text_content_format_has_emails', 'conversation_text_content_format_format_complexity_score', 'conversation_text_content_quality_has_pii', 'conversation_text_content_quality_pii_types', 'conversation_text_content_quality_pii_count', 'conversation_text_content_quality_has_encoding_issues', 'conversation_text_content_quality_repetition_ratio', 'conversation_text_content_quality_has_high_repetition', 'conversation_text_content_training_quality_response_completeness_score', 'conversation_text_content_training_quality_has_proper_ending', 'conversation_text_content_training_quality_has_structure', 'conversation_text_content_training_quality_response_word_count', 'conversation_text_content_cost_fits_context_4k', 'conversation_text_content_cost_context_utilization_4k', 'conversation_text_content_cost_tokens_wasted_4k', 'conversation_text_content_cost_fits_context_8k', 'conversation_text_content_cost_context_utilization_8k', 'conversation_text_content_cost_tokens_wasted_8k', 'conversation_text_content_cost_fits_context_16k', 'conversation_text_content_cost_context_utilization_16k', 'conversation_text_content_cost_tokens_wasted_16k', 'conversation_text_content_cost_fits_context_32k', 'conversation_text_content_cost_context_utilization_32k', 'conversation_text_content_cost_tokens_wasted_32k', 'conversation_text_content_content_pattern_has_placeholder', 'conversation_text_content_content_pattern_placeholder_count', 'conversation_text_content_content_pattern_placeholder_types', 'conversation_text_content_content_pattern_has_hallucinated_experience', 'conversation_text_content_content_pattern_has_nooutput', 'conversation_text_content_content_pattern_has_refusal', 'conversation_text_content_fasttext_detected_language', 'conversation_text_content_fasttext_language_confidence', 'conversation_text_content_fasttext_language_name', 'conversation_text_content_fasttext_low_confidence', 'conversation_text_content_fasttext_detected_script', 'conversation_text_content_fasttext_is_multilingual']\n",
      "[2025-12-29 17:10:15,461][oumi][rank0][pid:90380][MainThread][INFO]][repr_diversity_analyzer.py:362] Computing diversity scores for 10 samples in column 'conversation_text_content'...\n",
      "[2025-12-29 17:10:15,462][oumi][rank0][pid:90380][MainThread][INFO]][repr_diversity_analyzer.py:164] Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 103.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 17:10:16,504][oumi][rank0][pid:90380][MainThread][INFO]][repr_diversity_analyzer.py:229] Computing nearest neighbor distances for 10 samples (k=5)...\n",
      "[2025-12-29 17:10:16,506][oumi][rank0][pid:90380][MainThread][INFO]][repr_diversity_analyzer.py:555] Column 'conversation_text_content': 10/10 samples (100.0%) are redundant\n",
      "[2025-12-29 17:10:16,649][oumi][rank0][pid:90380][MainThread][INFO]][question_diversity_analyzer.py:463] Computing embeddings for 10 user questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 604.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 17:10:16,670][oumi][rank0][pid:90380][MainThread][INFO]][question_diversity_analyzer.py:468] Clustering 10 questions using dbscan...\n",
      "[2025-12-29 17:10:16,673][oumi][rank0][pid:90380][MainThread][INFO]][question_diversity_analyzer.py:481] Found 0 clusters, 10 unique/diverse questions (not similar to others)\n",
      "[2025-12-29 17:10:16,674][oumi][rank0][pid:90380][MainThread][WARNING]][dataframe_analyzer.py:153] Analyzer question_diversity failed: INTEGER\n",
      "[2025-12-29 17:10:16,674][oumi][rank0][pid:90380][MainThread][INFO]][fasttext_analyzer.py:435] Analyzing language for column: text_content\n",
      "[2025-12-29 17:10:16,681][oumi][rank0][pid:90380][MainThread][INFO]][ifd_analyzer.py:617] Detected conversation format. Computing IFD for assistant messages using preceding user messages as instructions.\n",
      "[2025-12-29 17:10:19,506][oumi][rank0][pid:90380][MainThread][INFO]][ifd_analyzer.py:497] IFD analysis complete. Processed 10 assistant messages out of 10 total.\n",
      "[2025-12-29 17:10:19,508][oumi][rank0][pid:90380][MainThread][INFO]][repr_diversity_analyzer.py:362] Computing diversity scores for 30 samples in column 'text_content'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 30/30 [00:00<00:00, 136.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 17:10:19,729][oumi][rank0][pid:90380][MainThread][INFO]][repr_diversity_analyzer.py:229] Computing nearest neighbor distances for 30 samples (k=5)...\n",
      "[2025-12-29 17:10:19,763][oumi][rank0][pid:90380][MainThread][INFO]][repr_diversity_analyzer.py:555] Column 'text_content': 19/30 samples (63.3%) are redundant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanarman/miniconda3/envs/oumi/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-29 17:10:19,856][oumi][rank0][pid:90380][MainThread][WARNING]][dataset_analyzer.py:757] Failed to generate recommendations: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "Total conversations analyzed: 10\n"
     ]
    }
   ],
   "source": [
    "# Run the analysis\n",
    "analyzer.analyze_dataset()\n",
    "\n",
    "# The results are stored in analyzer object\n",
    "if analyzer._analysis_results:\n",
    "    print(\n",
    "        f\"Total conversations analyzed: {analyzer._analysis_results.conversations_analyzed}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07ae1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(schema): 174\n",
      "len(merged_columns): 174\n"
     ]
    }
   ],
   "source": [
    "schema = analyzer.get_schema()\n",
    "print(f\"len(schema): {len(schema)}\")\n",
    "merged_columns = analyzer.analysis_df.columns\n",
    "print(f\"len(merged_columns): {len(merged_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c2ff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_index</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>num_messages</th>\n",
       "      <th>conversation_text_content</th>\n",
       "      <th>conversation_text_content_length_token_count</th>\n",
       "      <th>conversation_text_content_diversity_unique_words_ratio</th>\n",
       "      <th>conversation_text_content_format_has_markdown</th>\n",
       "      <th>conversation_text_content_format_has_json</th>\n",
       "      <th>conversation_text_content_format_has_code_blocks</th>\n",
       "      <th>conversation_text_content_format_code_block_count</th>\n",
       "      <th>...</th>\n",
       "      <th>conversation_structure_conversation_depth</th>\n",
       "      <th>conversation_structure_role_balance</th>\n",
       "      <th>conversation_structure_has_system_prompt</th>\n",
       "      <th>conversation_structure_avg_turn_length</th>\n",
       "      <th>conversation_structure_turn_length_variance</th>\n",
       "      <th>text_content_response_completeness_is_complete</th>\n",
       "      <th>text_content_response_completeness_score</th>\n",
       "      <th>text_content_response_completeness_ends_naturally</th>\n",
       "      <th>text_content_response_completeness_has_conclusion</th>\n",
       "      <th>text_content_response_completeness_truncation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>SYSTEM: You are a banking intent classifier. C...</td>\n",
       "      <td>1775</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>6.5</td>\n",
       "      <td>30.25</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>SYSTEM: You are a banking intent classifier. C...</td>\n",
       "      <td>1775</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>6.5</td>\n",
       "      <td>30.25</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>SYSTEM: You are a banking intent classifier. C...</td>\n",
       "      <td>1775</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>6.5</td>\n",
       "      <td>30.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>SYSTEM: You are a banking intent classifier. C...</td>\n",
       "      <td>1774</td>\n",
       "      <td>0.511602</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>SYSTEM: You are a banking intent classifier. C...</td>\n",
       "      <td>1774</td>\n",
       "      <td>0.511602</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_index conversation_id  num_messages  \\\n",
       "0                   0               0             3   \n",
       "1                   0               0             3   \n",
       "2                   0               0             3   \n",
       "3                   1               1             3   \n",
       "4                   1               1             3   \n",
       "\n",
       "                           conversation_text_content  \\\n",
       "0  SYSTEM: You are a banking intent classifier. C...   \n",
       "1  SYSTEM: You are a banking intent classifier. C...   \n",
       "2  SYSTEM: You are a banking intent classifier. C...   \n",
       "3  SYSTEM: You are a banking intent classifier. C...   \n",
       "4  SYSTEM: You are a banking intent classifier. C...   \n",
       "\n",
       "   conversation_text_content_length_token_count  \\\n",
       "0                                          1775   \n",
       "1                                          1775   \n",
       "2                                          1775   \n",
       "3                                          1774   \n",
       "4                                          1774   \n",
       "\n",
       "   conversation_text_content_diversity_unique_words_ratio  \\\n",
       "0                                           0.516556        \n",
       "1                                           0.516556        \n",
       "2                                           0.516556        \n",
       "3                                           0.511602        \n",
       "4                                           0.511602        \n",
       "\n",
       "   conversation_text_content_format_has_markdown  \\\n",
       "0                                           True   \n",
       "1                                           True   \n",
       "2                                           True   \n",
       "3                                           True   \n",
       "4                                           True   \n",
       "\n",
       "   conversation_text_content_format_has_json  \\\n",
       "0                                      False   \n",
       "1                                      False   \n",
       "2                                      False   \n",
       "3                                      False   \n",
       "4                                      False   \n",
       "\n",
       "   conversation_text_content_format_has_code_blocks  \\\n",
       "0                                             False   \n",
       "1                                             False   \n",
       "2                                             False   \n",
       "3                                             False   \n",
       "4                                             False   \n",
       "\n",
       "   conversation_text_content_format_code_block_count  ...  \\\n",
       "0                                                  0  ...   \n",
       "1                                                  0  ...   \n",
       "2                                                  0  ...   \n",
       "3                                                  0  ...   \n",
       "4                                                  0  ...   \n",
       "\n",
       "  conversation_structure_conversation_depth  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "\n",
       "   conversation_structure_role_balance  \\\n",
       "0                                  0.5   \n",
       "1                                  0.5   \n",
       "2                                  0.5   \n",
       "3                                  0.5   \n",
       "4                                  0.5   \n",
       "\n",
       "   conversation_structure_has_system_prompt  \\\n",
       "0                                      True   \n",
       "1                                      True   \n",
       "2                                      True   \n",
       "3                                      True   \n",
       "4                                      True   \n",
       "\n",
       "   conversation_structure_avg_turn_length  \\\n",
       "0                                     6.5   \n",
       "1                                     6.5   \n",
       "2                                     6.5   \n",
       "3                                     6.0   \n",
       "4                                     6.0   \n",
       "\n",
       "   conversation_structure_turn_length_variance  \\\n",
       "0                                        30.25   \n",
       "1                                        30.25   \n",
       "2                                        30.25   \n",
       "3                                        25.00   \n",
       "4                                        25.00   \n",
       "\n",
       "  text_content_response_completeness_is_complete  \\\n",
       "0                                           None   \n",
       "1                                           None   \n",
       "2                                          False   \n",
       "3                                           None   \n",
       "4                                           None   \n",
       "\n",
       "   text_content_response_completeness_score  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       0.5   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "   text_content_response_completeness_ends_naturally  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                              False   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "   text_content_response_completeness_has_conclusion  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                              False   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "   text_content_response_completeness_truncation_type  \n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                                      \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ee896",
   "metadata": {},
   "source": [
    "# Conv level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e34d4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: conversation_text_content_repr_diversity_percentile\n",
      "schema[col]: {'type': <ColumnType.FLOAT: 'float'>, 'content_type': <ContentType.NUMERIC: 'numeric'>, 'description': 'Diversity percentile rank (0.0-100.0)'}\n",
      "row[col]: 100.0\n"
     ]
    }
   ],
   "source": [
    "conv_columns = analyzer.conversation_df.columns\n",
    "row = analyzer.conversation_df.iloc[0]\n",
    "col = conv_columns[51]\n",
    "print(f\"col: {col}\")\n",
    "print(f\"schema[col]: {schema[col]}\")\n",
    "print(f\"row[col]: {row[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d04cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(conv_columns)):\n",
    "    if \"question\" in conv_columns[i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bef2d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['conversation_index', 'conversation_id', 'num_messages',\n",
       "       'conversation_text_content',\n",
       "       'conversation_text_content_length_token_count',\n",
       "       'conversation_text_content_diversity_unique_words_ratio',\n",
       "       'conversation_text_content_format_has_markdown',\n",
       "       'conversation_text_content_format_has_json',\n",
       "       'conversation_text_content_format_has_code_blocks',\n",
       "       'conversation_text_content_format_code_block_count',\n",
       "       'conversation_text_content_format_code_block_languages',\n",
       "       'conversation_text_content_format_has_urls',\n",
       "       'conversation_text_content_format_has_emails',\n",
       "       'conversation_text_content_format_format_complexity_score',\n",
       "       'conversation_text_content_quality_has_pii',\n",
       "       'conversation_text_content_quality_pii_types',\n",
       "       'conversation_text_content_quality_pii_count',\n",
       "       'conversation_text_content_quality_has_encoding_issues',\n",
       "       'conversation_text_content_quality_repetition_ratio',\n",
       "       'conversation_text_content_quality_has_high_repetition',\n",
       "       'conversation_text_content_training_quality_response_completeness_score',\n",
       "       'conversation_text_content_training_quality_has_proper_ending',\n",
       "       'conversation_text_content_training_quality_has_structure',\n",
       "       'conversation_text_content_training_quality_response_word_count',\n",
       "       'conversation_text_content_cost_fits_context_4k',\n",
       "       'conversation_text_content_cost_context_utilization_4k',\n",
       "       'conversation_text_content_cost_tokens_wasted_4k',\n",
       "       'conversation_text_content_cost_fits_context_8k',\n",
       "       'conversation_text_content_cost_context_utilization_8k',\n",
       "       'conversation_text_content_cost_tokens_wasted_8k',\n",
       "       'conversation_text_content_cost_fits_context_16k',\n",
       "       'conversation_text_content_cost_context_utilization_16k',\n",
       "       'conversation_text_content_cost_tokens_wasted_16k',\n",
       "       'conversation_text_content_cost_fits_context_32k',\n",
       "       'conversation_text_content_cost_context_utilization_32k',\n",
       "       'conversation_text_content_cost_tokens_wasted_32k',\n",
       "       'conversation_text_content_content_pattern_has_placeholder',\n",
       "       'conversation_text_content_content_pattern_placeholder_count',\n",
       "       'conversation_text_content_content_pattern_placeholder_types',\n",
       "       'conversation_text_content_content_pattern_has_hallucinated_experience',\n",
       "       'conversation_text_content_content_pattern_has_nooutput',\n",
       "       'conversation_text_content_content_pattern_has_refusal',\n",
       "       'conversation_text_content_fasttext_detected_language',\n",
       "       'conversation_text_content_fasttext_language_confidence',\n",
       "       'conversation_text_content_fasttext_language_name',\n",
       "       'conversation_text_content_fasttext_low_confidence',\n",
       "       'conversation_text_content_fasttext_detected_script',\n",
       "       'conversation_text_content_fasttext_is_multilingual',\n",
       "       'conversation_text_content_repr_diversity_nn_distance',\n",
       "       'conversation_text_content_repr_diversity_score',\n",
       "       'conversation_text_content_repr_diversity_is_redundant',\n",
       "       'conversation_text_content_repr_diversity_percentile',\n",
       "       'conversation_text_content_task_category_category',\n",
       "       'conversation_text_content_task_category_confidence',\n",
       "       'conversation_text_content_task_category_is_stem',\n",
       "       'conversation_text_content_task_category_is_conversational',\n",
       "       'conversation_text_content_safety_score',\n",
       "       'conversation_text_content_safety_is_safe',\n",
       "       'conversation_text_content_safety_risk_level',\n",
       "       'conversation_text_content_safety_categories_triggered',\n",
       "       'conversation_text_content_difficulty_score',\n",
       "       'conversation_text_content_difficulty_tier',\n",
       "       'conversation_text_content_difficulty_requires_reasoning',\n",
       "       'conversation_text_content_difficulty_requires_domain_knowledge',\n",
       "       'conversation_text_content_difficulty_constraint_count',\n",
       "       'conversation_text_content_instruct_reward_score',\n",
       "       'conversation_text_content_instruct_reward_tier',\n",
       "       'conversation_text_content_instruct_reward_helpfulness',\n",
       "       'conversation_text_content_instruct_reward_completeness',\n",
       "       'conversation_text_content_instruct_reward_clarity',\n",
       "       'conversation_text_content_input_quality_tier',\n",
       "       'conversation_text_content_input_quality_score',\n",
       "       'conversation_text_content_input_quality_is_ambiguous',\n",
       "       'conversation_text_content_input_quality_is_answerable',\n",
       "       'conversation_text_content_input_quality_has_sufficient_context',\n",
       "       'conversation_text_content_response_completeness_is_complete',\n",
       "       'conversation_text_content_response_completeness_score',\n",
       "       'conversation_text_content_response_completeness_ends_naturally',\n",
       "       'conversation_text_content_response_completeness_has_conclusion',\n",
       "       'conversation_text_content_response_completeness_truncation_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abfccb",
   "metadata": {},
   "source": [
    "# Message level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a476fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_columns = analyzer.message_df.columns\n",
    "\n",
    "for i in range(len(msg_columns)):\n",
    "    if \"question\" in msg_columns[i]:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0273d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['conversation_index', 'conversation_id', 'message_index', 'message_id',\n",
       "       'role', 'text_content', 'text_content_length_token_count',\n",
       "       'text_content_diversity_unique_words_ratio',\n",
       "       'text_content_format_has_markdown', 'text_content_format_has_json',\n",
       "       'text_content_format_has_code_blocks',\n",
       "       'text_content_format_code_block_count',\n",
       "       'text_content_format_code_block_languages',\n",
       "       'text_content_format_has_urls', 'text_content_format_has_emails',\n",
       "       'text_content_format_format_complexity_score',\n",
       "       'text_content_quality_has_pii', 'text_content_quality_pii_types',\n",
       "       'text_content_quality_pii_count',\n",
       "       'text_content_quality_has_encoding_issues',\n",
       "       'text_content_quality_repetition_ratio',\n",
       "       'text_content_quality_has_high_repetition',\n",
       "       'text_content_training_quality_response_completeness_score',\n",
       "       'text_content_training_quality_has_proper_ending',\n",
       "       'text_content_training_quality_has_structure',\n",
       "       'text_content_training_quality_response_word_count',\n",
       "       'text_content_cost_fits_context_4k',\n",
       "       'text_content_cost_context_utilization_4k',\n",
       "       'text_content_cost_tokens_wasted_4k',\n",
       "       'text_content_cost_fits_context_8k',\n",
       "       'text_content_cost_context_utilization_8k',\n",
       "       'text_content_cost_tokens_wasted_8k',\n",
       "       'text_content_cost_fits_context_16k',\n",
       "       'text_content_cost_context_utilization_16k',\n",
       "       'text_content_cost_tokens_wasted_16k',\n",
       "       'text_content_cost_fits_context_32k',\n",
       "       'text_content_cost_context_utilization_32k',\n",
       "       'text_content_cost_tokens_wasted_32k',\n",
       "       'text_content_content_pattern_has_placeholder',\n",
       "       'text_content_content_pattern_placeholder_count',\n",
       "       'text_content_content_pattern_placeholder_types',\n",
       "       'text_content_content_pattern_has_hallucinated_experience',\n",
       "       'text_content_content_pattern_has_nooutput',\n",
       "       'text_content_content_pattern_has_refusal',\n",
       "       'text_content_fasttext_detected_language',\n",
       "       'text_content_fasttext_language_confidence',\n",
       "       'text_content_fasttext_language_name',\n",
       "       'text_content_fasttext_low_confidence',\n",
       "       'text_content_fasttext_detected_script',\n",
       "       'text_content_fasttext_is_multilingual', 'text_content_ifd_score',\n",
       "       'text_content_ifd_ppl_with_instruction',\n",
       "       'text_content_ifd_ppl_without_instruction',\n",
       "       'text_content_ifd_response_loss',\n",
       "       'text_content_repr_diversity_nn_distance',\n",
       "       'text_content_repr_diversity_score',\n",
       "       'text_content_repr_diversity_is_redundant',\n",
       "       'text_content_repr_diversity_percentile',\n",
       "       'text_content_task_category_category',\n",
       "       'text_content_task_category_confidence',\n",
       "       'text_content_task_category_is_stem',\n",
       "       'text_content_task_category_is_conversational',\n",
       "       'text_content_safety_score', 'text_content_safety_is_safe',\n",
       "       'text_content_safety_risk_level',\n",
       "       'text_content_safety_categories_triggered',\n",
       "       'text_content_difficulty_score', 'text_content_difficulty_tier',\n",
       "       'text_content_difficulty_requires_reasoning',\n",
       "       'text_content_difficulty_requires_domain_knowledge',\n",
       "       'text_content_difficulty_constraint_count',\n",
       "       'text_content_instruct_reward_score',\n",
       "       'text_content_instruct_reward_tier',\n",
       "       'text_content_instruct_reward_helpfulness',\n",
       "       'text_content_instruct_reward_completeness',\n",
       "       'text_content_instruct_reward_clarity',\n",
       "       'text_content_input_quality_tier', 'text_content_input_quality_score',\n",
       "       'text_content_input_quality_is_ambiguous',\n",
       "       'text_content_input_quality_is_answerable',\n",
       "       'text_content_input_quality_has_sufficient_context',\n",
       "       'conversation_structure_turn_count',\n",
       "       'conversation_structure_user_turn_count',\n",
       "       'conversation_structure_assistant_turn_count',\n",
       "       'conversation_structure_is_single_turn',\n",
       "       'conversation_structure_is_multi_turn',\n",
       "       'conversation_structure_conversation_depth',\n",
       "       'conversation_structure_role_balance',\n",
       "       'conversation_structure_has_system_prompt',\n",
       "       'conversation_structure_avg_turn_length',\n",
       "       'conversation_structure_turn_length_variance',\n",
       "       'text_content_response_completeness_is_complete',\n",
       "       'text_content_response_completeness_score',\n",
       "       'text_content_response_completeness_ends_naturally',\n",
       "       'text_content_response_completeness_has_conclusion',\n",
       "       'text_content_response_completeness_truncation_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b9cb31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: text_content_repr_diversity_is_redundant\n",
      "schema[col]: {'type': <ColumnType.BOOL: 'bool'>, 'content_type': <ContentType.BOOLEAN: 'boolean'>, 'description': 'Whether sample is redundant (too similar to others)'}\n",
      "row[col]: False\n"
     ]
    }
   ],
   "source": [
    "row = analyzer.message_df.iloc[1]\n",
    "col = msg_columns[56]\n",
    "print(f\"col: {col}\")\n",
    "print(f\"schema[col]: {schema[col]}\")\n",
    "print(f\"row[col]: {row[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7e788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
