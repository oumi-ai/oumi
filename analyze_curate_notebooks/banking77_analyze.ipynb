{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470e1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the config file\n",
    "config_path = \"/Users/ryanarman/code/oumi/configs/examples/analyze/analyze.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334e3fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS has been disabled - forcing CPU-only mode\n",
      "PyTorch device: cpu\n",
      "PyTorch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# IMPORTANT: Set these BEFORE importing torch or any ML libraries\n",
    "# Disable all GPU/MPS backends to prevent crashes with IFD analyzer\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Disable CUDA\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # Disable MPS memory allocation\n",
    "os.environ[\"DISABLE_MPS_COMPAT\"] = \"1\"  # Additional MPS disable flag\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"  # Disable HuggingFace telemetry\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Allow model downloads\n",
    "\n",
    "# Force CPU usage in PyTorch to avoid MPS crashes\n",
    "import torch\n",
    "\n",
    "# Forcefully disable MPS before anything else\n",
    "torch.set_default_device(\"cpu\")\n",
    "if hasattr(torch.backends, \"mps\"):\n",
    "    # Monkey-patch to prevent MPS usage\n",
    "    original_is_available = torch.backends.mps.is_available\n",
    "    torch.backends.mps.is_available = lambda: False\n",
    "    print(\"MPS has been disabled - forcing CPU-only mode\")\n",
    "else:\n",
    "    print(\"Using CPU for all computations\")\n",
    "\n",
    "print(f\"PyTorch device: {torch.get_default_device()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430925a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 18 analyzers: ['length', 'diversity', 'format', 'quality', 'training_quality', 'cost', 'content_pattern', 'question_diversity', 'fasttext', 'ifd', 'repr_diversity', 'task_category', 'safety', 'difficulty', 'instruct_reward', 'input_quality', 'conversation_structure', 'response_completeness']\n",
      "[2026-01-05 16:54:20,402][oumi][rank0][pid:24381][MainThread][INFO]][base_map_dataset.py:91] Creating map dataset (type: TextSftJsonLinesDataset)... dataset_name: 'custom'\n",
      "[2026-01-05 16:54:20,402][oumi.utils.analysis_utils][rank0][pid:24381][MainThread][INFO]][analysis_utils.py:227] Loaded text dataset from: /Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\n",
      "[2026-01-05 16:54:20,403][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:154] Loaded dataset from config: None\n",
      "[2026-01-05 16:54:20,526][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: length\n",
      "[2026-01-05 16:54:20,526][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: diversity\n",
      "[2026-01-05 16:54:20,527][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: format\n",
      "[2026-01-05 16:54:20,527][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: quality\n",
      "[2026-01-05 16:54:20,528][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: training_quality\n",
      "[2026-01-05 16:54:20,529][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: cost\n",
      "[2026-01-05 16:54:20,529][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: content_pattern\n",
      "[2026-01-05 16:54:20,538][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: question_diversity\n",
      "[2026-01-05 16:54:20,538][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: fasttext\n",
      "[2026-01-05 16:54:20,539][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: ifd\n",
      "[2026-01-05 16:54:20,539][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: repr_diversity\n",
      "[2026-01-05 16:54:20,539][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: task_category\n",
      "[2026-01-05 16:54:20,539][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: safety\n",
      "[2026-01-05 16:54:20,540][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: difficulty\n",
      "[2026-01-05 16:54:20,540][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: instruct_reward\n",
      "[2026-01-05 16:54:20,540][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: input_quality\n",
      "[2026-01-05 16:54:20,540][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: conversation_structure\n",
      "[2026-01-05 16:54:20,541][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:318] Initialized sample analyzer: response_completeness\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from oumi.core.configs import AnalyzeConfig\n",
    "from oumi.core.analyze.dataset_analyzer import DatasetAnalyzer\n",
    "\n",
    "# Path to your dataset file\n",
    "dataset_path = \"/Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\"\n",
    "\n",
    "# Load the config from YAML\n",
    "config = AnalyzeConfig.from_yaml(\n",
    "    config_path=config_path,\n",
    ")\n",
    "\n",
    "config.sample_count = 10\n",
    "config.chat_template = \"chat_ml\"\n",
    "\n",
    "# Override the dataset settings to use your local file\n",
    "config.dataset_path = dataset_path\n",
    "config.dataset_name = None  # Clear dataset_name so it uses dataset_path instead\n",
    "\n",
    "# Optionally update output path\n",
    "config.output_path = \"./analysis_output/banking77\"\n",
    "\n",
    "# IMPORTANT: Disable analyzers that require large model downloads or have issues\n",
    "# IFD requires downloading Qwen model and may cause MPS crashes\n",
    "# fasttext requires additional dependencies\n",
    "# repr_diversity and question_diversity download embedding models\n",
    "print(\n",
    "    f\"Running {len(config.analyzers)} analyzers: {[a.instance_id for a in config.analyzers]}\"\n",
    ")\n",
    "\n",
    "# config.analyzers = [a for a in config.analyzers if a.id == \"length\"]\n",
    "\n",
    "\n",
    "# Validate the configuration\n",
    "config.finalize_and_validate()\n",
    "\n",
    "# Create the analyzer\n",
    "analyzer = DatasetAnalyzer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0ca499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-05 16:54:20,554][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:361] Starting analysis of dataset: None\n",
      "[2026-01-05 16:54:20,555][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:362] Using 18 sample analyzers: ['length', 'diversity', 'format', 'quality', 'training_quality', 'cost', 'content_pattern', 'question_diversity', 'fasttext', 'ifd', 'repr_diversity', 'task_category', 'safety', 'difficulty', 'instruct_reward', 'input_quality', 'conversation_structure', 'response_completeness']\n",
      "[2026-01-05 16:54:20,556][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:385] Analyzing 10 of 8002 conversations\n",
      "[2026-01-05 16:54:20,556][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:435] Converting conversation dataset with 8002 items\n",
      "[2026-01-05 16:54:20,556][oumi][rank0][pid:24381][MainThread][INFO]][dataset_analyzer.py:442] Limiting analysis to first 10 items (dataset has 8002 total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Unknown Dataset to DataFrames: 100%|██████████| 10/10 [00:00<00:00, 501.55item/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-05 16:54:20,595][oumi.utils.analysis_utils][rank0][pid:24381][MainThread][INFO]][analysis_utils.py:1322] Adding default schema entries for 2 columns not in base schema: ['label', 'label_name']\n",
      "[2026-01-05 16:54:20,625][oumi][rank0][pid:24381][MainThread][INFO]][question_diversity_analyzer.py:464] Computing embeddings for 10 user questions...\n",
      "[2026-01-05 16:54:20,626][oumi][rank0][pid:24381][MainThread][INFO]][question_diversity_analyzer.py:174] Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 44.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-05 16:54:21,830][oumi][rank0][pid:24381][MainThread][INFO]][question_diversity_analyzer.py:469] Clustering 10 questions using dbscan...\n",
      "[2026-01-05 16:54:22,237][oumi][rank0][pid:24381][MainThread][INFO]][question_diversity_analyzer.py:487] Found 1 clusters\n",
      "[2026-01-05 16:54:22,259][oumi][rank0][pid:24381][MainThread][INFO]][fasttext_analyzer.py:220] Initialized fast-langdetect for language detection\n",
      "[2026-01-05 16:54:22,260][oumi][rank0][pid:24381][MainThread][INFO]][fasttext_analyzer.py:436] Analyzing language for column: conversation_text_content\n",
      "[2026-01-05 16:54:22,316][oumi][rank0][pid:24381][MainThread][INFO]][ifd_analyzer.py:154] Loading model for IFD analysis: Qwen/Qwen3-0.6B\n",
      "[2026-01-05 16:54:24,169][oumi][rank0][pid:24381][MainThread][INFO]][ifd_analyzer.py:193] Loaded Qwen/Qwen3-0.6B on cpu (dtype: torch.float32)\n",
      "[2026-01-05 16:54:24,170][oumi][rank0][pid:24381][MainThread][INFO]][ifd_analyzer.py:664] Computing IFD scores using instruction='conversation_text_content__question_diversity__cluster_id', response='conversation_text_content__training_quality__response_completeness_score'\n",
      "[2026-01-05 16:54:25,910][oumi][rank0][pid:24381][MainThread][INFO]][ifd_analyzer.py:677] IFD analysis complete. Mean IFD: inf, Min: inf, Max: inf\n",
      "[2026-01-05 16:54:25,911][oumi][rank0][pid:24381][MainThread][INFO]][repr_diversity_analyzer.py:363] Computing diversity scores for 10 samples in column 'conversation_text_content'...\n",
      "[2026-01-05 16:54:25,911][oumi][rank0][pid:24381][MainThread][INFO]][repr_diversity_analyzer.py:165] Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 103.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-05 16:54:27,112][oumi][rank0][pid:24381][MainThread][INFO]][repr_diversity_analyzer.py:230] Computing nearest neighbor distances for 10 samples (k=5)...\n",
      "[2026-01-05 16:54:27,115][oumi][rank0][pid:24381][MainThread][INFO]][repr_diversity_analyzer.py:556] Column 'conversation_text_content': 10/10 samples (100.0%) are redundant\n",
      "[2026-01-05 16:54:27,257][oumi][rank0][pid:24381][MainThread][INFO]][question_diversity_analyzer.py:464] Computing embeddings for 10 user questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 10/10 [00:00<00:00, 598.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-05 16:54:27,277][oumi][rank0][pid:24381][MainThread][INFO]][question_diversity_analyzer.py:469] Clustering 10 questions using dbscan...\n",
      "[2026-01-05 16:54:27,280][oumi][rank0][pid:24381][MainThread][INFO]][question_diversity_analyzer.py:482] Found 0 clusters, 10 unique/diverse questions (not similar to others)\n",
      "[2026-01-05 16:54:27,282][oumi][rank0][pid:24381][MainThread][INFO]][fasttext_analyzer.py:436] Analyzing language for column: text_content\n",
      "[2026-01-05 16:54:27,288][oumi][rank0][pid:24381][MainThread][INFO]][ifd_analyzer.py:643] Detected conversation format. Computing IFD for assistant messages using preceding user messages as instructions.\n",
      "[2026-01-05 16:54:29,419][oumi][rank0][pid:24381][MainThread][INFO]][ifd_analyzer.py:521] IFD analysis complete. Processed 10 assistant messages out of 10 total.\n",
      "[2026-01-05 16:54:29,421][oumi][rank0][pid:24381][MainThread][INFO]][repr_diversity_analyzer.py:363] Computing diversity scores for 30 samples in column 'text_content'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 30/30 [00:00<00:00, 160.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-05 16:54:29,610][oumi][rank0][pid:24381][MainThread][INFO]][repr_diversity_analyzer.py:230] Computing nearest neighbor distances for 30 samples (k=5)...\n",
      "[2026-01-05 16:54:29,613][oumi][rank0][pid:24381][MainThread][INFO]][repr_diversity_analyzer.py:556] Column 'text_content': 19/30 samples (63.3%) are redundant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanarman/miniconda3/envs/oumi/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/ryanarman/miniconda3/envs/oumi/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total conversations analyzed: 10\n"
     ]
    }
   ],
   "source": [
    "# Run the analysis\n",
    "analyzer.analyze_dataset()\n",
    "\n",
    "# The results are stored in analyzer object\n",
    "if analyzer._analysis_results:\n",
    "    print(\n",
    "        f\"Total conversations analyzed: {analyzer._analysis_results.conversations_analyzed}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07ae1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(schema): 186\n",
      "len(merged_columns): 186\n"
     ]
    }
   ],
   "source": [
    "schema = analyzer.get_schema()\n",
    "print(f\"len(schema): {len(schema)}\")\n",
    "merged_columns = analyzer.analysis_df.columns\n",
    "print(f\"len(merged_columns): {len(merged_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c2ff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['length',\n",
       " 'diversity',\n",
       " 'format',\n",
       " 'quality',\n",
       " 'training_quality',\n",
       " 'cost',\n",
       " 'content_pattern',\n",
       " 'question_diversity',\n",
       " 'fasttext',\n",
       " 'ifd',\n",
       " 'repr_diversity',\n",
       " 'task_category',\n",
       " 'safety',\n",
       " 'difficulty',\n",
       " 'instruct_reward',\n",
       " 'input_quality',\n",
       " 'conversation_structure',\n",
       " 'response_completeness']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer_names = [a.instance_id for a in config.analyzers]\n",
    "analyzer_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ee896",
   "metadata": {},
   "source": [
    "# Conv level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a9dc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['length',\n",
       " 'diversity',\n",
       " 'format',\n",
       " 'quality',\n",
       " 'training_quality',\n",
       " 'cost',\n",
       " 'content_pattern',\n",
       " 'question_diversity',\n",
       " 'fasttext',\n",
       " 'ifd',\n",
       " 'repr_diversity',\n",
       " 'task_category',\n",
       " 'safety',\n",
       " 'difficulty',\n",
       " 'instruct_reward',\n",
       " 'input_quality',\n",
       " 'conversation_structure',\n",
       " 'response_completeness']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e71af10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_index</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>num_messages</th>\n",
       "      <th>conversation_text_content</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>conversation_text_content__length__token_count</th>\n",
       "      <th>conversation_text_content__diversity__unique_words_ratio</th>\n",
       "      <th>conversation_text_content__format__has_markdown</th>\n",
       "      <th>conversation_text_content__format__has_json</th>\n",
       "      <th>...</th>\n",
       "      <th>conversation_text_content__input_quality__tier</th>\n",
       "      <th>conversation_text_content__input_quality__score</th>\n",
       "      <th>conversation_text_content__input_quality__is_ambiguous</th>\n",
       "      <th>conversation_text_content__input_quality__is_answerable</th>\n",
       "      <th>conversation_text_content__input_quality__has_sufficient_context</th>\n",
       "      <th>conversation_text_content__response_completeness__is_complete</th>\n",
       "      <th>conversation_text_content__response_completeness__score</th>\n",
       "      <th>conversation_text_content__response_completeness__ends_naturally</th>\n",
       "      <th>conversation_text_content__response_completeness__has_conclusion</th>\n",
       "      <th>conversation_text_content__response_completeness__truncation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a banking intent c...</td>\n",
       "      <td>52</td>\n",
       "      <td>request_refund</td>\n",
       "      <td>1806</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>fair</td>\n",
       "      <td>0.42</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>incomplete_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a banking intent c...</td>\n",
       "      <td>69</td>\n",
       "      <td>verify_my_identity</td>\n",
       "      <td>1805</td>\n",
       "      <td>0.512707</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.66</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>incomplete_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a banking intent c...</td>\n",
       "      <td>59</td>\n",
       "      <td>top_up_failed</td>\n",
       "      <td>1801</td>\n",
       "      <td>0.518313</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.66</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>incomplete_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a banking intent c...</td>\n",
       "      <td>54</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "      <td>1807</td>\n",
       "      <td>0.513782</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.66</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>incomplete_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a banking intent c...</td>\n",
       "      <td>57</td>\n",
       "      <td>top_up_by_card_charge</td>\n",
       "      <td>1804</td>\n",
       "      <td>0.517127</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.66</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>incomplete_list</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_index conversation_id  num_messages  \\\n",
       "0                   0               0             3   \n",
       "1                   1               1             3   \n",
       "2                   2               2             3   \n",
       "3                   3               3             3   \n",
       "4                   4               4             3   \n",
       "\n",
       "                           conversation_text_content  label  \\\n",
       "0  <|im_start|>system\\nYou are a banking intent c...     52   \n",
       "1  <|im_start|>system\\nYou are a banking intent c...     69   \n",
       "2  <|im_start|>system\\nYou are a banking intent c...     59   \n",
       "3  <|im_start|>system\\nYou are a banking intent c...     54   \n",
       "4  <|im_start|>system\\nYou are a banking intent c...     57   \n",
       "\n",
       "                       label_name  \\\n",
       "0                  request_refund   \n",
       "1              verify_my_identity   \n",
       "2                   top_up_failed   \n",
       "3  supported_cards_and_currencies   \n",
       "4           top_up_by_card_charge   \n",
       "\n",
       "   conversation_text_content__length__token_count  \\\n",
       "0                                            1806   \n",
       "1                                            1805   \n",
       "2                                            1801   \n",
       "3                                            1807   \n",
       "4                                            1804   \n",
       "\n",
       "   conversation_text_content__diversity__unique_words_ratio  \\\n",
       "0                                           0.516556          \n",
       "1                                           0.512707          \n",
       "2                                           0.518313          \n",
       "3                                           0.513782          \n",
       "4                                           0.517127          \n",
       "\n",
       "   conversation_text_content__format__has_markdown  \\\n",
       "0                                             True   \n",
       "1                                             True   \n",
       "2                                             True   \n",
       "3                                             True   \n",
       "4                                             True   \n",
       "\n",
       "   conversation_text_content__format__has_json  ...  \\\n",
       "0                                        False  ...   \n",
       "1                                        False  ...   \n",
       "2                                        False  ...   \n",
       "3                                        False  ...   \n",
       "4                                        False  ...   \n",
       "\n",
       "   conversation_text_content__input_quality__tier  \\\n",
       "0                                            fair   \n",
       "1                                            good   \n",
       "2                                            good   \n",
       "3                                            good   \n",
       "4                                            good   \n",
       "\n",
       "   conversation_text_content__input_quality__score  \\\n",
       "0                                             0.42   \n",
       "1                                             0.66   \n",
       "2                                             0.66   \n",
       "3                                             0.66   \n",
       "4                                             0.66   \n",
       "\n",
       "  conversation_text_content__input_quality__is_ambiguous  \\\n",
       "0                                               True       \n",
       "1                                              False       \n",
       "2                                              False       \n",
       "3                                              False       \n",
       "4                                              False       \n",
       "\n",
       "   conversation_text_content__input_quality__is_answerable  \\\n",
       "0                                               True         \n",
       "1                                               True         \n",
       "2                                               True         \n",
       "3                                               True         \n",
       "4                                               True         \n",
       "\n",
       "   conversation_text_content__input_quality__has_sufficient_context  \\\n",
       "0                                               True                  \n",
       "1                                               True                  \n",
       "2                                               True                  \n",
       "3                                               True                  \n",
       "4                                               True                  \n",
       "\n",
       "   conversation_text_content__response_completeness__is_complete  \\\n",
       "0                                              False               \n",
       "1                                              False               \n",
       "2                                              False               \n",
       "3                                              False               \n",
       "4                                              False               \n",
       "\n",
       "   conversation_text_content__response_completeness__score  \\\n",
       "0                                                0.4         \n",
       "1                                                0.4         \n",
       "2                                                0.4         \n",
       "3                                                0.4         \n",
       "4                                                0.4         \n",
       "\n",
       "  conversation_text_content__response_completeness__ends_naturally  \\\n",
       "0                                              False                 \n",
       "1                                              False                 \n",
       "2                                              False                 \n",
       "3                                              False                 \n",
       "4                                              False                 \n",
       "\n",
       "   conversation_text_content__response_completeness__has_conclusion  \\\n",
       "0                                              False                  \n",
       "1                                              False                  \n",
       "2                                              False                  \n",
       "3                                              False                  \n",
       "4                                              False                  \n",
       "\n",
       "   conversation_text_content__response_completeness__truncation_type  \n",
       "0                                    incomplete_list                  \n",
       "1                                    incomplete_list                  \n",
       "2                                    incomplete_list                  \n",
       "3                                    incomplete_list                  \n",
       "4                                    incomplete_list                  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.conversation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d56f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer: length\n",
      "metric: token_count\n",
      "description: Token count for conversation_text_content\n",
      "value: 1806\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.analyze.column_utils import (\n",
    "    filter_analyzer_columns,\n",
    "    get_analyzer_columns_by_analyzer,\n",
    "    parse_analyzer_column_name,\n",
    ")\n",
    "\n",
    "conv_columns = analyzer.conversation_df.columns\n",
    "row = analyzer.conversation_df.iloc[0]\n",
    "\n",
    "# Choose the analzyer to analyze\n",
    "analyzer_name = analyzer_names[0]\n",
    "\n",
    "\n",
    "filtered_cols = filter_analyzer_columns(conv_columns, analyzer_id=analyzer_name)\n",
    "if filtered_cols:\n",
    "    print(f\"Analyzer: {analyzer_name}\")\n",
    "    info = parse_analyzer_column_name(filtered_cols[0])\n",
    "    # print(\"\\nInput:\")\n",
    "    # print(f\"source_column: {info.source_column}\")\n",
    "    # print(f\"{row[info.source_column]}\\n\")\n",
    "\n",
    "    for col in filtered_cols:\n",
    "        info = parse_analyzer_column_name(col)\n",
    "        print(f\"metric: {info.metric_name}\")\n",
    "        # print(f\"type: {schema[col]['type']}\")\n",
    "        # print(f\"content_type: {schema[col]['content_type']}\")\n",
    "        print(f\"description: {schema[col]['description']}\")\n",
    "        print(f\"value: {row[col]}\")\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(f\"No columns found for analyzer: {analyzer_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abfccb",
   "metadata": {},
   "source": [
    "# Message level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb677ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer: length\n",
      "\n",
      "Input:\n",
      "[user]: If I bought something I didn't like, can I get a refund?\n",
      "\n",
      "If I bought something I didn't like, can I get a refund?\n",
      "\n",
      "metric: token_count\n",
      "description: Token count for text_content\n",
      "value: 14\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.analyze.column_utils import (\n",
    "    filter_analyzer_columns,\n",
    "    get_analyzer_columns_by_analyzer,\n",
    "    parse_analyzer_column_name,\n",
    ")\n",
    "\n",
    "msg_columns = analyzer.message_df.columns\n",
    "row = analyzer.message_df.iloc[1]\n",
    "\n",
    "# Choose the analzyer to analyze\n",
    "analyzer_name = analyzer_names[0]\n",
    "\n",
    "\n",
    "filtered_cols = filter_analyzer_columns(msg_columns, analyzer_id=analyzer_name)\n",
    "if filtered_cols:\n",
    "    print(f\"Analyzer: {analyzer_name}\")\n",
    "    info = parse_analyzer_column_name(filtered_cols[0])\n",
    "\n",
    "    print(\"\\nInput:\")\n",
    "    print(f\"[{row['role']}]: {row[info.source_column]}\\n\")\n",
    "    # print(f\"source_column: {info.source_column}\")\n",
    "    print(f\"{row[info.source_column]}\\n\")\n",
    "\n",
    "    for col in filtered_cols:\n",
    "        info = parse_analyzer_column_name(col)\n",
    "        print(f\"metric: {info.metric_name}\")\n",
    "        # print(f\"type: {schema[col]['type']}\")\n",
    "        # print(f\"content_type: {schema[col]['content_type']}\")\n",
    "        print(f\"description: {schema[col]['description']}\")\n",
    "        print(f\"value: {row[col]}\")\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(f\"No columns found for analyzer: {analyzer_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782aee00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
