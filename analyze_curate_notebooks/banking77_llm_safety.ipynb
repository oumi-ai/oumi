{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470e1fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available preset prompts: ['instruction_quality', 'response_quality', 'conversation_coherence', 'safety', 'helpfulness', 'factuality']\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.analyze.llm_judge_analyzer import LLMJudgeAnalyzer\n",
    "\n",
    "print(\"Available preset prompts:\", LLMJudgeAnalyzer.list_presets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334e3fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS has been disabled - forcing CPU-only mode\n",
      "PyTorch device: cpu\n",
      "PyTorch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# IMPORTANT: Set these BEFORE importing torch or any ML libraries\n",
    "# Disable all GPU/MPS backends to prevent crashes with IFD analyzer\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Disable CUDA\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # Disable MPS memory allocation\n",
    "os.environ[\"DISABLE_MPS_COMPAT\"] = \"1\"  # Additional MPS disable flag\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"  # Disable HuggingFace telemetry\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Allow model downloads\n",
    "\n",
    "# Force CPU usage in PyTorch to avoid MPS crashes\n",
    "import torch\n",
    "\n",
    "# Forcefully disable MPS before anything else\n",
    "torch.set_default_device(\"cpu\")\n",
    "if hasattr(torch.backends, \"mps\"):\n",
    "    # Monkey-patch to prevent MPS usage\n",
    "    original_is_available = torch.backends.mps.is_available\n",
    "    torch.backends.mps.is_available = lambda: False\n",
    "    print(\"MPS has been disabled - forcing CPU-only mode\")\n",
    "else:\n",
    "    print(\"Using CPU for all computations\")\n",
    "\n",
    "print(f\"PyTorch device: {torch.get_default_device()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fd63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oumi.core.configs import AnalyzeConfig, SampleAnalyzerParams\n",
    "\n",
    "llm_safety_params = SampleAnalyzerParams(\n",
    "    id=\"llm_judge\",\n",
    "    params={\n",
    "        # Use a preset prompt (available: instruction_quality, response_quality,\n",
    "        # conversation_coherence, safety, helpfulness, factuality)\n",
    "        \"prompt_preset\": \"safety\",\n",
    "        # Inference configuration\n",
    "        \"inference_config\": {\n",
    "            \"model_name\": \"gpt-4o-mini\",  # or \"gpt-4o\", \"claude-3-5-sonnet-20241022\", etc.\n",
    "            \"engine\": \"openai\",  # or \"vllm\", \"native\" for local models\n",
    "            \"temperature\": 0.1,  # Low temperature for consistent judgments\n",
    "            \"max_tokens\": 256,\n",
    "            # For OpenAI, API key is read from OPENAI_API_KEY env var by default\n",
    "            # For Anthropic, use ANTHROPIC_API_KEY env var\n",
    "            # Or specify explicitly:\n",
    "            # \"api_key_env\": \"OPENAI_API_KEY\",  # or \"ANTHROPIC_API_KEY\"\n",
    "        },\n",
    "        \"batch_size\": 10,  # Process 10 samples at a time\n",
    "        \"max_text_length\": 4000,  # Truncate long texts\n",
    "        \"parse_json_response\": True,  # Parse JSON from LLM response\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50f608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 16:46:52,226][oumi][rank0][pid:69225][MainThread][INFO]][base_map_dataset.py:91] Creating map dataset (type: TextSftJsonLinesDataset)... dataset_name: 'custom'\n",
      "[2025-12-30 16:46:52,227][oumi.utils.analysis_utils][rank0][pid:69225][MainThread][INFO]][analysis_utils.py:225] Loaded text dataset from: /Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\n",
      "[2025-12-30 16:46:52,228][oumi][rank0][pid:69225][MainThread][INFO]][dataset_analyzer.py:154] Loaded dataset from config: None\n",
      "[2025-12-30 16:46:52,228][oumi][rank0][pid:69225][MainThread][INFO]][dataset_analyzer.py:304] Initialized sample analyzer: llm_judge\n",
      "[2025-12-30 16:46:52,229][oumi][rank0][pid:69225][MainThread][INFO]][dataset_analyzer.py:347] Starting analysis of dataset: None\n",
      "[2025-12-30 16:46:52,229][oumi][rank0][pid:69225][MainThread][INFO]][dataset_analyzer.py:348] Using 1 sample analyzers: ['llm_judge']\n",
      "[2025-12-30 16:46:52,230][oumi][rank0][pid:69225][MainThread][INFO]][dataset_analyzer.py:371] Analyzing 5 of 8002 conversations\n",
      "[2025-12-30 16:46:52,230][oumi][rank0][pid:69225][MainThread][INFO]][dataset_analyzer.py:421] Converting conversation dataset with 8002 items\n",
      "[2025-12-30 16:46:52,231][oumi][rank0][pid:69225][MainThread][INFO]][dataset_analyzer.py:428] Limiting analysis to first 5 items (dataset has 8002 total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Unknown Dataset to DataFrames: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00<00:00, 1461.53item/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 16:46:52,279][oumi][rank0][pid:69225][MainThread][INFO]][llm_judge_analyzer.py:444] Initialized LLM Judge with model: gpt-4o-mini, engine: openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:08<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 16:47:00,406][oumi][rank0][pid:69225][MainThread][INFO]][llm_judge_analyzer.py:679] Batch of 10: 7 unique to evaluate, 3 duplicates, 0 from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 4/7 [00:06<00:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 16:47:09,750][oumi][rank0][pid:69225][ThreadPoolExecutor-7_0][WARNING]][adaptive_concurrency_controller.py:237] Entering warmup state, but concurrency is already at maximum value. Consider raising the max concurrency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:12<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-30 16:47:13,207][oumi][rank0][pid:69225][MainThread][INFO]][llm_judge_analyzer.py:679] Batch of 5: 4 unique to evaluate, 0 duplicates, 1 from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:06<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from oumi.core.configs import AnalyzeConfig\n",
    "from oumi.core.analyze.dataset_analyzer import DatasetAnalyzer\n",
    "\n",
    "# Create the full AnalyzeConfig\n",
    "config = AnalyzeConfig(\n",
    "    # Dataset configuration\n",
    "    dataset_path=\"/Users/ryanarman/code/scratch/ryan_hillclimbing_experiments/banking77/notebooks/data/banking77_train.jsonl\",\n",
    "    # Analysis configuration\n",
    "    sample_count=5,  # Analyze first 100 samples (LLM calls can be expensive!)\n",
    "    analyzers=[\n",
    "        llm_safety_params,\n",
    "    ],  # Just the LLM judge\n",
    "    # Output configuration\n",
    "    output_path=\"./analysis_output/banking77_llm_judge\",\n",
    "    generate_report=False,  # Optional: generate HTML report\n",
    ")\n",
    "\n",
    "# Finalize and run\n",
    "config.finalize_and_validate()\n",
    "\n",
    "from oumi.core.analyze.dataset_analyzer import DatasetAnalyzer\n",
    "\n",
    "analyzer = DatasetAnalyzer(config)\n",
    "analyzer.analyze_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07ae1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(schema): 16\n",
      "len(merged_columns): 16\n"
     ]
    }
   ],
   "source": [
    "schema = analyzer.get_schema()\n",
    "print(f\"len(schema): {len(schema)}\")\n",
    "merged_columns = analyzer.analysis_df.columns\n",
    "print(f\"len(merged_columns): {len(merged_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c2ff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llm_judge']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer_names = [a.instance_id for a in config.analyzers]\n",
    "analyzer_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ee896",
   "metadata": {},
   "source": [
    "# Conv level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d56f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer: llm_judge\n",
      "metric: score\n",
      "description: LLM judge score (0-10, higher = better quality)\n",
      "value: 10.0\n",
      "\n",
      "\n",
      "metric: label\n",
      "description: LLM judge label/category for the sample\n",
      "value: safe\n",
      "\n",
      "\n",
      "metric: reasoning\n",
      "description: LLM judge reasoning/explanation\n",
      "value: The text contains no harmful or dangerous content, personal information exposure, inappropriate language, misleading claims, or potential policy violations. It is a straightforward instruction set for a banking intent classifier.\n",
      "\n",
      "\n",
      "metric: raw_response\n",
      "description: Raw LLM response before parsing\n",
      "value: ```json\n",
      "{\n",
      "  \"score\": 10,\n",
      "  \"label\": \"safe\",\n",
      "  \"reasoning\": \"The text contains no harmful or dangerous content, personal information exposure, inappropriate language, misleading claims, or potential policy violations. It is a straightforward instruction set for a banking intent classifier.\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.analyze.column_utils import (\n",
    "    filter_analyzer_columns,\n",
    "    get_analyzer_columns_by_analyzer,\n",
    "    parse_analyzer_column_name,\n",
    ")\n",
    "\n",
    "conv_columns = analyzer.conversation_df.columns\n",
    "row = analyzer.conversation_df.iloc[0]\n",
    "\n",
    "# Choose the analzyer to analyze\n",
    "analyzer_name = analyzer_names[0]\n",
    "\n",
    "\n",
    "filtered_cols = filter_analyzer_columns(conv_columns, analyzer_id=analyzer_name)\n",
    "if filtered_cols:\n",
    "    print(f\"Analyzer: {analyzer_name}\")\n",
    "    info = parse_analyzer_column_name(filtered_cols[0])\n",
    "    # print(\"\\nInput:\")\n",
    "    # print(f\"source_column: {info.source_column}\")\n",
    "    # print(f\"{row[info.source_column]}\\n\")\n",
    "\n",
    "    for col in filtered_cols:\n",
    "        info = parse_analyzer_column_name(col)\n",
    "        print(f\"metric: {info.metric_name}\")\n",
    "        # print(f\"type: {schema[col]['type']}\")\n",
    "        # print(f\"content_type: {schema[col]['content_type']}\")\n",
    "        print(f\"description: {schema[col]['description']}\")\n",
    "        print(f\"value: {row[col]}\")\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(f\"No columns found for analyzer: {analyzer_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abfccb",
   "metadata": {},
   "source": [
    "# Message level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a7ee9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_index</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message_index</th>\n",
       "      <th>message_id</th>\n",
       "      <th>role</th>\n",
       "      <th>text_content</th>\n",
       "      <th>text_content__llm_judge__score</th>\n",
       "      <th>text_content__llm_judge__label</th>\n",
       "      <th>text_content__llm_judge__reasoning</th>\n",
       "      <th>text_content__llm_judge__raw_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>msg_0</td>\n",
       "      <td>system</td>\n",
       "      <td>You are a banking intent classifier. Classify ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text contains no harmful content, personal...</td>\n",
       "      <td>{\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>msg_1</td>\n",
       "      <td>user</td>\n",
       "      <td>If I bought something I didn't like, can I get...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text poses a general question about refund...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>msg_2</td>\n",
       "      <td>assistant</td>\n",
       "      <td>52</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text '52' does not contain any harmful or ...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>msg_0</td>\n",
       "      <td>system</td>\n",
       "      <td>You are a banking intent classifier. Classify ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text contains no harmful content, personal...</td>\n",
       "      <td>{\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>msg_1</td>\n",
       "      <td>user</td>\n",
       "      <td>If I'm getting my identity verified, what all ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text is a general inquiry about identity v...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 9,\\n  \"label\": \"safe\",\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>msg_2</td>\n",
       "      <td>assistant</td>\n",
       "      <td>69</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text '69' does not contain harmful or dang...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>msg_0</td>\n",
       "      <td>system</td>\n",
       "      <td>You are a banking intent classifier. Classify ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text contains no harmful content, personal...</td>\n",
       "      <td>{\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>msg_1</td>\n",
       "      <td>user</td>\n",
       "      <td>My top-up was rejected by an app.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text does not contain harmful or dangerous...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 9,\\n  \"label\": \"safe\",\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>msg_2</td>\n",
       "      <td>assistant</td>\n",
       "      <td>59</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text '59' does not contain any harmful or ...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>msg_0</td>\n",
       "      <td>system</td>\n",
       "      <td>You are a banking intent classifier. Classify ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text contains no harmful content, personal...</td>\n",
       "      <td>{\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>msg_1</td>\n",
       "      <td>user</td>\n",
       "      <td>I want to add funds to my account. What paymen...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text does not contain any harmful or dange...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>msg_2</td>\n",
       "      <td>assistant</td>\n",
       "      <td>54</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text '54' does not contain any harmful or ...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>msg_0</td>\n",
       "      <td>system</td>\n",
       "      <td>You are a banking intent classifier. Classify ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text contains no harmful content, personal...</td>\n",
       "      <td>{\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>msg_1</td>\n",
       "      <td>user</td>\n",
       "      <td>Is there a fee for adding funds with a credit ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text is a straightforward inquiry about a ...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>msg_2</td>\n",
       "      <td>assistant</td>\n",
       "      <td>57</td>\n",
       "      <td>10.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>The text '57' does not contain any harmful or ...</td>\n",
       "      <td>```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    conversation_index conversation_id  message_index message_id       role  \\\n",
       "0                    0               0              0      msg_0     system   \n",
       "1                    0               0              1      msg_1       user   \n",
       "2                    0               0              2      msg_2  assistant   \n",
       "3                    1               1              0      msg_0     system   \n",
       "4                    1               1              1      msg_1       user   \n",
       "5                    1               1              2      msg_2  assistant   \n",
       "6                    2               2              0      msg_0     system   \n",
       "7                    2               2              1      msg_1       user   \n",
       "8                    2               2              2      msg_2  assistant   \n",
       "9                    3               3              0      msg_0     system   \n",
       "10                   3               3              1      msg_1       user   \n",
       "11                   3               3              2      msg_2  assistant   \n",
       "12                   4               4              0      msg_0     system   \n",
       "13                   4               4              1      msg_1       user   \n",
       "14                   4               4              2      msg_2  assistant   \n",
       "\n",
       "                                         text_content  \\\n",
       "0   You are a banking intent classifier. Classify ...   \n",
       "1   If I bought something I didn't like, can I get...   \n",
       "2                                                  52   \n",
       "3   You are a banking intent classifier. Classify ...   \n",
       "4   If I'm getting my identity verified, what all ...   \n",
       "5                                                  69   \n",
       "6   You are a banking intent classifier. Classify ...   \n",
       "7                   My top-up was rejected by an app.   \n",
       "8                                                  59   \n",
       "9   You are a banking intent classifier. Classify ...   \n",
       "10  I want to add funds to my account. What paymen...   \n",
       "11                                                 54   \n",
       "12  You are a banking intent classifier. Classify ...   \n",
       "13  Is there a fee for adding funds with a credit ...   \n",
       "14                                                 57   \n",
       "\n",
       "    text_content__llm_judge__score text_content__llm_judge__label  \\\n",
       "0                             10.0                           safe   \n",
       "1                             10.0                           safe   \n",
       "2                             10.0                           safe   \n",
       "3                             10.0                           safe   \n",
       "4                              9.0                           safe   \n",
       "5                             10.0                           safe   \n",
       "6                             10.0                           safe   \n",
       "7                              9.0                           safe   \n",
       "8                             10.0                           safe   \n",
       "9                             10.0                           safe   \n",
       "10                            10.0                           safe   \n",
       "11                            10.0                           safe   \n",
       "12                            10.0                           safe   \n",
       "13                            10.0                           safe   \n",
       "14                            10.0                           safe   \n",
       "\n",
       "                   text_content__llm_judge__reasoning  \\\n",
       "0   The text contains no harmful content, personal...   \n",
       "1   The text poses a general question about refund...   \n",
       "2   The text '52' does not contain any harmful or ...   \n",
       "3   The text contains no harmful content, personal...   \n",
       "4   The text is a general inquiry about identity v...   \n",
       "5   The text '69' does not contain harmful or dang...   \n",
       "6   The text contains no harmful content, personal...   \n",
       "7   The text does not contain harmful or dangerous...   \n",
       "8   The text '59' does not contain any harmful or ...   \n",
       "9   The text contains no harmful content, personal...   \n",
       "10  The text does not contain any harmful or dange...   \n",
       "11  The text '54' does not contain any harmful or ...   \n",
       "12  The text contains no harmful content, personal...   \n",
       "13  The text is a straightforward inquiry about a ...   \n",
       "14  The text '57' does not contain any harmful or ...   \n",
       "\n",
       "                text_content__llm_judge__raw_response  \n",
       "0   {\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...  \n",
       "1   ```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...  \n",
       "2   ```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...  \n",
       "3   {\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...  \n",
       "4   ```json\\n{\\n  \"score\": 9,\\n  \"label\": \"safe\",\\...  \n",
       "5   ```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...  \n",
       "6   {\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...  \n",
       "7   ```json\\n{\\n  \"score\": 9,\\n  \"label\": \"safe\",\\...  \n",
       "8   ```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...  \n",
       "9   {\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...  \n",
       "10  ```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...  \n",
       "11  ```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...  \n",
       "12  {\\n  \"score\": 10,\\n  \"label\": \"safe\",\\n  \"reas...  \n",
       "13  ```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...  \n",
       "14  ```json\\n{\\n  \"score\": 10,\\n  \"label\": \"safe\",...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.message_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb677ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer: llm_judge\n",
      "\n",
      "Input:\n",
      "[user]\n",
      "metric: score\n",
      "description: LLM judge score (0-10, higher = better quality)\n",
      "value: 9.0\n",
      "\n",
      "\n",
      "metric: label\n",
      "description: LLM judge label/category for the sample\n",
      "value: safe\n",
      "\n",
      "\n",
      "metric: reasoning\n",
      "description: LLM judge reasoning/explanation\n",
      "value: The text is a general inquiry about identity verification and does not contain harmful content, personal information, inappropriate language, or misleading claims. However, it could be slightly concerning if it implies a context where identity verification is being misused, but overall, it is a safe question.\n",
      "\n",
      "\n",
      "metric: raw_response\n",
      "description: Raw LLM response before parsing\n",
      "value: ```json\n",
      "{\n",
      "  \"score\": 9,\n",
      "  \"label\": \"safe\",\n",
      "  \"reasoning\": \"The text is a general inquiry about identity verification and does not contain harmful content, personal information, inappropriate language, or misleading claims. However, it could be slightly concerning if it implies a context where identity verification is being misused, but overall, it is a safe question.\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.analyze.column_utils import (\n",
    "    filter_analyzer_columns,\n",
    "    get_analyzer_columns_by_analyzer,\n",
    "    parse_analyzer_column_name,\n",
    ")\n",
    "\n",
    "msg_columns = analyzer.message_df.columns\n",
    "row = analyzer.message_df.iloc[4]\n",
    "\n",
    "# Choose the analzyer to analyze\n",
    "analyzer_name = analyzer_names[0]\n",
    "\n",
    "\n",
    "filtered_cols = filter_analyzer_columns(msg_columns, analyzer_id=analyzer_name)\n",
    "if filtered_cols:\n",
    "    print(f\"Analyzer: {analyzer_name}\")\n",
    "    info = parse_analyzer_column_name(filtered_cols[0])\n",
    "\n",
    "    print(\"\\nInput:\")\n",
    "    print(f\"[{row['role']}]\")\n",
    "    # print(f\"{row[info.source_column]}\\n\")\n",
    "    # print(f\"source_column: {info.source_column}\")\n",
    "    # print(f\"{row[info.source_column]}\\n\")\n",
    "\n",
    "    for col in filtered_cols:\n",
    "        info = parse_analyzer_column_name(col)\n",
    "        print(f\"metric: {info.metric_name}\")\n",
    "        # print(f\"type: {schema[col]['type']}\")\n",
    "        # print(f\"content_type: {schema[col]['content_type']}\")\n",
    "        print(f\"description: {schema[col]['description']}\")\n",
    "        print(f\"value: {row[col]}\")\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(f\"No columns found for analyzer: {analyzer_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782aee00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}