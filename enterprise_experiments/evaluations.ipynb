{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9663a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset = json.load(\n",
    "    open(\n",
    "        \"/home/shanghong/oumi/enterprise_experiments/data/multilingual_thinking_test_new.json\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2372632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e62986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-14 19:45:47 [__init__.py:241] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:10<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from oumi.judges.simple_judge import SimpleJudge\n",
    "\n",
    "judge = SimpleJudge(\"judge_config.yaml\")\n",
    "outputs = judge.judge(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78efdf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JudgeOutput(raw_output='```json\\n{\\n  \"explanation\": \"The response provides a detailed breakdown of the nutritional value of an apple, including key nutrients, health benefits, and additional notes about the importance of the apple skin and variety. It stays focused on the user\\'s request for nutritional information and does not include unrelated content. The response is structured clearly and covers all relevant aspects of the nutritional value of an apple, as requested.\",\\n  \"judgment\": \"Yes\"\\n}\\n```', parsed_output={'explanation': \"The response provides a detailed breakdown of the nutritional value of an apple, including key nutrients, health benefits, and additional notes about the importance of the apple skin and variety. It stays focused on the user's request for nutritional information and does not include unrelated content. The response is structured clearly and covers all relevant aspects of the nutritional value of an apple, as requested.\", 'judgment': 'Yes'}, output_fields=[JudgeOutputField(field_key='explanation', field_type=<JudgeOutputType.TEXT: 'text'>, field_scores=None), JudgeOutputField(field_key='judgment', field_type=<JudgeOutputType.BOOL: 'bool'>, field_scores=None)], field_values={'explanation': \"The response provides a detailed breakdown of the nutritional value of an apple, including key nutrients, health benefits, and additional notes about the importance of the apple skin and variety. It stays focused on the user's request for nutritional information and does not include unrelated content. The response is structured clearly and covers all relevant aspects of the nutritional value of an apple, as requested.\", 'judgment': True}, field_scores={'explanation': None, 'judgment': 1.0}, response_format=<JudgeResponseFormat.JSON: 'json'>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4725cd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for output in outputs:\n",
    "    judgment = output.field_values[\"judgment\"]\n",
    "    ls.append(judgment)\n",
    "\n",
    "print(sum(ls) / len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_outputs = []\n",
    "for input, output in zip(dataset, outputs):\n",
    "    judgment = output.field_values[\"judgment\"]\n",
    "    explanation = output.field_values[\"explanation\"]\n",
    "    request = input[\"request\"]\n",
    "    response = input[\"response\"]\n",
    "    save_outputs.append(\n",
    "        {\n",
    "            \"request\": request,\n",
    "            \"response\": response,\n",
    "            \"judgment\": judgment,\n",
    "            \"explanation\": explanation,\n",
    "        }\n",
    "    )\n",
    "\n",
    "json.dump(\n",
    "    save_outputs,\n",
    "    open(\"output/multilingual_thinking_test_new_outputs.json\", \"w\"),\n",
    "    indent=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9023ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77f5c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open(\"data/1k_arxiv_val.jsonl\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c15b24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oumi.core.types.conversation import Conversation, Message, Role\n",
    "\n",
    "processed_data = []\n",
    "for d in data[:10]:\n",
    "    output = Conversation(\n",
    "        messages=[\n",
    "            Message(role=Role.SYSTEM, content=d[\"messages\"][0][\"content\"]),\n",
    "            Message(role=Role.USER, content=d[\"messages\"][1][\"content\"]),\n",
    "        ]\n",
    "    )\n",
    "    processed_data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-17 23:34:47,341][oumi][rank0][pid:3312362][MainThread][INFO]][models.py:544] Using the model's built-in chat template for model 'Qwen/Qwen3-8B'.\n",
      "INFO 10-17 23:34:47 [utils.py:326] non-default args: {'model': 'Qwen/Qwen3-8B', 'trust_remote_code': True, 'dtype': 'bfloat16', 'enable_prefix_caching': True, 'gpu_memory_utilization': 0.95, 'max_num_seqs': 10, 'disable_log_stats': True, 'enforce_eager': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-17 23:34:47 [__init__.py:711] Resolved architecture: Qwen3ForCausalLM\n",
      "INFO 10-17 23:34:47 [__init__.py:1750] Using max model len 40960\n",
      "INFO 10-17 23:34:47 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "INFO 10-17 23:34:47 [__init__.py:3565] Cudagraph is disabled under eager mode\n",
      "INFO 10-17 23:34:55 [__init__.py:241] Automatically detected platform cuda.\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:34:56 [core.py:636] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:34:56 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='Qwen/Qwen3-8B', speculative_config=None, tokenizer='Qwen/Qwen3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-8B, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":0,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":0,\"local_cache_dir\":null}\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:34:57 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m WARNING 10-17 23:34:57 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:34:57 [gpu_model_runner.py:1953] Starting to load model Qwen/Qwen3-8B...\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:34:57 [gpu_model_runner.py:1985] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:34:57 [cuda.py:328] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:34:58 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:00<00:02,  1.58it/s]\n",
      "Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:01<00:02,  1.48it/s]\n",
      "Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:02<00:01,  1.47it/s]\n",
      "Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:02<00:00,  1.60it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:02<00:00,  2.03it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:02<00:00,  1.77it/s]\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:35:01 [default_loader.py:262] Loading weights took 2.84 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:35:02 [gpu_model_runner.py:2007] Model loading took 15.2683 GiB and 3.992397 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:35:03 [gpu_worker.py:276] Available KV cache memory: 58.24 GiB\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:35:03 [kv_cache_utils.py:849] GPU KV cache size: 424,080 tokens\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:35:03 [kv_cache_utils.py:853] Maximum concurrency for 40,960 tokens per request: 10.35x\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:35:03 [core.py:214] init engine (profile, create kv cache, warmup model) took 1.25 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m INFO 10-17 23:35:04 [__init__.py:3565] Cudagraph is disabled under eager mode\n",
      "INFO 10-17 23:35:04 [llm.py:298] Supported_tasks: ['generate']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9161269c9fa40e5a20baf0b4b6a4138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=3315291)\u001b[0;0m WARNING 10-17 23:35:04 [cudagraph_dispatcher.py:101] cudagraph dispatching keys are not initialized. No cudagraph will be used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ad93c8f67443ff88852a70bfd2bf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation_id='c4523988-eb35-5bdd-b72e-b578a33ba318' messages=[SYSTEM: You are a document question-answering assistant. Your job is to answer user questions using only the content and structure of the provided document context.\n",
      "\n",
      "Follow these principles:\n",
      "\n",
      "1. Answer strictly based on the document. Do not use outside knowledge unless explicitly allowed.\n",
      "2. Adapt your answer to the style and tone requested (e.g., formal, concise, casual).\n",
      "3. Respect the expected answer format (e.g., yes/no, list, number, explanation).\n",
      "4. Use reasoning (temporal, arithmetic, logical, spatial) when necessary to synthesize answers from multiple parts of the document.\n",
      "5. If the document does not contain enough information to answer the question, reply with \"Not answerable from the document.\"\n",
      "6. Do not make assumptions or speculate.\n",
      "7. If multiple answers are possible, choose the best-supported one or note the ambiguity, depending on the task setup.\n",
      "8. Be clear, accurate, and context-aware.\n",
      "\n",
      "You may be shown structured documents, tables, or visual layouts. Interpret spatial relationships when relevant (e.g., rows, columns, nearby elements).\n",
      "\n",
      "Always prioritize accuracy, document grounding, and alignment with the user's question intent.\n",
      "\n",
      "Answer Attributes:\n",
      "Citation Requirement (Specifies whether and how the assistant should attribute its response to the source document or external references. Controls the presence and form of citations in the answer.): Explicit Citation (The assistant should clearly indicate the source of its information, using inline references, quotes, footnotes, or document pointers. This may include document section headers, line numbers, URLs, or citation styles depending on the use case.), USER: Context: 19\n",
      "20\n",
      "k\n",
      "0.0\n",
      "\n",
      "Config\n",
      "no-validation\n",
      "validation-binary\n",
      "\n",
      "validation-p75\n",
      "validation-p90\n",
      "\n",
      "Figure 7: More aggressive filtering tradeoffs between reduc-\n",
      "\n",
      "ing developer noise and increasing bug resolution rate.\n",
      "\n",
      "1.0\n",
      "\n",
      "Mean filtered fail-to-pass@k\n",
      "\n",
      "0.8\n",
      "\n",
      "Figure 9: Abstention and Validation Funnel. Our combined\n",
      "policies filter an initial set of 174 bugs, progressively nar-\n",
      "\n",
      "rowing the set to increase the quality of patches shown to\n",
      "a developer. Each stage reduces the number of bugs but in-\n",
      "\n",
      "creases the filtered fail-to-pass@1 rate, from a baseline of\n",
      "11.29% to 53% for the most selective configuration.\n",
      "\n",
      "0.6\n",
      "\n",
      "0.4\n",
      "\n",
      "0.2\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "k\n",
      "0.0\n",
      "\n",
      "6.4 RQ4: Validation on NPE and sanitizer bugs\n",
      "We further evaluate patch validation in bug categories that have\n",
      "more systematic information in their bug reports, and so are as-\n",
      "\n",
      "sumed good candidates for APR by construction (i.e., these bugs\n",
      "pass abstention by construction). We consider the machine-reported\n",
      "NPE and sanitizer bugs, whose bug reports always have a stack\n",
      "trace and reproduction test, respectively.\n",
      "\n",
      "Config\n",
      "no_filter(bugs=174)\n",
      "abstention(bugs=39)\n",
      "combined-binary(bugs=33)\n",
      "\n",
      "combined-p75(bugs=25)\n",
      "combined-p90(bugs=12)\n",
      "\n",
      "Figure 8: Abstention and validation are complementary,\n",
      "jointly they can raise filtered fail-to-pass@k.\n",
      "\n",
      "Figure 10 shows filtered-accept@k by manually inspecting the\n",
      "correctness of patches for NPE bugs, whose bug reports have stack\n",
      "traces. The baseline (build-and-test) filters patches that did not\n",
      "pass build and test regression checks. We observe that validation\n",
      "using binary judgment provide little improvement over these re-\n",
      "\n",
      "gression checks. However, validation using the more-aggressive\n",
      "percentile-threshold judgment can result in improvements to filtered-\n",
      "\n",
      "accept@1 of +8 percentage points and +24 percentage points, with\n",
      "75th and 90th percentile thresholds, respectively. No-spec valida-\n",
      "\n",
      "tion at 90th percentile produces a bigger filtered-accept@1 improve-\n",
      "\n",
      "ment than that at 75th percentile (+20 percentage points vs +24\n",
      "percentage points relative to regression checks), but both of them\n",
      "perform worse than the spec-based variant at 90th percentile (i.e.,\n",
      "validation-p90).\n",
      "\n",
      "success of the attempt, while the abstention policy is more likely\n",
      "to reflect overall quality of bug report.\n",
      "\n",
      "Figure 9 visualizes the process of our dual-policy framework as a\n",
      "configurable funnel. The funnel presents the filtered fail-to-pass@1\n",
      "rate on human-reported bugs at each stage. Starting with the full\n",
      "set of 174 bugs, where our APR system has a baseline pass@1\n",
      "rate of 11.29%, the abstention policy first filters this down to 39\n",
      "more promising bugs, increasing the filtered fail-to-pass@1 rate\n",
      "to 21.5%. The combined validation policies (combined-*) further\n",
      "refine this set. The combined-binary policy leaves 33 bugs with a\n",
      "rate of 29%. More aggressive filtering with combined-p75 and the\n",
      "strictest combined-p90 variant narrow the funnel to 25 and 12 bugs,\n",
      "respectively, boosting the quality of patches to achieve high filtered\n",
      "fail-to-pass@1 rates of 35% and 53%. Overall, Figure 9 demonstrates\n",
      "the trade-off between the volume of bugs attempted and the preci-\n",
      "\n",
      "sion of the patches ultimately shown to developers.\n",
      "\n",
      "Figure 11 shows mean filtered-accept@k (based on manual in-\n",
      "\n",
      "spection of patch correctness) for sanitizer bugs, whose bug reports\n",
      "have reproduction tests. As a result, we filter any patches first by\n",
      "the reproduction test and then apply the validation policy. The\n",
      "baseline (repro-test) filters patches that did not pass reproduction\n",
      "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair\n",
      "\n",
      "Sanitizer # Bugs repro-test validation-binary validation-p75 validation-p90\n",
      "data_race 17 3.11 2.93 2.43 3.04\n",
      "Fuzz+property testing 3 NA NA NA NA\n",
      "heap_buffer_overflow 1 1.43 1.43 1.54 1.54\n",
      "invalid_bool_load 2 1.49 1.65 1.25 NA\n",
      "invalid_enum_load 1 NA NA NA NA\n",
      "leak_detected 2 1.52 1.72 4.29 3.81\n",
      "misaligned_pointer_use 6 1.34 1.33 2.14 1.43\n",
      "null_pointer_use 1 2.86 3.33 NA NA\n",
      "signed_integer_overflow 2 1.2 1.27 1.56 2.5\n",
      "stack_use_after_scope 2 1.85 1.85 1.67 3.33\n",
      "use_of_uninitialized_value 13 2.05 1.93 2.05 1.95\n",
      "\n",
      "1.0\n",
      "\n",
      "0.8\n",
      "\n",
      "mean filtered accept@k\n",
      "\n",
      "0.6\n",
      "\n",
      "0.4\n",
      "\n",
      "0.2\n",
      "\n",
      "5\n",
      "\n",
      "k\n",
      "0.0\n",
      "\n",
      "Table 2: Lift (filtered-accept@1 / original accept@1) varies\n",
      "for different sanitizer bug types. The higher the better.\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Config\n",
      "build-and-test(bugs=135)\n",
      "validation-binary(bugs=104)\n",
      "validation-p75(bugs=43)\n",
      "validation-p90(bugs=21)\n",
      "no-spec-validation-binary(bugs=132)\n",
      "no-spec-validation-p75(bugs=53)\n",
      "no-spec-validation-p90(bugs=24)\n",
      "\n",
      "Metric Abstain AttemptRepair\n",
      "Average # code-like identifiers 3.03 5.28\n",
      "Average character length 771.67 1239.26\n",
      "Fraction with repository root 0.12 0.31\n",
      "Fraction possible build rule 0.01 0.03\n",
      "Fraction Markdown code ticks 0.17 0.20\n",
      "Table 3: Abstention-accepted bugs more frequently have the\n",
      "presence of the monorepo root directory.\n",
      "\n",
      "Figure 10: More aggressive validation can increase filtered\n",
      "accept@k for NPE bugs.\n",
      "\n",
      "1.0\n",
      "\n",
      "0.8\n",
      "\n",
      "mean filtered accept@k\n",
      "\n",
      "0.6\n",
      "\n",
      "0.4\n",
      "\n",
      "to reproduction test filtering slightly reduces lift, while adding the\n",
      "70th percentile validation keeps the same lift. For data races, adding\n",
      "validation actually reduces lift compared to just using reproduction\n",
      "tests. We hypothesize that: for these bugs, a patch that adds lock-\n",
      "\n",
      "ing mechanism indeed resolves the data race and can pass patch\n",
      "validation, but still may not be an acceptable solution for a Google\n",
      "developer if it introduces downsides such as larger critical sections.\n",
      "For some categories, e.g. leaks and misaligned pointer usage, a less\n",
      "aggressive validation (75th percentile) achieves better lift than a\n",
      "more aggressive one (90th percentile).\n",
      "\n",
      "0.2\n",
      "\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "k\n",
      "0.0\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "Config\n",
      "repro-test(bugs=48)\n",
      "\n",
      "no-spec-validation-binary(bugs=48)\n",
      "no-spec-validation-p75(bugs=32)\n",
      "no-spec-validation-p90(bugs=21)\n",
      "\n",
      "validation-binary(bugs=45)\n",
      "validation-p75(bugs=30)\n",
      "validation-p90(bugs=15)\n",
      "\n",
      "Figure 11: Aggressive validation increases filtered accept@1\n",
      "for sanitizer bugs. But just reviewing more patches can lead\n",
      "to higher filtered-accept@k, with 4 patches sufficing.\n",
      "\n",
      "We hypothesize that a true bug reproduction test, such as that\n",
      "included in the sanitizer’s bug report, results in a set of plausible\n",
      "patches that are increasingly difficult for validation to assess, com-\n",
      "\n",
      "pared to the patches produced for the less-constrained bugs such as\n",
      "the human-reported ones. This points to a few future research di-\n",
      "\n",
      "rections. First, generating additional executable tests to help assess\n",
      "patch correctness is a particularly promising direction. For exam-\n",
      "\n",
      "ple, AutoCodeSherpa [15] generates property-based tests to assist\n",
      "reviewing and filtering agent-generated patches. As pointed out,\n",
      "after filtering with the reproduction test, sampling  = 4 produces\n",
      "a mean filtered accept rate of 0.74. Supporting developers when\n",
      "inspecting more patches may help maintain a high success rate.\n",
      "\n",
      "tests. For sanitizer bugs, validation can lift filtered-accept\n",
      "\n",
      "Question: How does the dual-policy framework's combination of abstention and validation policies improve patch quality, and what are the specific performance improvements achieved at different filtering stages?, ASSISTANT: <think>\n",
      "Okay, let's tackle this question. The user is asking how the dual-policy framework combines abstention and validation to improve patch quality and what specific performance improvements are achieved at different stages.\n",
      "\n",
      "First, I need to recall the document content. From the context provided, there are several figures and tables discussing the framework. Figure 9 mentions a funnel process where the number of bugs decreases through stages, and the filtered fail-to-pass@1 rate increases. The initial set is 174 bugs with a baseline pass@1 rate of 11.29%. The abstention policy reduces this to 39 bugs, increasing the fail-to-pass@1 rate to 21.5%. Then, combined validation policies further refine it. The combined-binary policy leaves 33 bugs with a 29% rate. More aggressive filters like combined-p75 and combined-p90 narrow it down to 25 and 12 bugs, with rates of 35% and 53% respectively. \n",
      "\n",
      "So the combination of abstention and validation reduces the number of bugs, which increases the quality of the patches shown to developers. The performance improvements are the increases in the filtered fail-to-pass@1 rate at each stage. The answer should mention the stages and the corresponding rates. Also, the document mentions that validation using percentile thresholds (p75 and p90) provides better improvements than binary judgment, especially for certain bug types. \n",
      "\n",
      "I need to make sure to reference the specific numbers from the figures and tables. For example, Figure 9 shows the progression from 174 to 39 to 33, 25, 12 bugs with the corresponding rates. Also, Table 2 and Table 3 might have more data, but the user's question is about the framework's combination, so focusing on Figure 9 and the related text is key. \n",
      "\n",
      "The answer should explain that abstention first filters out less promising bugs, then validation further refines the set, leading to higher quality patches. The specific improvements are the increases in the filtered fail-to-pass@1 rate at each stage. Also, mention that more aggressive validation (p75 and p90) leads to higher rates but with fewer bugs. \n",
      "\n",
      "I need to check if the document mentions any specific performance metrics beyond the rates. For example, in Figure 10 and 11, there are mentions of filtered-accept@k improvements, but the main question is about the dual-policy framework's stages. The answer should focus on the funnel stages and the corresponding performance metrics. \n",
      "\n",
      "So, the answer should outline the stages: initial set (174 bugs, 11.29%), after abstention (39 bugs, 21.5%), then combined policies leading to 33 (29%), 25 (35%), and 12 (53%) bugs. The improvement is the increase in the filtered fail-to-pass@1 rate. Also, note that the combined policies (validation-p90) achieve the highest rate but with fewer bugs, showing a trade-off between volume and precision. \n",
      "\n",
      "I need to make sure all numbers are correctly cited from the document. The user might be looking for the specific percentages and the stages where they occur. Also, the answer should mention that the combination of abstention and validation policies leads to higher quality patches by reducing noise and increasing the resolution rate, as mentioned in Figure 7 and the discussion around the funnel.\n",
      "</think>\n",
      "\n",
      "The dual-policy framework combines **abstention** and **validation** to improve patch quality by progressively filtering bugs, reducing noise, and increasing the precision of patches shown to developers. Here’s how it works and the specific performance improvements at each stage:\n",
      "\n",
      "1. **Initial Stage (Full Bug Set):**  \n",
      "   - Starts with **174 bugs**, where the baseline **filtered fail-to-pass@1 rate** is **11.29%** (Figure 9).  \n",
      "   - This represents the raw set of bugs before any filtering.\n",
      "\n",
      "2. **Abstention Policy:**  \n",
      "   - Filters the set to **39 bugs**, increasing the **filtered fail-to-pass@1 rate to 21.5%**.  \n",
      "   - This stage prioritizes bugs with higher potential for successful repair, based on the quality of the bug report (e.g., presence of repository root, test cases).\n",
      "\n",
      "3. **Combined Validation Policies:**  \n",
      "   - **Combined-binary** further narrows the set to **33 bugs**, boosting the rate to **29%**.  \n",
      "   - **Combined-p75** reduces it to **25 bugs** with a **35%** rate.  \n",
      "   - **Combined-p90** (most aggressive) narrows it to **12 bugs**, achieving the highest **53%** rate (Figure 9).  \n",
      "\n",
      "### Key Improvements:  \n",
      "- **Trade-off Between Volume and Precision:**  \n",
      "  Each stage reduces the number of bugs but increases the **filtered fail-to-pass@1 rate**, reflecting higher patch quality. For example, the strictest configuration (combined-p90) achieves **53%** precision, up from the baseline **11.29%**.  \n",
      "- **Validation Thresholds:**  \n",
      "  Aggressive percentile thresholds (p75/p90) outperform binary validation. For instance, **validation-p90** improves **filtered-accept@1** by **+24%** (vs. regression checks) and **+20%** (vs. p75), though it performs worse than spec-based validation for some categories (e.g., sanitizer bugs).  \n",
      "- **Bug Type-Specific Effects:**  \n",
      "  For **NPE bugs**, validation-p90 improves **filtered-accept@1** by **+24%** over regression checks (Figure 10). For **sanitizer bugs**, validation-p90 also shows significant gains (Table 2), though some categories (e.g., data races) show reduced lift due to trade-offs between correctness and practicality.  \n",
      "\n",
      "### Conclusion:  \n",
      "The dual-policy framework enhances patch quality by iteratively filtering bugs, with validation policies (especially percentile-based thresholds) significantly improving precision. The most selective configuration (combined-p90) achieves the highest **53%** filtered fail-to-pass@1 rate, though it sacrifices volume, highlighting the trade-off between precision and the number of bugs attempted.  \n",
      "\n",
      "**Citations:**  \n",
      "- Figure 9 [1] describes the funnel process and metrics.  \n",
      "- Table 2 [2] and Figure 10 [3] provide specific improvements for sanitizer and NPE bugs.  \n",
      "- Text discussing validation thresholds and bug types [4].  \n",
      "\n",
      "[1] Figure 9: \"progressively narrowing the set to increase the quality of patches shown to a developer.\"  \n",
      "[2] Table 2: \"validation-p90 improves filtered-accept@1 by +24% over regression checks.\"  \n",
      "[3] Figure 10: \"validation-p90 results in improvements to filtered-accept@1 of +8% and +24%.\"  \n",
      "[4] Text: \"validation-p90 performs worse than the spec-based variant at 90th percentile.\"] metadata={}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR 10-17 23:36:11 [core_client.py:562] Engine core proc EngineCore_0 died unexpectedly, shutting down client.\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.configs import InferenceConfig\n",
    "from oumi.inference import VLLMInferenceEngine\n",
    "\n",
    "config = InferenceConfig.from_yaml(\n",
    "    \"/home/shanghong/oumi/enterprise_experiments/configs/infer.yaml\"\n",
    ")\n",
    "\n",
    "engine = VLLMInferenceEngine(\n",
    "    model_params=config.model,\n",
    "    generation_params=config.generation,\n",
    "    gpu_memory_utilization=0.95,\n",
    "    max_num_seqs=10,\n",
    ")\n",
    "\n",
    "results = engine.infer(input=processed_data, inference_config=config)\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0135cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=None content='<think>\\nOkay, let\\'s tackle this question. The user is asking how the dual-policy framework combines abstention and validation to improve patch quality and what specific performance improvements are achieved at different stages.\\n\\nFirst, I need to recall the document content. From the context provided, there are several figures and tables discussing the framework. Figure 9 mentions a funnel process where the number of bugs decreases through stages, and the filtered fail-to-pass@1 rate increases. The initial set is 174 bugs with a baseline pass@1 rate of 11.29%. The abstention policy reduces this to 39 bugs, increasing the fail-to-pass@1 rate to 21.5%. Then, combined validation policies further refine it. The combined-binary policy leaves 33 bugs with a 29% rate. More aggressive filters like combined-p75 and combined-p90 narrow it down to 25 and 12 bugs, with rates of 35% and 53% respectively. \\n\\nSo the combination of abstention and validation reduces the number of bugs, which increases the quality of the patches shown to developers. The performance improvements are the increases in the filtered fail-to-pass@1 rate at each stage. The answer should mention the stages and the corresponding rates. Also, the document mentions that validation using percentile thresholds (p75 and p90) provides better improvements than binary judgment, especially for certain bug types. \\n\\nI need to make sure to reference the specific numbers from the figures and tables. For example, Figure 9 shows the progression from 174 to 39 to 33, 25, 12 bugs with the corresponding rates. Also, Table 2 and Table 3 might have more data, but the user\\'s question is about the framework\\'s combination, so focusing on Figure 9 and the related text is key. \\n\\nThe answer should explain that abstention first filters out less promising bugs, then validation further refines the set, leading to higher quality patches. The specific improvements are the increases in the filtered fail-to-pass@1 rate at each stage. Also, mention that more aggressive validation (p75 and p90) leads to higher rates but with fewer bugs. \\n\\nI need to check if the document mentions any specific performance metrics beyond the rates. For example, in Figure 10 and 11, there are mentions of filtered-accept@k improvements, but the main question is about the dual-policy framework\\'s stages. The answer should focus on the funnel stages and the corresponding performance metrics. \\n\\nSo, the answer should outline the stages: initial set (174 bugs, 11.29%), after abstention (39 bugs, 21.5%), then combined policies leading to 33 (29%), 25 (35%), and 12 (53%) bugs. The improvement is the increase in the filtered fail-to-pass@1 rate. Also, note that the combined policies (validation-p90) achieve the highest rate but with fewer bugs, showing a trade-off between volume and precision. \\n\\nI need to make sure all numbers are correctly cited from the document. The user might be looking for the specific percentages and the stages where they occur. Also, the answer should mention that the combination of abstention and validation policies leads to higher quality patches by reducing noise and increasing the resolution rate, as mentioned in Figure 7 and the discussion around the funnel.\\n</think>\\n\\nThe dual-policy framework combines **abstention** and **validation** to improve patch quality by progressively filtering bugs, reducing noise, and increasing the precision of patches shown to developers. Here’s how it works and the specific performance improvements at each stage:\\n\\n1. **Initial Stage (Full Bug Set):**  \\n   - Starts with **174 bugs**, where the baseline **filtered fail-to-pass@1 rate** is **11.29%** (Figure 9).  \\n   - This represents the raw set of bugs before any filtering.\\n\\n2. **Abstention Policy:**  \\n   - Filters the set to **39 bugs**, increasing the **filtered fail-to-pass@1 rate to 21.5%**.  \\n   - This stage prioritizes bugs with higher potential for successful repair, based on the quality of the bug report (e.g., presence of repository root, test cases).\\n\\n3. **Combined Validation Policies:**  \\n   - **Combined-binary** further narrows the set to **33 bugs**, boosting the rate to **29%**.  \\n   - **Combined-p75** reduces it to **25 bugs** with a **35%** rate.  \\n   - **Combined-p90** (most aggressive) narrows it to **12 bugs**, achieving the highest **53%** rate (Figure 9).  \\n\\n### Key Improvements:  \\n- **Trade-off Between Volume and Precision:**  \\n  Each stage reduces the number of bugs but increases the **filtered fail-to-pass@1 rate**, reflecting higher patch quality. For example, the strictest configuration (combined-p90) achieves **53%** precision, up from the baseline **11.29%**.  \\n- **Validation Thresholds:**  \\n  Aggressive percentile thresholds (p75/p90) outperform binary validation. For instance, **validation-p90** improves **filtered-accept@1** by **+24%** (vs. regression checks) and **+20%** (vs. p75), though it performs worse than spec-based validation for some categories (e.g., sanitizer bugs).  \\n- **Bug Type-Specific Effects:**  \\n  For **NPE bugs**, validation-p90 improves **filtered-accept@1** by **+24%** over regression checks (Figure 10). For **sanitizer bugs**, validation-p90 also shows significant gains (Table 2), though some categories (e.g., data races) show reduced lift due to trade-offs between correctness and practicality.  \\n\\n### Conclusion:  \\nThe dual-policy framework enhances patch quality by iteratively filtering bugs, with validation policies (especially percentile-based thresholds) significantly improving precision. The most selective configuration (combined-p90) achieves the highest **53%** filtered fail-to-pass@1 rate, though it sacrifices volume, highlighting the trade-off between precision and the number of bugs attempted.  \\n\\n**Citations:**  \\n- Figure 9 [1] describes the funnel process and metrics.  \\n- Table 2 [2] and Figure 10 [3] provide specific improvements for sanitizer and NPE bugs.  \\n- Text discussing validation thresholds and bug types [4].  \\n\\n[1] Figure 9: \"progressively narrowing the set to increase the quality of patches shown to a developer.\"  \\n[2] Table 2: \"validation-p90 improves filtered-accept@1 by +24% over regression checks.\"  \\n[3] Figure 10: \"validation-p90 results in improvements to filtered-accept@1 of +8% and +24%.\"  \\n[4] Text: \"validation-p90 performs worse than the spec-based variant at 90th percentile.\"' role=<Role.ASSISTANT: 'assistant'>\n"
     ]
    }
   ],
   "source": [
    "print(results[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10e28e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-17 23:36:31,856][oumi][rank0][pid:3312362][MainThread][INFO]][models.py:260] Building model using device_map: auto (DeviceRankInfo(world_size=1, rank=0, local_world_size=1, local_rank=0))...\n",
      "[2025-10-17 23:36:31,953][oumi][rank0][pid:3312362][MainThread][INFO]][models.py:336] Using model class: <class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'> to instantiate model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6908b39b8fd4e158e65f90cbd809c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-17 23:36:35,823][oumi][rank0][pid:3312362][MainThread][INFO]][models.py:544] Using the model's built-in chat template for model 'Qwen/Qwen3-8B'.\n",
      "[2025-10-17 23:36:35,838][oumi][rank0][pid:3312362][MainThread][INFO]][native_text_inference_engine.py:151] Setting EOS token id to `151645`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Model Responses:   0%|          | 0/2 [00:00<?, ?it/s]`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True, 'temperature': 0.6, 'top_k': 20, 'top_p': 0.95, 'pad_token_id': 151643, 'bos_token_id': 151643}. If this is not desired, please set these values explicitly.\n",
      "Generating Model Responses: 100%|██████████| 2/2 [02:15<00:00, 67.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation_id='c4523988-eb35-5bdd-b72e-b578a33ba318' messages=[SYSTEM: You are a document question-answering assistant. Your job is to answer user questions using only the content and structure of the provided document context.\n",
      "\n",
      "Follow these principles:\n",
      "\n",
      "1. Answer strictly based on the document. Do not use outside knowledge unless explicitly allowed.\n",
      "2. Adapt your answer to the style and tone requested (e.g., formal, concise, casual).\n",
      "3. Respect the expected answer format (e.g., yes/no, list, number, explanation).\n",
      "4. Use reasoning (temporal, arithmetic, logical, spatial) when necessary to synthesize answers from multiple parts of the document.\n",
      "5. If the document does not contain enough information to answer the question, reply with \"Not answerable from the document.\"\n",
      "6. Do not make assumptions or speculate.\n",
      "7. If multiple answers are possible, choose the best-supported one or note the ambiguity, depending on the task setup.\n",
      "8. Be clear, accurate, and context-aware.\n",
      "\n",
      "You may be shown structured documents, tables, or visual layouts. Interpret spatial relationships when relevant (e.g., rows, columns, nearby elements).\n",
      "\n",
      "Always prioritize accuracy, document grounding, and alignment with the user's question intent.\n",
      "\n",
      "Answer Attributes:\n",
      "Citation Requirement (Specifies whether and how the assistant should attribute its response to the source document or external references. Controls the presence and form of citations in the answer.): Explicit Citation (The assistant should clearly indicate the source of its information, using inline references, quotes, footnotes, or document pointers. This may include document section headers, line numbers, URLs, or citation styles depending on the use case.), USER: Context: 19\n",
      "20\n",
      "k\n",
      "0.0\n",
      "\n",
      "Config\n",
      "no-validation\n",
      "validation-binary\n",
      "\n",
      "validation-p75\n",
      "validation-p90\n",
      "\n",
      "Figure 7: More aggressive filtering tradeoffs between reduc-\n",
      "\n",
      "ing developer noise and increasing bug resolution rate.\n",
      "\n",
      "1.0\n",
      "\n",
      "Mean filtered fail-to-pass@k\n",
      "\n",
      "0.8\n",
      "\n",
      "Figure 9: Abstention and Validation Funnel. Our combined\n",
      "policies filter an initial set of 174 bugs, progressively nar-\n",
      "\n",
      "rowing the set to increase the quality of patches shown to\n",
      "a developer. Each stage reduces the number of bugs but in-\n",
      "\n",
      "creases the filtered fail-to-pass@1 rate, from a baseline of\n",
      "11.29% to 53% for the most selective configuration.\n",
      "\n",
      "0.6\n",
      "\n",
      "0.4\n",
      "\n",
      "0.2\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "k\n",
      "0.0\n",
      "\n",
      "6.4 RQ4: Validation on NPE and sanitizer bugs\n",
      "We further evaluate patch validation in bug categories that have\n",
      "more systematic information in their bug reports, and so are as-\n",
      "\n",
      "sumed good candidates for APR by construction (i.e., these bugs\n",
      "pass abstention by construction). We consider the machine-reported\n",
      "NPE and sanitizer bugs, whose bug reports always have a stack\n",
      "trace and reproduction test, respectively.\n",
      "\n",
      "Config\n",
      "no_filter(bugs=174)\n",
      "abstention(bugs=39)\n",
      "combined-binary(bugs=33)\n",
      "\n",
      "combined-p75(bugs=25)\n",
      "combined-p90(bugs=12)\n",
      "\n",
      "Figure 8: Abstention and validation are complementary,\n",
      "jointly they can raise filtered fail-to-pass@k.\n",
      "\n",
      "Figure 10 shows filtered-accept@k by manually inspecting the\n",
      "correctness of patches for NPE bugs, whose bug reports have stack\n",
      "traces. The baseline (build-and-test) filters patches that did not\n",
      "pass build and test regression checks. We observe that validation\n",
      "using binary judgment provide little improvement over these re-\n",
      "\n",
      "gression checks. However, validation using the more-aggressive\n",
      "percentile-threshold judgment can result in improvements to filtered-\n",
      "\n",
      "accept@1 of +8 percentage points and +24 percentage points, with\n",
      "75th and 90th percentile thresholds, respectively. No-spec valida-\n",
      "\n",
      "tion at 90th percentile produces a bigger filtered-accept@1 improve-\n",
      "\n",
      "ment than that at 75th percentile (+20 percentage points vs +24\n",
      "percentage points relative to regression checks), but both of them\n",
      "perform worse than the spec-based variant at 90th percentile (i.e.,\n",
      "validation-p90).\n",
      "\n",
      "success of the attempt, while the abstention policy is more likely\n",
      "to reflect overall quality of bug report.\n",
      "\n",
      "Figure 9 visualizes the process of our dual-policy framework as a\n",
      "configurable funnel. The funnel presents the filtered fail-to-pass@1\n",
      "rate on human-reported bugs at each stage. Starting with the full\n",
      "set of 174 bugs, where our APR system has a baseline pass@1\n",
      "rate of 11.29%, the abstention policy first filters this down to 39\n",
      "more promising bugs, increasing the filtered fail-to-pass@1 rate\n",
      "to 21.5%. The combined validation policies (combined-*) further\n",
      "refine this set. The combined-binary policy leaves 33 bugs with a\n",
      "rate of 29%. More aggressive filtering with combined-p75 and the\n",
      "strictest combined-p90 variant narrow the funnel to 25 and 12 bugs,\n",
      "respectively, boosting the quality of patches to achieve high filtered\n",
      "fail-to-pass@1 rates of 35% and 53%. Overall, Figure 9 demonstrates\n",
      "the trade-off between the volume of bugs attempted and the preci-\n",
      "\n",
      "sion of the patches ultimately shown to developers.\n",
      "\n",
      "Figure 11 shows mean filtered-accept@k (based on manual in-\n",
      "\n",
      "spection of patch correctness) for sanitizer bugs, whose bug reports\n",
      "have reproduction tests. As a result, we filter any patches first by\n",
      "the reproduction test and then apply the validation policy. The\n",
      "baseline (repro-test) filters patches that did not pass reproduction\n",
      "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair\n",
      "\n",
      "Sanitizer # Bugs repro-test validation-binary validation-p75 validation-p90\n",
      "data_race 17 3.11 2.93 2.43 3.04\n",
      "Fuzz+property testing 3 NA NA NA NA\n",
      "heap_buffer_overflow 1 1.43 1.43 1.54 1.54\n",
      "invalid_bool_load 2 1.49 1.65 1.25 NA\n",
      "invalid_enum_load 1 NA NA NA NA\n",
      "leak_detected 2 1.52 1.72 4.29 3.81\n",
      "misaligned_pointer_use 6 1.34 1.33 2.14 1.43\n",
      "null_pointer_use 1 2.86 3.33 NA NA\n",
      "signed_integer_overflow 2 1.2 1.27 1.56 2.5\n",
      "stack_use_after_scope 2 1.85 1.85 1.67 3.33\n",
      "use_of_uninitialized_value 13 2.05 1.93 2.05 1.95\n",
      "\n",
      "1.0\n",
      "\n",
      "0.8\n",
      "\n",
      "mean filtered accept@k\n",
      "\n",
      "0.6\n",
      "\n",
      "0.4\n",
      "\n",
      "0.2\n",
      "\n",
      "5\n",
      "\n",
      "k\n",
      "0.0\n",
      "\n",
      "Table 2: Lift (filtered-accept@1 / original accept@1) varies\n",
      "for different sanitizer bug types. The higher the better.\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Config\n",
      "build-and-test(bugs=135)\n",
      "validation-binary(bugs=104)\n",
      "validation-p75(bugs=43)\n",
      "validation-p90(bugs=21)\n",
      "no-spec-validation-binary(bugs=132)\n",
      "no-spec-validation-p75(bugs=53)\n",
      "no-spec-validation-p90(bugs=24)\n",
      "\n",
      "Metric Abstain AttemptRepair\n",
      "Average # code-like identifiers 3.03 5.28\n",
      "Average character length 771.67 1239.26\n",
      "Fraction with repository root 0.12 0.31\n",
      "Fraction possible build rule 0.01 0.03\n",
      "Fraction Markdown code ticks 0.17 0.20\n",
      "Table 3: Abstention-accepted bugs more frequently have the\n",
      "presence of the monorepo root directory.\n",
      "\n",
      "Figure 10: More aggressive validation can increase filtered\n",
      "accept@k for NPE bugs.\n",
      "\n",
      "1.0\n",
      "\n",
      "0.8\n",
      "\n",
      "mean filtered accept@k\n",
      "\n",
      "0.6\n",
      "\n",
      "0.4\n",
      "\n",
      "to reproduction test filtering slightly reduces lift, while adding the\n",
      "70th percentile validation keeps the same lift. For data races, adding\n",
      "validation actually reduces lift compared to just using reproduction\n",
      "tests. We hypothesize that: for these bugs, a patch that adds lock-\n",
      "\n",
      "ing mechanism indeed resolves the data race and can pass patch\n",
      "validation, but still may not be an acceptable solution for a Google\n",
      "developer if it introduces downsides such as larger critical sections.\n",
      "For some categories, e.g. leaks and misaligned pointer usage, a less\n",
      "aggressive validation (75th percentile) achieves better lift than a\n",
      "more aggressive one (90th percentile).\n",
      "\n",
      "0.2\n",
      "\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "k\n",
      "0.0\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "Config\n",
      "repro-test(bugs=48)\n",
      "\n",
      "no-spec-validation-binary(bugs=48)\n",
      "no-spec-validation-p75(bugs=32)\n",
      "no-spec-validation-p90(bugs=21)\n",
      "\n",
      "validation-binary(bugs=45)\n",
      "validation-p75(bugs=30)\n",
      "validation-p90(bugs=15)\n",
      "\n",
      "Figure 11: Aggressive validation increases filtered accept@1\n",
      "for sanitizer bugs. But just reviewing more patches can lead\n",
      "to higher filtered-accept@k, with 4 patches sufficing.\n",
      "\n",
      "We hypothesize that a true bug reproduction test, such as that\n",
      "included in the sanitizer’s bug report, results in a set of plausible\n",
      "patches that are increasingly difficult for validation to assess, com-\n",
      "\n",
      "pared to the patches produced for the less-constrained bugs such as\n",
      "the human-reported ones. This points to a few future research di-\n",
      "\n",
      "rections. First, generating additional executable tests to help assess\n",
      "patch correctness is a particularly promising direction. For exam-\n",
      "\n",
      "ple, AutoCodeSherpa [15] generates property-based tests to assist\n",
      "reviewing and filtering agent-generated patches. As pointed out,\n",
      "after filtering with the reproduction test, sampling  = 4 produces\n",
      "a mean filtered accept rate of 0.74. Supporting developers when\n",
      "inspecting more patches may help maintain a high success rate.\n",
      "\n",
      "tests. For sanitizer bugs, validation can lift filtered-accept\n",
      "\n",
      "Question: How does the dual-policy framework's combination of abstention and validation policies improve patch quality, and what are the specific performance improvements achieved at different filtering stages?, ASSISTANT: <think>\n",
      "Okay, let's tackle this question. The user wants to know how the dual-policy framework combines abstention and validation to improve patch quality and the specific performance improvements at different stages.\n",
      "\n",
      "First, I need to recall the document content. From what I remember, the document discusses a dual-policy approach where abstention and validation are used together. The abstention policy filters out less promising bugs, while validation further refines the remaining patches. \n",
      "\n",
      "Looking at Figure 9, it mentions that the process is visualized as a funnel. Starting with 174 bugs, the baseline pass@1 rate is 11.29%. The abstention policy reduces this to 39 bugs, increasing the filtered fail-to-pass@1 rate to 21.5%. Then, combined validation policies further refine it. The combined-binary policy leaves 33 bugs with a 29% rate. More aggressive filters like combined-p75 and combined-p90 narrow it down to 25 and 12 bugs, respectively, with higher rates of 35% and 53%. \n",
      "\n",
      "The user is asking about the improvement in patch quality and the specific numbers at each stage. So, the answer should outline each stage's bug count and the corresponding filtered fail-to-pass@1 rates. Also, mention how each step contributes to quality by reducing noise and increasing the rate. \n",
      "\n",
      "I need to make sure the numbers are correctly attributed to each policy. The combined-p90 has the highest rate at 53%, which is a significant improvement from the baseline. Also, the document mentions that validation using percentile thresholds (p75 and p90) provides better improvements than binary judgment. \n",
      "\n",
      "Another point is that the abstention policy is based on the overall quality of the bug report, while validation focuses on the success of the attempt. Combining them allows for a balance between volume and precision. \n",
      "\n",
      "I should structure the answer by first explaining the combination's effect on quality, then list the stages with their respective bug counts and performance metrics. Also, note the trade-offs between the number of bugs and the precision of the patches. \n",
      "\n",
      "Check if there are any other relevant parts. The table in Figure 11 talks about different bug types and their filtered-accept@k, but the question is about the framework's overall performance. So focus on the funnel stages and the metrics mentioned in Figure 9. \n",
      "\n",
      "Make sure to cite the relevant sections, like Figure 9 and the descriptions around it. Also, mention that the combined policies progressively narrow down the bugs, leading to higher filtered fail-to-pass rates, which indicates better patch quality.\n",
      "</think>\n",
      "\n",
      "The dual-policy framework combines **abstention** (filtering low-quality bugs) and **validation** (refining patches via thresholds) to improve patch quality by reducing noise and increasing the precision of patches shown to developers. Here’s the breakdown of performance improvements at each filtering stage:\n",
      "\n",
      "1. **Baseline (174 bugs):**  \n",
      "   - **Filtered fail-to-pass@1 rate:** 11.29% (low precision, high noise).  \n",
      "\n",
      "2. **After Abstention Policy:**  \n",
      "   - Filters to **39 bugs**, increasing the **filtered fail-to-pass@1 rate to 21.5%**.  \n",
      "   - Abstention reflects the overall quality of bug reports, narrowing focus to more promising candidates.  \n",
      "\n",
      "3. **Combined Validation Policies:**  \n",
      "   - **combined-binary:** 33 bugs, **29% fail-to-pass@1**.  \n",
      "   - **combined-p75:** 25 bugs, **35% fail-to-pass@1**.  \n",
      "   - **combined-p90 (most selective):** 12 bugs, **53% fail-to-pass@1**.  \n",
      "   - Aggressive validation (percentile thresholds) significantly boosts precision, with **combined-p90 achieving a 53% rate**—a +41.7 percentage point improvement over the baseline.  \n",
      "\n",
      "### Key Trade-offs:  \n",
      "- **Volume vs. Precision:** Each stage reduces the number of bugs but increases patch quality.  \n",
      "- **Validation Impact:** Percentile thresholds (e.g., p90) outperform binary validation, though some categories (e.g., leaks) show better results with less aggressive thresholds.  \n",
      "\n",
      "This framework balances noise reduction and precision, enabling developers to focus on high-quality patches. (Citations: Figure 9, Section on \"Validation on NPE and sanitizer bugs\")<|im_end|>] metadata={}\n"
     ]
    }
   ],
   "source": [
    "from oumi.core.configs import InferenceConfig\n",
    "from oumi.inference import NativeTextInferenceEngine\n",
    "\n",
    "config = InferenceConfig.from_yaml(\n",
    "    \"/home/shanghong/oumi/enterprise_experiments/configs/infer.yaml\"\n",
    ")\n",
    "\n",
    "engine = NativeTextInferenceEngine(\n",
    "    model_params=config.model,\n",
    "    generation_params=config.generation,\n",
    ")\n",
    "\n",
    "results = engine.infer(input=processed_data[:2], inference_config=config)\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2824258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's tackle this question. The user wants to know how the dual-policy framework combines abstention and validation to improve patch quality and the specific performance improvements at different stages.\n",
      "\n",
      "First, I need to recall the document content. From what I remember, the document discusses a dual-policy approach where abstention and validation are used together. The abstention policy filters out less promising bugs, while validation further refines the remaining patches. \n",
      "\n",
      "Looking at Figure 9, it mentions that the process is visualized as a funnel. Starting with 174 bugs, the baseline pass@1 rate is 11.29%. The abstention policy reduces this to 39 bugs, increasing the filtered fail-to-pass@1 rate to 21.5%. Then, combined validation policies further refine it. The combined-binary policy leaves 33 bugs with a 29% rate. More aggressive filters like combined-p75 and combined-p90 narrow it down to 25 and 12 bugs, respectively, with higher rates of 35% and 53%. \n",
      "\n",
      "The user is asking about the improvement in patch quality and the specific numbers at each stage. So, the answer should outline each stage's bug count and the corresponding filtered fail-to-pass@1 rates. Also, mention how each step contributes to quality by reducing noise and increasing the rate. \n",
      "\n",
      "I need to make sure the numbers are correctly attributed to each policy. The combined-p90 has the highest rate at 53%, which is a significant improvement from the baseline. Also, the document mentions that validation using percentile thresholds (p75 and p90) provides better improvements than binary judgment. \n",
      "\n",
      "Another point is that the abstention policy is based on the overall quality of the bug report, while validation focuses on the success of the attempt. Combining them allows for a balance between volume and precision. \n",
      "\n",
      "I should structure the answer by first explaining the combination's effect on quality, then list the stages with their respective bug counts and performance metrics. Also, note the trade-offs between the number of bugs and the precision of the patches. \n",
      "\n",
      "Check if there are any other relevant parts. The table in Figure 11 talks about different bug types and their filtered-accept@k, but the question is about the framework's overall performance. So focus on the funnel stages and the metrics mentioned in Figure 9. \n",
      "\n",
      "Make sure to cite the relevant sections, like Figure 9 and the descriptions around it. Also, mention that the combined policies progressively narrow down the bugs, leading to higher filtered fail-to-pass rates, which indicates better patch quality.\n",
      "</think>\n",
      "\n",
      "The dual-policy framework combines **abstention** (filtering low-quality bugs) and **validation** (refining patches via thresholds) to improve patch quality by reducing noise and increasing the precision of patches shown to developers. Here’s the breakdown of performance improvements at each filtering stage:\n",
      "\n",
      "1. **Baseline (174 bugs):**  \n",
      "   - **Filtered fail-to-pass@1 rate:** 11.29% (low precision, high noise).  \n",
      "\n",
      "2. **After Abstention Policy:**  \n",
      "   - Filters to **39 bugs**, increasing the **filtered fail-to-pass@1 rate to 21.5%**.  \n",
      "   - Abstention reflects the overall quality of bug reports, narrowing focus to more promising candidates.  \n",
      "\n",
      "3. **Combined Validation Policies:**  \n",
      "   - **combined-binary:** 33 bugs, **29% fail-to-pass@1**.  \n",
      "   - **combined-p75:** 25 bugs, **35% fail-to-pass@1**.  \n",
      "   - **combined-p90 (most selective):** 12 bugs, **53% fail-to-pass@1**.  \n",
      "   - Aggressive validation (percentile thresholds) significantly boosts precision, with **combined-p90 achieving a 53% rate**—a +41.7 percentage point improvement over the baseline.  \n",
      "\n",
      "### Key Trade-offs:  \n",
      "- **Volume vs. Precision:** Each stage reduces the number of bugs but increases patch quality.  \n",
      "- **Validation Impact:** Percentile thresholds (e.g., p90) outperform binary validation, though some categories (e.g., leaks) show better results with less aggressive thresholds.  \n",
      "\n",
      "This framework balances noise reduction and precision, enabling developers to focus on high-quality patches. (Citations: Figure 9, Section on \"Validation on NPE and sanitizer bugs\")<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(results[0][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37595d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0dba820e8f49cfba2206e9304c55f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10451135e364493b926a03fe0f35f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1282d02af45c478fa6663b7f2d2f5c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...atqa/checkpoint-208/rng_state_4.pth: 100%|##########| 16.4kB / 16.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e51c13456b44058154df0965deec69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...atqa/checkpoint-208/rng_state_6.pth: 100%|##########| 16.4kB / 16.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9784335f0c4bb09923091f9e53bb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...atqa/checkpoint-208/rng_state_3.pth: 100%|##########| 16.4kB / 16.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5427f040a6b7433c85bf3c5ce5173418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...atqa/checkpoint-208/rng_state_2.pth: 100%|##########| 16.4kB / 16.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17da3f6255804781b796ac14d2bf5c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...atqa/checkpoint-208/rng_state_7.pth: 100%|##########| 16.4kB / 16.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbac1a327be44a7c811130c2a2d968c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...atqa/checkpoint-208/rng_state_5.pth: 100%|##########| 16.4kB / 16.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340f0c65ddbe4f31b7651cb8e67adf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...atqa/checkpoint-208/rng_state_0.pth: 100%|##########| 16.4kB / 16.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad213399f6c4e3ea2f518cd17b9deac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...atqa/checkpoint-208/rng_state_1.pth: 100%|##########| 16.4kB / 16.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99d057e78b8477cbdc6db6f731a3687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...tatqa/checkpoint-208/tokenizer.json:  97%|#########7| 11.1MB / 11.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4248fa9aece64bc6887c3831d173e422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...08/model-00001-of-00004.safetensors:   0%|          | 3.61MB / 4.90GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/shanghong/qwen3_8b_tatqa/commit/873ca5ec066a3d48ec89aceeabca717abac743fe', commit_message='Upload folder using huggingface_hub', commit_description='', oid='873ca5ec066a3d48ec89aceeabca717abac743fe', pr_url=None, repo_url=RepoUrl('https://huggingface.co/shanghong/qwen3_8b_tatqa', endpoint='https://huggingface.co', repo_type='model', repo_id='shanghong/qwen3_8b_tatqa'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, upload_folder\n",
    "\n",
    "folder_path = \"/home/shanghong/oumi/output/qwen3_8b.fft_tatqa/checkpoint-208\"\n",
    "repo_id = \"shanghong/qwen3_8b_tatqa\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Create repo if it does not exist\n",
    "api.create_repo(repo_id, repo_type=\"model\", exist_ok=True)\n",
    "\n",
    "# Upload folder\n",
    "upload_folder(folder_path=folder_path, repo_id=repo_id, repo_type=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e2312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open(\n",
    "    \"/home/shanghong/oumi/enterprise_experiments/output/judgment_results_ep3.jsonl\"\n",
    ") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a2099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8634996993385448\n"
     ]
    }
   ],
   "source": [
    "judgement_results = []\n",
    "for i in range(len(data)):\n",
    "    judgement = data[i][\"judgment\"]\n",
    "    judgement_results.append(judgement)\n",
    "\n",
    "print(sum(judgement_results) / len(judgement_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0cc4c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shanghong/oumi/tmp/enterprise_experiments/output/qwen3_8b_tatqa_think2_ep1_filtered.jsonl\n",
      "Skipped 0 samples\n",
      "/home/shanghong/oumi/tmp/enterprise_experiments/output/qwen3_8b_tatqa_think2_ep2_filtered.jsonl\n",
      "Skipped 0 samples\n",
      "/home/shanghong/oumi/tmp/enterprise_experiments/output/qwen3_8b_tatqa_think2_ep3_filtered.jsonl\n",
      "Skipped 0 samples\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "file_paths = [\n",
    "    \"/home/shanghong/oumi/tmp/enterprise_experiments/output/qwen3_8b_tatqa_think2_ep1.json\",\n",
    "    \"/home/shanghong/oumi/tmp/enterprise_experiments/output/qwen3_8b_tatqa_think2_ep2.json\",\n",
    "    \"/home/shanghong/oumi/tmp/enterprise_experiments/output/qwen3_8b_tatqa_think2_ep3.json\",\n",
    "]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    outputs = []\n",
    "    skipped_num = 0\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    for d in data:\n",
    "        sample = d[\"messages\"]\n",
    "        request = sample[0][\"content\"]\n",
    "        response = sample[1][\"content\"]\n",
    "        if \"</think>\" in response:\n",
    "            response = response.split(\"</think>\")[1]\n",
    "        else:\n",
    "            skipped_num += 1\n",
    "            continue\n",
    "        outputs.append({\"request\": request, \"response\": response})\n",
    "    \n",
    "    with open(f\"{file_path.split('.')[0]}_filtered.jsonl\", \"w\") as f:\n",
    "        for output in outputs:\n",
    "            f.write(json.dumps(output) + \"\\n\")\n",
    "    print(f\"{file_path.split('.')[0]}_filtered.jsonl\")\n",
    "    print(f\"Skipped {skipped_num} samples\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0dd10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
