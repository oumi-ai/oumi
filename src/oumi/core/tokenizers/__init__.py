"""Tokenizers module for the LeMa (Learning Machines) library.

This module provides base classes for tokenizers used in the LeMa framework.
These base classes serve as foundations for creating custom tokenizers for various
natural language processing tasks.
"""

from oumi.core.tokenizers.base_tokenizer import BaseTokenizer

__all__ = [
    "BaseTokenizer",
]
