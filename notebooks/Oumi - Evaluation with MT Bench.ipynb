{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with MT Bench\n",
    "\n",
    "This notebook discusses how you can run E2E evaluations for your trained model with [MT Bench](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge). Evaluating with MT Bench is a 2-step process. In the first step, we run inference for your model to generate answers for 80 multi-turn MT-bench questions. In the second step, we generate judgments (GPT-4 is the default judge) comparing your model's answers vs. reference answers. Each answer is scored [1, 10], considering factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Configuration\n",
    "\n",
    "First, start by cloning the [FastChat](https://github.com/lm-sys/FastChat) repo, which includes the MT Bench framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/gcpuser/Eval/FastChat'...\n",
      "remote: Enumerating objects: 8425, done.\u001b[K\n",
      "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
      "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
      "remote: Total 8425 (delta 135), reused 84 (delta 84), pack-reused 8275 (from 4)\u001b[K\n",
      "Receiving objects: 100% (8425/8425), 34.52 MiB | 36.36 MiB/s, done.\n",
      "Resolving deltas: 100% (6398/6398), done.\n"
     ]
    }
   ],
   "source": [
    "FAST_CHAT_REPO = \"/home/gcpuser/Eval/FastChat\"  # Folder to clone to.\n",
    "! git clone https://github.com/lm-sys/FastChat.git $FAST_CHAT_REPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, navigate to that folder and pip install the packages `model_worker` and `llm_judge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/gcpuser/Eval/FastChat\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (3.10.9)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (0.115.6)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (0.28.1)\n",
      "Collecting markdown2[all]\n",
      "  Downloading markdown2-2.5.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting nh3\n",
      "  Downloading nh3-0.2.19-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.25.2)\n",
      "Requirement already satisfied: prompt_toolkit>=3.0.0 in /opt/conda/lib/python3.10/site-packages (3.0.39)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (2.10.3)\n",
      "Collecting pydantic-settings\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (6.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.10/site-packages (13.6.0)\n",
      "Collecting shortuuid\n",
      "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: accelerate>=0.21 in /opt/conda/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (4.45.2)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (3.20.3)\n",
      "Collecting openai<1\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting anthropic>=0.3\n",
      "  Downloading anthropic-0.40.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: ray in /opt/conda/lib/python3.10/site-packages (2.40.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21) (23.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21) (0.4.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from anthropic>=0.3) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from anthropic>=0.3) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from anthropic>=0.3) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from anthropic>=0.3) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from anthropic>=0.3) (4.12.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx) (0.14.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai<1) (4.67.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt_toolkit>=3.0.0) (0.2.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=2.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=2.0.0) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0) (2.16.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0) (0.20.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp) (1.18.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp) (4.0.3)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from fastapi) (0.41.3)\n",
      "Collecting wavedrom (from markdown2[all])\n",
      "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting latex2mathml (from markdown2[all])\n",
      "  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings) (1.0.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray) (8.1.7)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray) (1.0.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic>=0.3) (1.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0) (0.1.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp) (0.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting svgwrite (from wavedrom->markdown2[all])\n",
      "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from wavedrom->markdown2[all]) (1.16.0)\n",
      "Downloading anthropic-0.40.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nh3-0.2.19-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m748.3/748.3 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown2-2.5.2-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hChecking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: fschat, wavedrom\n",
      "  Building editable for fschat (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fschat: filename=fschat-0.2.36-0.editable-py3-none-any.whl size=15016 sha256=48c3c533befb0e3af51b3e309bb05209def56cf4c3cf19ae56be12003602363c\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-pur02m6a/wheels/65/8f/2c/ed6898d9d401f7cc5f74365b878de8fe9bfc3de89b90ff7866\n",
      "  Building wheel for wavedrom (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30053 sha256=3f3e376369db4bf1b5bdf33b7f703d948a3497d65b0b34ad82b86b5102f7372c\n",
      "  Stored in directory: /home/gcpuser/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
      "Successfully built fschat wavedrom\n",
      "Installing collected packages: nh3, svgwrite, shortuuid, markdown2, latex2mathml, wavedrom, pydantic-settings, openai, anthropic, fschat\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.57.3\n",
      "    Uninstalling openai-1.57.3:\n",
      "      Successfully uninstalled openai-1.57.3\n",
      "vllm 0.6.3.post1 requires openai>=1.40.0, but you have openai 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anthropic-0.40.0 fschat-0.2.36 latex2mathml-3.77.0 markdown2-2.5.2 nh3-0.2.19 openai-0.28.1 pydantic-settings-2.6.1 shortuuid-1.0.13 svgwrite-1.4.3 wavedrom-2.0.3.post3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(FAST_CHAT_REPO)\n",
    "! pip install -e \".[model_worker,llm_judge]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing your model's responses vs. the reference responses to calculate the score, a judge is needed. By default, the judge is set to GPT4. To access GPT-4 models, an Open API key is required. Details on creating an OpenAI account and generating a key can be found at [Open AI's quickstart webpage](https://platform.openai.com/docs/quickstart).\n",
    "\n",
    "<b>⚠️ Cost considerations</b>: To estimate the cost of judging 160 examples (80 x 2-turn conversations) with GPT4, please visit [Open AI's pricing](https://openai.com/api/pricing/) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # NOTE: Set your OpenAI API key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, point to your model (`MODEL_PATH`). MT Bench supports HuggingFace repo IDs and paths to local folders that contain your model. \n",
    "Also, please provide a (human friendly) custom `MODEL_ID` for your model; this will be used to uniquely reference your model when generating judgments or inspecting scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "MODEL_ID = \"my_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run inference\n",
    "\n",
    "Navigate to the LLM judge folder and run inference, passing in your model path and model id as shown below.\n",
    "\n",
    "Additional arguments to consider (more details [here](https://github.com/lm-sys/FastChat/blob/1cd4b74fa00d1a60852ea9c88e4cc4fc070e4512/fastchat/llm_judge/gen_model_answer.py#L209C1-L271C6)):\n",
    "- You can change the location of the output file by setting `--answer-file=<file path>`.\n",
    "- You can restrict the max number of generated tokens by your model by setting `--max-new-token=<number of tokens>`.\n",
    "- You can specify the model revision to be loaded by `--revision=<model revision>`.\n",
    "- You can set the number of GPUs to be used when running inference with your model with `--num-gpus-per-model=<num GPUs>` (if not set, the default is 1).\n",
    "- You can restrict the GPU memory used when running inference by `--max-gpu-memory=<max memory>`.\n",
    "- You can overwrite the default `dtype` with `--dtype=<dtype>` (if not set, the default is to use float16 on GPU, float32 on CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output to data/mt_bench/model_answer/my_model.jsonl\n",
      "tokenizer_config.json: 100%|███████████████| 54.5k/54.5k [00:00<00:00, 6.50MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:00<00:00, 17.8MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 296/296 [00:00<00:00, 2.77MB/s]\n",
      "config.json: 100%|█████████████████████████████| 877/877 [00:00<00:00, 6.89MB/s]\n",
      "model.safetensors: 100%|███████████████████| 2.47G/2.47G [00:59<00:00, 41.6MB/s]\n",
      "generation_config.json: 100%|██████████████████| 189/189 [00:00<00:00, 1.30MB/s]\n",
      "  0%|                                                    | 0/80 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  1%|▌                                           | 1/80 [00:34<45:03, 34.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  2%|█                                           | 2/80 [00:58<36:30, 28.08s/it]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  4%|█▋                                          | 3/80 [01:20<32:28, 25.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  5%|██▏                                         | 4/80 [01:39<29:20, 23.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  6%|██▊                                         | 5/80 [02:04<29:46, 23.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  8%|███▎                                        | 6/80 [02:17<24:38, 19.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  9%|███▊                                        | 7/80 [02:42<26:31, 21.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 10%|████▍                                       | 8/80 [03:16<30:38, 25.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 11%|████▉                                       | 9/80 [03:45<31:23, 26.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 12%|█████▍                                     | 10/80 [04:10<30:36, 26.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 14%|█████▉                                     | 11/80 [04:32<28:45, 25.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 15%|██████▍                                    | 12/80 [05:06<31:18, 27.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 16%|██████▉                                    | 13/80 [05:24<27:36, 24.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 18%|███████▌                                   | 14/80 [05:53<28:33, 25.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 19%|████████                                   | 15/80 [06:07<24:11, 22.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 20%|████████▌                                  | 16/80 [06:39<26:55, 25.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 21%|█████████▏                                 | 17/80 [07:04<26:34, 25.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 22%|█████████▋                                 | 18/80 [07:25<24:34, 23.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 24%|██████████▏                                | 19/80 [07:50<24:45, 24.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 25%|██████████▊                                | 20/80 [08:13<24:00, 24.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 26%|███████████▎                               | 21/80 [08:32<22:06, 22.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 28%|███████████▊                               | 22/80 [08:34<15:39, 16.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 29%|████████████▎                              | 23/80 [09:06<19:48, 20.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 30%|████████████▉                              | 24/80 [09:32<21:07, 22.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 31%|█████████████▍                             | 25/80 [09:57<21:12, 23.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 32%|█████████████▉                             | 26/80 [10:26<22:34, 25.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 34%|██████████████▌                            | 27/80 [10:58<23:56, 27.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 35%|███████████████                            | 28/80 [11:30<24:41, 28.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 36%|███████████████▌                           | 29/80 [11:50<22:01, 25.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 38%|████████████████▏                          | 30/80 [12:08<19:35, 23.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 39%|████████████████▋                          | 31/80 [12:39<21:12, 25.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 40%|█████████████████▏                         | 32/80 [12:59<19:14, 24.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 41%|█████████████████▋                         | 33/80 [13:31<20:42, 26.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 42%|██████████████████▎                        | 34/80 [13:50<18:30, 24.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 44%|██████████████████▊                        | 35/80 [14:07<16:29, 21.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 45%|███████████████████▎                       | 36/80 [14:26<15:26, 21.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 46%|███████████████████▉                       | 37/80 [14:31<11:44, 16.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 48%|████████████████████▍                      | 38/80 [14:59<13:58, 19.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 49%|████████████████████▉                      | 39/80 [15:33<16:27, 24.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 50%|█████████████████████▌                     | 40/80 [15:58<16:17, 24.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 51%|██████████████████████                     | 41/80 [16:29<17:00, 26.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 52%|██████████████████████▌                    | 42/80 [17:02<17:57, 28.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 54%|███████████████████████                    | 43/80 [17:06<13:00, 21.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 55%|███████████████████████▋                   | 44/80 [17:40<14:53, 24.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 56%|████████████████████████▏                  | 45/80 [18:01<13:47, 23.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 57%|████████████████████████▋                  | 46/80 [18:33<14:51, 26.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 59%|█████████████████████████▎                 | 47/80 [19:07<15:40, 28.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 60%|█████████████████████████▊                 | 48/80 [19:38<15:43, 29.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 61%|██████████████████████████▎                | 49/80 [20:10<15:35, 30.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 62%|██████████████████████████▉                | 50/80 [20:27<13:08, 26.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 64%|███████████████████████████▍               | 51/80 [20:47<11:43, 24.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 65%|███████████████████████████▉               | 52/80 [21:21<12:37, 27.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 66%|████████████████████████████▍              | 53/80 [21:47<12:04, 26.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 68%|█████████████████████████████              | 54/80 [22:18<12:15, 28.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 69%|█████████████████████████████▌             | 55/80 [22:45<11:33, 27.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 70%|██████████████████████████████             | 56/80 [23:17<11:34, 28.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 71%|██████████████████████████████▋            | 57/80 [23:37<10:05, 26.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 72%|███████████████████████████████▏           | 58/80 [23:57<08:59, 24.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 74%|███████████████████████████████▋           | 59/80 [24:29<09:19, 26.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 75%|████████████████████████████████▎          | 60/80 [25:02<09:33, 28.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 76%|████████████████████████████████▊          | 61/80 [25:28<08:49, 27.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 78%|█████████████████████████████████▎         | 62/80 [25:45<07:20, 24.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 79%|█████████████████████████████████▊         | 63/80 [26:17<07:33, 26.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 80%|██████████████████████████████████▍        | 64/80 [26:48<07:31, 28.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 81%|██████████████████████████████████▉        | 65/80 [27:05<06:12, 24.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 82%|███████████████████████████████████▍       | 66/80 [27:20<05:05, 21.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 84%|████████████████████████████████████       | 67/80 [27:50<05:16, 24.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 85%|████████████████████████████████████▌      | 68/80 [28:03<04:08, 20.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 86%|█████████████████████████████████████      | 69/80 [28:34<04:24, 24.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 88%|█████████████████████████████████████▋     | 70/80 [28:57<03:56, 23.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 89%|██████████████████████████████████████▏    | 71/80 [29:29<03:54, 26.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 90%|██████████████████████████████████████▋    | 72/80 [30:01<03:42, 27.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 91%|███████████████████████████████████████▏   | 73/80 [30:22<03:00, 25.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 92%|███████████████████████████████████████▊   | 74/80 [30:46<02:32, 25.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 94%|████████████████████████████████████████▎  | 75/80 [31:04<01:55, 23.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 95%|████████████████████████████████████████▊  | 76/80 [31:25<01:30, 22.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 96%|█████████████████████████████████████████▍ | 77/80 [31:44<01:04, 21.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 98%|█████████████████████████████████████████▉ | 78/80 [32:13<00:47, 23.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 99%|██████████████████████████████████████████▍| 79/80 [32:27<00:20, 20.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "100%|███████████████████████████████████████████| 80/80 [32:57<00:00, 24.72s/it]\n"
     ]
    }
   ],
   "source": [
    "LLM_JUDGE_FOLDER = f\"{FAST_CHAT_REPO}/fastchat/llm_judge/\"\n",
    "os.chdir(LLM_JUDGE_FOLDER)\n",
    "! python gen_model_answer.py --model-path $MODEL_PATH --model-id $MODEL_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the inference results folder to make sure your inference results are there. The default output filename is `<MODEL_ID>.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['my_model.jsonl']\n"
     ]
    }
   ],
   "source": [
    "INFERENCE_RESULTS_FOLDER = f\"{LLM_JUDGE_FOLDER}/data/mt_bench/model_answer/\"\n",
    "inference_result_files = os.listdir(INFERENCE_RESULTS_FOLDER)\n",
    "print(f\"files: {inference_result_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Judge the model answers\n",
    "\n",
    "In this notebook, we demonstrate the recommended \"single-answer\" grading mode, where the judge assigns (for each turn) a score on a scale of 10. There are two additional grading options, where the judged model is compared pairwise to a single baseline model (`pairwise-baseline`) or multiple baseline models (`pairwise-all`) and win rates are generated. For more details, please read FastChat's [other grading options](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge#other-grading-options) section.\n",
    "\n",
    "The command to invoke the GPT-4 judge to score each answer (single-answer grading) is shown below. Note that the `echo -ne '\\n'` prefix is required because we are invoking the shell via a notebook and that script (`gen_judgment.py`) requires human verification by pressing \"Enter\". Piping the `\\n` character into the script emulates pressing \"Enter\" right after executing `gen_judgment.py`.\n",
    "\n",
    "Additional arguments to consider (more details [here](https://github.com/lm-sys/FastChat/blob/1cd4b74fa00d1a60852ea9c88e4cc4fc070e4512/fastchat/llm_judge/gen_judgment.py#L170)):\n",
    "- You can change the location of the judgement file by setting `--judge-file=<file path>`.\n",
    "- If you want multiple concurrent API calls to the judge, you can set this with `--parallel=<number of concurrent API calls>` (default is 1).\n",
    "- You can use a different judge model by setting `--judge-model=<judge model name>` (default is `gpt-4`). This option is not documented and might not be very informative if you are interested in generating comparative results, since the reference model is the default model. \n",
    "- If you want to update the model that generated the reference answers you can do so by `--baseline-model=<judge model name>` (default is `gpt-3.5-turbo`). This option is also not documented, since the reference answers are used for comparative analysis. \n",
    "- If you want to test judgement for a subset of the answers set `--first-n=<number of answers to judge>`. This flag is mainly used for debugging purposes; you can use it to reduce your judgment costs when testing the MT Bench framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:\n",
      "{\n",
      "    \"bench_name\": \"mt_bench\",\n",
      "    \"mode\": \"single\",\n",
      "    \"judge\": \"gpt-4\",\n",
      "    \"baseline\": null,\n",
      "    \"model_list\": [\n",
      "        \"my_model\"\n",
      "    ],\n",
      "    \"total_num_questions\": 80,\n",
      "    \"total_num_matches\": 160,\n",
      "    \"output_path\": \"data/mt_bench/model_judgment/gpt-4_single.jsonl\"\n",
      "}\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s]question: 81, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      "  1%|▎                                          | 1/160 [00:04<12:46,  4.82s/it]question: 82, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      "  1%|▌                                          | 2/160 [00:12<17:48,  6.77s/it]question: 83, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      "  2%|▊                                          | 3/160 [00:19<17:41,  6.76s/it]question: 84, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      "  2%|█                                          | 4/160 [00:25<16:40,  6.42s/it]question: 85, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      "  3%|█▎                                         | 5/160 [00:32<17:15,  6.68s/it]question: 86, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      "  4%|█▌                                         | 6/160 [00:38<16:40,  6.50s/it]question: 87, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      "  4%|█▉                                         | 7/160 [00:46<17:17,  6.78s/it]question: 88, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      "  5%|██▏                                        | 8/160 [00:51<15:53,  6.27s/it]question: 89, turn: 1, model: my_model, score: 8.5, judge: ('gpt-4', 'single-v1')\n",
      "  6%|██▍                                        | 9/160 [00:54<13:03,  5.19s/it]question: 90, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      "  6%|██▋                                       | 10/160 [00:58<12:33,  5.02s/it]question: 91, turn: 1, model: my_model, score: 8, judge: ('gpt-4', 'single-v1')\n",
      "  7%|██▉                                       | 11/160 [01:01<10:55,  4.40s/it]question: 92, turn: 1, model: my_model, score: 6, judge: ('gpt-4', 'single-v1')\n",
      "  8%|███▏                                      | 12/160 [01:08<12:11,  4.94s/it]question: 93, turn: 1, model: my_model, score: 7, judge: ('gpt-4', 'single-v1')\n",
      "  8%|███▍                                      | 13/160 [01:12<11:52,  4.84s/it]question: 94, turn: 1, model: my_model, score: 7, judge: ('gpt-4', 'single-v1')\n",
      "  9%|███▋                                      | 14/160 [01:16<10:50,  4.46s/it]question: 95, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-v1')\n",
      "  9%|███▉                                      | 15/160 [01:21<11:07,  4.60s/it]question: 96, turn: 1, model: my_model, score: 6, judge: ('gpt-4', 'single-v1')\n",
      " 10%|████▏                                     | 16/160 [01:28<12:43,  5.30s/it]question: 97, turn: 1, model: my_model, score: 7, judge: ('gpt-4', 'single-v1')\n",
      " 11%|████▍                                     | 17/160 [01:32<12:10,  5.11s/it]question: 98, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      " 11%|████▋                                     | 18/160 [01:37<11:39,  4.92s/it]question: 99, turn: 1, model: my_model, score: 3, judge: ('gpt-4', 'single-v1')\n",
      " 12%|████▉                                     | 19/160 [01:42<12:00,  5.11s/it]question: 100, turn: 1, model: my_model, score: 6, judge: ('gpt-4', 'single-v1')\n",
      " 12%|█████▎                                    | 20/160 [01:47<11:34,  4.96s/it]question: 131, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      " 13%|█████▌                                    | 21/160 [01:52<11:47,  5.09s/it]question: 132, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-v1')\n",
      " 14%|█████▊                                    | 22/160 [01:56<10:27,  4.55s/it]question: 133, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      " 14%|██████                                    | 23/160 [01:59<09:42,  4.25s/it]question: 134, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-v1')\n",
      " 15%|██████▎                                   | 24/160 [02:03<09:07,  4.02s/it]question: 135, turn: 1, model: my_model, score: 6, judge: ('gpt-4', 'single-v1')\n",
      " 16%|██████▌                                   | 25/160 [02:07<09:27,  4.20s/it]question: 136, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-v1')\n",
      " 16%|██████▊                                   | 26/160 [02:12<09:40,  4.33s/it]question: 137, turn: 1, model: my_model, score: 8, judge: ('gpt-4', 'single-v1')\n",
      " 17%|███████                                   | 27/160 [02:16<09:19,  4.21s/it]question: 138, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-v1')\n",
      " 18%|███████▎                                  | 28/160 [02:23<11:03,  5.02s/it]question: 139, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-v1')\n",
      " 18%|███████▌                                  | 29/160 [02:27<10:11,  4.67s/it]question: 140, turn: 1, model: my_model, score: 3, judge: ('gpt-4', 'single-v1')\n",
      " 19%|███████▉                                  | 30/160 [02:32<10:20,  4.77s/it]question: 141, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      " 19%|████████▏                                 | 31/160 [02:39<11:54,  5.54s/it]question: 142, turn: 1, model: my_model, score: 3, judge: ('gpt-4', 'single-v1')\n",
      " 20%|████████▍                                 | 32/160 [02:47<13:08,  6.16s/it]question: 143, turn: 1, model: my_model, score: 8, judge: ('gpt-4', 'single-v1')\n",
      " 21%|████████▋                                 | 33/160 [02:50<11:16,  5.32s/it]question: 144, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      " 21%|████████▉                                 | 34/160 [02:54<10:27,  4.98s/it]question: 145, turn: 1, model: my_model, score: 6, judge: ('gpt-4', 'single-v1')\n",
      " 22%|█████████▏                                | 35/160 [02:59<10:31,  5.06s/it]question: 146, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-v1')\n",
      " 22%|█████████▍                                | 36/160 [03:04<10:19,  5.00s/it]question: 147, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      " 23%|█████████▋                                | 37/160 [03:10<10:35,  5.17s/it]question: 148, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      " 24%|█████████▉                                | 38/160 [03:18<12:40,  6.24s/it]question: 149, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      " 24%|██████████▏                               | 39/160 [03:24<12:21,  6.13s/it]question: 150, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      " 25%|██████████▌                               | 40/160 [03:28<10:41,  5.34s/it]question: 151, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      " 26%|██████████▊                               | 41/160 [03:32<10:06,  5.10s/it]question: 152, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      " 26%|███████████                               | 42/160 [03:37<09:51,  5.02s/it]question: 153, turn: 1, model: my_model, score: 8, judge: ('gpt-4', 'single-v1')\n",
      " 27%|███████████▎                              | 43/160 [03:42<09:33,  4.90s/it]question: 154, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-v1')\n",
      " 28%|███████████▌                              | 44/160 [03:47<09:51,  5.10s/it]question: 155, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      " 28%|███████████▊                              | 45/160 [03:52<09:23,  4.90s/it]question: 156, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-v1')\n",
      " 29%|████████████                              | 46/160 [03:56<09:09,  4.82s/it]question: 157, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      " 29%|████████████▎                             | 47/160 [04:00<08:32,  4.53s/it]question: 158, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      " 30%|████████████▌                             | 48/160 [04:07<09:31,  5.10s/it]question: 159, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-v1')\n",
      " 31%|████████████▊                             | 49/160 [04:13<10:03,  5.43s/it]question: 160, turn: 1, model: my_model, score: 5, judge: ('gpt-4', 'single-v1')\n",
      " 31%|█████████████▏                            | 50/160 [04:21<11:11,  6.10s/it]question: 101, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 32%|█████████████▍                            | 51/160 [04:25<10:22,  5.71s/it]question: 102, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-math-v1')\n",
      " 32%|█████████████▋                            | 52/160 [04:32<10:46,  5.98s/it]question: 103, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1')\n",
      " 33%|█████████████▉                            | 53/160 [04:45<14:35,  8.18s/it]question: 104, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 34%|██████████████▏                           | 54/160 [04:50<12:40,  7.17s/it]question: 105, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1')\n",
      " 34%|██████████████▍                           | 55/160 [05:00<14:11,  8.11s/it]question: 106, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 35%|██████████████▋                           | 56/160 [05:09<14:15,  8.22s/it]question: 107, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 36%|██████████████▉                           | 57/160 [05:17<13:49,  8.05s/it]question: 108, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1')\n",
      " 36%|███████████████▏                          | 58/160 [05:25<13:57,  8.21s/it]question: 109, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 37%|███████████████▍                          | 59/160 [05:37<15:42,  9.33s/it]question: 110, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 38%|███████████████▊                          | 60/160 [05:45<14:34,  8.74s/it]question: 111, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 38%|████████████████                          | 61/160 [05:51<13:07,  7.96s/it]question: 112, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-math-v1')\n",
      " 39%|████████████████▎                         | 62/160 [05:53<10:17,  6.30s/it]question: 113, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1')\n",
      " 39%|████████████████▌                         | 63/160 [06:04<12:33,  7.76s/it]question: 114, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1')\n",
      " 40%|████████████████▊                         | 64/160 [06:17<14:55,  9.32s/it]question: 115, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1')\n",
      " 41%|█████████████████                         | 65/160 [06:22<12:39,  8.00s/it]question: 116, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 41%|█████████████████▎                        | 66/160 [06:38<16:12, 10.35s/it]question: 117, turn: 1, model: my_model, score: 6, judge: ('gpt-4', 'single-math-v1')\n",
      " 42%|█████████████████▌                        | 67/160 [06:50<16:50, 10.86s/it]question: 118, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-math-v1')\n",
      " 42%|█████████████████▊                        | 68/160 [06:56<14:12,  9.26s/it]question: 119, turn: 1, model: my_model, score: 10, judge: ('gpt-4', 'single-math-v1')\n",
      " 43%|██████████████████                        | 69/160 [06:59<11:30,  7.58s/it]question: 120, turn: 1, model: my_model, score: 5, judge: ('gpt-4', 'single-math-v1')\n",
      " 44%|██████████████████▍                       | 70/160 [07:07<11:30,  7.68s/it]question: 121, turn: 1, model: my_model, score: 8, judge: ('gpt-4', 'single-math-v1')\n",
      " 44%|██████████████████▋                       | 71/160 [07:16<12:03,  8.13s/it]question: 122, turn: 1, model: my_model, score: 5, judge: ('gpt-4', 'single-math-v1')\n",
      " 45%|██████████████████▉                       | 72/160 [07:30<14:25,  9.83s/it]question: 123, turn: 1, model: my_model, score: 9, judge: ('gpt-4', 'single-math-v1')\n",
      " 46%|███████████████████▏                      | 73/160 [07:41<14:47, 10.20s/it]question: 124, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1')\n",
      " 46%|███████████████████▍                      | 74/160 [07:54<15:41, 10.95s/it]question: 125, turn: 1, model: my_model, score: 8, judge: ('gpt-4', 'single-math-v1')\n",
      " 47%|███████████████████▋                      | 75/160 [08:12<18:34, 13.11s/it]question: 126, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 48%|███████████████████▉                      | 76/160 [08:28<19:45, 14.12s/it]question: 127, turn: 1, model: my_model, score: 3, judge: ('gpt-4', 'single-math-v1')\n",
      " 48%|████████████████████▏                     | 77/160 [08:37<17:15, 12.48s/it]question: 128, turn: 1, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1')\n",
      " 49%|████████████████████▍                     | 78/160 [08:50<17:11, 12.58s/it]question: 129, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 49%|████████████████████▋                     | 79/160 [09:09<19:40, 14.57s/it]question: 130, turn: 1, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1')\n",
      " 50%|█████████████████████                     | 80/160 [09:22<18:32, 13.91s/it]question: 81, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 51%|█████████████████████▎                    | 81/160 [09:26<14:27, 10.98s/it]question: 82, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 51%|█████████████████████▌                    | 82/160 [09:32<12:21,  9.51s/it]question: 83, turn: 2, model: my_model, score: 7, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 52%|█████████████████████▊                    | 83/160 [09:37<10:24,  8.11s/it]question: 84, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 52%|██████████████████████                    | 84/160 [09:43<09:26,  7.45s/it]question: 85, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 53%|██████████████████████▎                   | 85/160 [09:47<08:08,  6.52s/it]question: 86, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 54%|██████████████████████▌                   | 86/160 [09:55<08:39,  7.02s/it]question: 87, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 54%|██████████████████████▊                   | 87/160 [10:00<07:39,  6.29s/it]question: 88, turn: 2, model: my_model, score: 3, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 55%|███████████████████████                   | 88/160 [10:05<07:05,  5.91s/it]question: 89, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 56%|███████████████████████▎                  | 89/160 [10:09<06:18,  5.33s/it]question: 90, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 56%|███████████████████████▋                  | 90/160 [10:13<05:55,  5.07s/it]question: 91, turn: 2, model: my_model, score: 5, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 57%|███████████████████████▉                  | 91/160 [10:18<05:41,  4.95s/it]question: 92, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 57%|████████████████████████▏                 | 92/160 [10:22<05:13,  4.61s/it]question: 93, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 58%|████████████████████████▍                 | 93/160 [10:28<05:42,  5.12s/it]question: 94, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 59%|████████████████████████▋                 | 94/160 [10:34<05:56,  5.40s/it]question: 95, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 59%|████████████████████████▉                 | 95/160 [10:43<07:10,  6.63s/it]question: 96, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 60%|█████████████████████████▏                | 96/160 [10:48<06:31,  6.11s/it]question: 97, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 61%|█████████████████████████▍                | 97/160 [10:53<06:04,  5.79s/it]question: 98, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 61%|█████████████████████████▋                | 98/160 [10:58<05:34,  5.40s/it]question: 99, turn: 2, model: my_model, score: 5, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 62%|█████████████████████████▉                | 99/160 [11:02<05:08,  5.06s/it]question: 100, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 62%|█████████████████████████▋               | 100/160 [11:07<04:53,  4.89s/it]question: 131, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 63%|█████████████████████████▉               | 101/160 [11:12<04:49,  4.90s/it]question: 132, turn: 2, model: my_model, score: 7, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 64%|██████████████████████████▏              | 102/160 [11:18<05:12,  5.39s/it]question: 133, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 64%|██████████████████████████▍              | 103/160 [11:21<04:30,  4.75s/it]question: 134, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 65%|██████████████████████████▋              | 104/160 [11:27<04:41,  5.03s/it]question: 135, turn: 2, model: my_model, score: 7, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 66%|██████████████████████████▉              | 105/160 [11:32<04:36,  5.03s/it]question: 136, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 66%|███████████████████████████▏             | 106/160 [11:36<04:14,  4.71s/it]question: 137, turn: 2, model: my_model, score: 7, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 67%|███████████████████████████▍             | 107/160 [11:42<04:24,  4.99s/it]question: 138, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 68%|███████████████████████████▋             | 108/160 [11:51<05:28,  6.32s/it]question: 139, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 68%|███████████████████████████▉             | 109/160 [11:57<05:11,  6.11s/it]question: 140, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 69%|████████████████████████████▏            | 110/160 [12:06<05:48,  6.96s/it]question: 141, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 69%|████████████████████████████▍            | 111/160 [12:11<05:21,  6.55s/it]question: 142, turn: 2, model: my_model, score: 3, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 70%|████████████████████████████▋            | 112/160 [12:21<06:03,  7.57s/it]question: 143, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 71%|████████████████████████████▉            | 113/160 [12:28<05:47,  7.39s/it]question: 144, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 71%|█████████████████████████████▏           | 114/160 [12:33<04:57,  6.47s/it]question: 145, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 72%|█████████████████████████████▍           | 115/160 [12:41<05:23,  7.18s/it]question: 146, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 72%|█████████████████████████████▋           | 116/160 [12:45<04:28,  6.09s/it]question: 147, turn: 2, model: my_model, score: 7, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 73%|█████████████████████████████▉           | 117/160 [12:54<04:56,  6.89s/it]question: 148, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 74%|██████████████████████████████▏          | 118/160 [12:58<04:17,  6.13s/it]question: 149, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 74%|██████████████████████████████▍          | 119/160 [13:03<03:52,  5.66s/it]question: 150, turn: 2, model: my_model, score: 4, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 75%|██████████████████████████████▊          | 120/160 [13:09<03:58,  5.97s/it]question: 151, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 76%|███████████████████████████████          | 121/160 [13:14<03:32,  5.45s/it]question: 152, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 76%|███████████████████████████████▎         | 122/160 [13:18<03:12,  5.05s/it]question: 153, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 77%|███████████████████████████████▌         | 123/160 [13:26<03:44,  6.08s/it]question: 154, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 78%|███████████████████████████████▊         | 124/160 [13:32<03:39,  6.11s/it]question: 155, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 78%|████████████████████████████████         | 125/160 [13:38<03:24,  5.85s/it]question: 156, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 79%|████████████████████████████████▎        | 126/160 [13:46<03:43,  6.58s/it]question: 157, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 79%|████████████████████████████████▌        | 127/160 [13:50<03:08,  5.72s/it]question: 158, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 80%|████████████████████████████████▊        | 128/160 [13:54<02:49,  5.29s/it]question: 159, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 81%|█████████████████████████████████        | 129/160 [13:59<02:44,  5.30s/it]question: 160, turn: 2, model: my_model, score: 9, judge: ('gpt-4', 'single-v1-multi-turn')\n",
      " 81%|█████████████████████████████████▎       | 130/160 [14:03<02:23,  4.77s/it]question: 101, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 82%|█████████████████████████████████▌       | 131/160 [14:11<02:45,  5.70s/it]question: 102, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 82%|█████████████████████████████████▊       | 132/160 [14:18<02:52,  6.17s/it]question: 103, turn: 2, model: my_model, score: 6, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 83%|██████████████████████████████████       | 133/160 [14:28<03:19,  7.37s/it]question: 104, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 84%|██████████████████████████████████▎      | 134/160 [14:36<03:14,  7.46s/it]question: 105, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 84%|██████████████████████████████████▌      | 135/160 [14:45<03:19,  7.97s/it]question: 106, turn: 2, model: my_model, score: 3, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 85%|██████████████████████████████████▊      | 136/160 [14:55<03:26,  8.59s/it]question: 107, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 86%|███████████████████████████████████      | 137/160 [14:59<02:48,  7.33s/it]question: 108, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 86%|███████████████████████████████████▎     | 138/160 [15:06<02:37,  7.17s/it]question: 109, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 87%|███████████████████████████████████▌     | 139/160 [15:17<02:54,  8.29s/it]question: 110, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 88%|███████████████████████████████████▉     | 140/160 [15:34<03:37, 10.86s/it]question: 111, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 88%|████████████████████████████████████▏    | 141/160 [15:40<03:00,  9.48s/it]question: 112, turn: 2, model: my_model, score: 10, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 89%|████████████████████████████████████▍    | 142/160 [15:44<02:20,  7.83s/it]question: 113, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 89%|████████████████████████████████████▋    | 143/160 [15:52<02:12,  7.80s/it]question: 114, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 90%|████████████████████████████████████▉    | 144/160 [16:25<04:04, 15.31s/it]question: 115, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 91%|█████████████████████████████████████▏   | 145/160 [16:32<03:15, 13.07s/it]question: 116, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 91%|█████████████████████████████████████▍   | 146/160 [16:47<03:10, 13.59s/it]question: 117, turn: 2, model: my_model, score: 6, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 92%|█████████████████████████████████████▋   | 147/160 [17:04<03:08, 14.54s/it]question: 118, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 92%|█████████████████████████████████████▉   | 148/160 [17:13<02:33, 12.82s/it]question: 119, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 93%|██████████████████████████████████████▏  | 149/160 [17:25<02:17, 12.54s/it]question: 120, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 94%|██████████████████████████████████████▍  | 150/160 [17:37<02:05, 12.53s/it]question: 121, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 94%|██████████████████████████████████████▋  | 151/160 [17:50<01:54, 12.72s/it]question: 122, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 95%|██████████████████████████████████████▉  | 152/160 [18:05<01:45, 13.19s/it]question: 123, turn: 2, model: my_model, score: 8, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 96%|███████████████████████████████████████▏ | 153/160 [18:22<01:40, 14.32s/it]question: 124, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 96%|███████████████████████████████████████▍ | 154/160 [18:47<01:45, 17.64s/it]question: 125, turn: 2, model: my_model, score: 4, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 97%|███████████████████████████████████████▋ | 155/160 [19:06<01:29, 17.93s/it]question: 126, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 98%|███████████████████████████████████████▉ | 156/160 [19:21<01:08, 17.22s/it]question: 127, turn: 2, model: my_model, score: 5, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 98%|████████████████████████████████████████▏| 157/160 [19:32<00:45, 15.23s/it]question: 128, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 99%|████████████████████████████████████████▍| 158/160 [19:49<00:31, 15.96s/it]question: 129, turn: 2, model: my_model, score: 1, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      " 99%|████████████████████████████████████████▋| 159/160 [20:06<00:16, 16.21s/it]question: 130, turn: 2, model: my_model, score: 2, judge: ('gpt-4', 'single-math-v1-multi-turn')\n",
      "100%|█████████████████████████████████████████| 160/160 [20:17<00:00,  7.61s/it]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(LLM_JUDGE_FOLDER)\n",
    "! echo -ne '\\n' | python gen_judgment.py --model-list $MODEL_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the judgement folder to make sure your results are there. The default output filename is `gpt-4_single.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['gpt-4_single.jsonl']\n"
     ]
    }
   ],
   "source": [
    "out_files = os.listdir(f\"{LLM_JUDGE_FOLDER}/data/mt_bench/model_judgment/\")\n",
    "print(f\"files: {out_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve your aggregate judgment score (with per-turn breakdown), as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: single\n",
      "Input file: data/mt_bench/model_judgment/gpt-4_single.jsonl\n",
      "\n",
      "########## First turn ##########\n",
      "                 score\n",
      "model    turn         \n",
      "my_model 1     5.84375\n",
      "\n",
      "########## Second turn ##########\n",
      "                score\n",
      "model    turn        \n",
      "my_model 2     4.9375\n",
      "\n",
      "########## Average ##########\n",
      "             score\n",
      "model             \n",
      "my_model  5.390625\n"
     ]
    }
   ],
   "source": [
    "! python show_result.py --model-list $MODEL_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Retain your configuration for reproducibility\n",
    "\n",
    "In order to be able to repro your evaluation run in the future, do not forget to save the configuration of your evaluation, together with your evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "import git\n",
    "\n",
    "evaluation_config_dict = {\n",
    "    \"fast_chat_repo\": {\n",
    "        \"repo_tag\": str(git.Repo(FAST_CHAT_REPO).tags[-1]),\n",
    "        \"commit_hash\": git.Repo(FAST_CHAT_REPO).head.commit.hexsha,\n",
    "    },\n",
    "    \"configs\": {\n",
    "        \"model_path\": MODEL_PATH,\n",
    "        \"model_id\": MODEL_ID,\n",
    "    },\n",
    "    \"timestamp\": str(datetime.datetime.now()),\n",
    "    \"eval_metrics\": \"<add relevant metrics here>\",\n",
    "}\n",
    "\n",
    "evaluation_config_json = json.dumps(evaluation_config_dict, indent=2)\n",
    "with open(\"./evaluation_config.json\", \"w\") as output_file:\n",
    "    output_file.write(evaluation_config_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
