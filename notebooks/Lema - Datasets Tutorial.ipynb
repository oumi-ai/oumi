{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForSeq2Seq\n",
    "\n",
    "from lema.datasets.alpaca import AlpacaDataset\n",
    "from lema.datasets.chatqa import ChatqaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Listing Supported Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tatsu-lab/alpaca -> AlpacaDataset\n",
      "yahma/alpaca-cleaned -> AlpacaDataset\n",
      "nvidia/ChatQA-Training-Data -> ChatqaDataset\n"
     ]
    }
   ],
   "source": [
    "from lema.core.registry import REGISTRY, RegistryType\n",
    "\n",
    "\n",
    "def list_datasets():\n",
    "    \"\"\"List all datasets in the registry.\"\"\"\n",
    "    for key, value in REGISTRY._registry.items():\n",
    "        if key.registry_type == RegistryType.DATASET:\n",
    "            print(key.name, \"->\", value.__name__)\n",
    "\n",
    "\n",
    "list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the alpaca dataset. Since multiple variants can be registered in the HuggingFace hub, by default we use `Dataset.default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oussamaelachqar/miniconda3/envs/dev/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80.4 ms, sys: 11.5 ms, total: 92 ms\n",
      "Wall time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: tatsu-lab/alpaca\n",
      "CPU times: user 164 ms, sys: 58.6 ms, total: 222 ms\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = AlpacaDataset(tokenizer=tokenizer)\n",
    "\n",
    "print(f\"Using: {dataset.dataset_name_or_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can pass a custom HuggingFace hub identifier. You can find a list of supported datasets in `Dataset.supported_datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: yahma/alpaca-cleaned\n",
      "CPU times: user 146 ms, sys: 33.3 ms, total: 179 ms\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = AlpacaDataset(\n",
    "    dataset_name_or_path=\"yahma/alpaca-cleaned\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(f\"Using: {dataset.dataset_name_or_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the dataset is downloaded from the HuggingFace hub, and cached in the `~/.cache/huggingface/datasets` directory.\n",
    "\n",
    "When instantiating the class, the dataset is loaded in memory. This is acceptable with small datasets, but for larger datasets, we can either use `IterableDataset` for streaming batch from disk, or shard per worker rank (so that Memory // N_GPUs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also load a dataset from a local `jsonl` or `parquet` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = LemaSftDataset(dataset_name_or_path=\"./sft.jsonl\", tokenizer=tokenizer)\n",
    "# dataset = LemaSftDataset(dataset_name_or_path=\"./sft.parquet\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Iterating Over Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 51760\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of examples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given everything is loaded into memory, we can randomly access any row in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the GPT2TokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 µs ± 6.45 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "dataset[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate over the dataset to get the examples, either manually or using a DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 216 ms, total: 16.4 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Manual iteration\n",
    "[dataset[i] for i in range(len(dataset))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 147 ms, total: 16.2 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# With a pytorch data loader\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=1, num_workers=0, shuffle=False, collate_fn=lambda x: x\n",
    ")\n",
    "list(loader);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use any library from the pytorch ecosystem, e.g. `torchtext`, `torchdata`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.stateful_dataloader import StatefulDataLoader\n",
    "\n",
    "loader = StatefulDataLoader(dataset, batch_size=1, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index_sampler_state': {'samples_yielded': 1},\n",
       " '_sampler_iter_state': None,\n",
       " '_sampler_iter_yielded': 1,\n",
       " '_num_yielded': 1,\n",
       " '_IterableDataset_len_called': None,\n",
       " '_shared_seed': None,\n",
       " 'fetcher_state': None,\n",
       " 'dataset_state': None,\n",
       " '_iterator_finished': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(loader));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Accessing Individual Examples\n",
    "\n",
    "Alpaca is a \"Supervised Finetuning Dataset\". It contains instructions, user inputs, and model outputs. An SFT dataset has the following methods:\n",
    "\n",
    "**Base Map Dataset**\n",
    "```python\n",
    "dataset[0] -> model inputs  # pytorch convention\n",
    "dataset.raw(0) -> raw data  # lema convention\n",
    "```\n",
    "**Base SFT Dataset**\n",
    "```python\n",
    "dataset.conversation(0) -> conversation # model independent\n",
    "dataset.prompt(0) -> prompt  # dependends on the tokenizer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output         1. Eat a balanced and nutritious diet: Make su...\n",
       "input                                                           \n",
       "instruction                 Give three tips for staying healthy.\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw data (pd.Series, dict), as defined by the dataset authors\n",
    "dataset.raw(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(id=None, content='Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.', role=<Role.SYSTEM: 'system'>),\n",
       " Message(id=None, content='Give three tips for staying healthy.', role=<Role.USER: 'user'>),\n",
       " Message(id=None, content='1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.', role=<Role.ASSISTANT: 'assistant'>)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to standard Lema SFT format (lema.core.types.Conversation)\n",
    "dataset.conversation(0).messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.<|endoftext|>Give three tips for staying healthy.<|endoftext|>1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|endoftext|>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to model prompt (str). This include the model's chat temlate,\n",
    "# EOS tokens for inference/generation, etc.\n",
    "dataset.prompt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [21106, 318, 281, 12064, 326, 8477, 257, 4876, 11, 20312, 351, 281, 5128, 326, 3769, 2252, 4732, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 50256, 23318, 1115, 9040, 329, 10589, 5448, 13, 50256, 16, 13, 27574, 257, 12974, 290, 48102, 5496, 25, 6889, 1654, 534, 13840, 389, 19889, 286, 257, 4996, 286, 15921, 290, 13701, 11, 10904, 7532, 11, 2187, 21824, 11, 290, 5448, 27997, 13, 770, 5419, 284, 2148, 534, 1767, 351, 262, 6393, 20901, 284, 2163, 379, 663, 1266, 290, 460, 1037, 2948, 10726, 10040, 13, 198, 198, 17, 13, 1985, 496, 287, 3218, 3518, 3842, 25, 32900, 318, 8780, 329, 10941, 1913, 11945, 11, 12749, 11, 290, 21134, 1535, 13, 36223, 329, 379, 1551, 6640, 2431, 286, 10768, 43294, 5517, 393, 5441, 2431, 286, 31543, 5517, 1123, 1285, 13, 198, 198, 18, 13, 3497, 1576, 3993, 25, 18067, 1576, 3081, 3993, 318, 8780, 329, 3518, 290, 5110, 880, 12, 11873, 13, 632, 5419, 284, 16697, 10038, 11, 2987, 10870, 2163, 11, 290, 6971, 5448, 3349, 290, 10900, 2163, 13, 36223, 329, 767, 12, 24, 2250, 286, 3993, 1123, 1755, 13, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is fed to the model.forward (dict)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Accessing the underlying data backend (for debugging only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently use pd.DataFrame as a backend for the dataset. We can trivially use either HuggingFace `datasets`, or an `arrow` Table as a backend for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['output', 'input', 'instruction'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n",
       "      <td></td>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The three primary colors are red, blue, and ye...</td>\n",
       "      <td></td>\n",
       "      <td>What are the three primary colors?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An atom is the basic building block of all mat...</td>\n",
       "      <td></td>\n",
       "      <td>Describe the structure of an atom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There are several ways to reduce air pollution...</td>\n",
       "      <td></td>\n",
       "      <td>How can we reduce air pollution?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had to make a difficult decision when I was ...</td>\n",
       "      <td></td>\n",
       "      <td>Pretend you are a project manager of a constru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              output input  \\\n",
       "0  1. Eat a balanced and nutritious diet: Make su...         \n",
       "1  The three primary colors are red, blue, and ye...         \n",
       "2  An atom is the basic building block of all mat...         \n",
       "3  There are several ways to reduce air pollution...         \n",
       "4  I had to make a difficult decision when I was ...         \n",
       "\n",
       "                                         instruction  \n",
       "0               Give three tips for staying healthy.  \n",
       "1                 What are the three primary colors?  \n",
       "2                 Describe the structure of an atom.  \n",
       "3                   How can we reduce air pollution?  \n",
       "4  Pretend you are a project manager of a constru...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.data[[\"instruction\", \"output\", \"input\"]].map(len).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To customize preprocessing behavior, we can override the appropriate method:\n",
    "- `BaseMapDataset.__getitem__` for fully custom behavior, multi-modal, multi-task, etc.\n",
    "- `BaseMapDataset.transform` for custom preprocessing of standard datasets (inputs, labels)\n",
    "- `BaseSftDataset.transform` To customize preprocessing, tokenization of a standard SFT dataset\n",
    "- `BaseSftDataset.transform_conversation` To transform raw data row into lema conversation\n",
    "- `LemaSftDataset` -> If raw data already in Lema format, no custom class needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: tatsu-lab/alpaca\n"
     ]
    }
   ],
   "source": [
    "dataset = AlpacaDataset(tokenizer=tokenizer)\n",
    "\n",
    "print(f\"Using: {dataset.dataset_name_or_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "dataset.raw(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.29 µs ± 52.9 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "dataset.raw(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9 µs ± 463 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "dataset.conversation(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.5 µs ± 180 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "dataset.prompt(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 µs ± 5.24 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "dataset[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing with other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = datasets.load_dataset(\"tatsu-lab/alpaca\")\n",
    "hf_dataset = hf_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Random Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.27 µs ± 125 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "dataset.raw(idx)  # use lema dataset random access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.4 µs ± 361 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "hf_dataset[idx]  # use huggingface dataset random access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.07 µs ± 35 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "hf_dataset.data[\"text\"][idx].as_py()  # directly access the arrow table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649 µs ± 19 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Arrow\n",
    "dataset.tokenize(hf_dataset.data[\"text\"][0].as_py())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.3 µs ± 978 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# HF Datasets\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "dataset.tokenize(hf_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.3 µs ± 1.39 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Lema dataset\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "dataset.tokenize(dataset.raw(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 µs ± 3.98 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Full lema pipeline\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "dataset[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5 s ± 129 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Manual iteration\n",
    "[dataset[i] for i in range(len(dataset))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# With a pytorch data loader\n",
    "loader = DataLoader(dataset, batch_size=1, num_workers=0, shuffle=False)\n",
    "list(loader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         21800369 function calls (21748606 primitive calls) in 23.434 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    51760   14.265    0.000   14.265    0.000 {method 'encode_batch' of 'tokenizers.Tokenizer' objects}\n",
      "   103520    1.456    0.000    1.456    0.000 {built-in method torch.tensor}\n",
      "        1    0.396    0.396   23.434   23.434 <string>:1(<module>)\n",
      "   207040    0.367    0.000    0.611    0.000 {method 'validate_python' of 'pydantic_core._pydantic_core.SchemaValidator' objects}\n",
      "  4547145    0.355    0.000    0.575    0.000 {built-in method builtins.isinstance}\n",
      "   207040    0.259    0.000    0.294    0.000 enum.py:686(__call__)\n",
      "   226197    0.197    0.000    0.719    0.000 series.py:1085(__getitem__)\n",
      "   155280    0.190    0.000    0.294    0.000 sandbox.py:125(is_internal_attribute)\n",
      "    51760    0.182    0.000   19.989    0.000 tokenization_utils_base.py:1684(apply_chat_template)\n",
      "    51760    0.181    0.000    1.603    0.000 base_dataset.py:314(format_inputs)\n",
      "    51760    0.178    0.000    0.183    0.000 tokenization_utils_fast.py:267(_convert_encoding)\n",
      "    51760    0.177    0.000   17.141    0.000 tokenization_utils_fast.py:469(_batch_encode_plus)\n",
      "    51760    0.160    0.000    0.579    0.000 runtime.py:91(new_context)\n",
      "    51760    0.151    0.000    1.971    0.000 tokenization_utils_base.py:681(convert_to_tensors)\n",
      "    51760    0.146    0.000    0.292    0.000 tokenization_utils_fast.py:398(set_truncation_and_padding)\n",
      "    51760    0.121    0.000   17.265    0.000 tokenization_gpt2_fast.py:121(_batch_encode_plus)\n",
      "   277957    0.120    0.000    0.173    0.000 indexing.py:2758(check_dict_or_set_indexers)\n",
      "   226197    0.120    0.000    0.324    0.000 series.py:1210(_get_value)\n",
      "    51760    0.115    0.000    0.759    0.000 frame.py:3971(_ixs)\n",
      "   362320    0.114    0.000    0.931    0.000 <template>:4(root)\n",
      "   776400    0.113    0.000    0.192    0.000 {built-in method builtins.getattr}\n",
      "   226197    0.097    0.000    0.110    0.000 base.py:3774(get_loc)\n",
      "    51760    0.095    0.000   17.881    0.000 tokenization_utils_base.py:2784(__call__)\n",
      "   362320    0.094    0.000    0.094    0.000 __init__.py:1000(__getitem__)\n",
      "   103520    0.092    0.000    0.144    0.000 __init__.py:1014(__iter__)\n",
      "    51760    0.091    0.000   17.683    0.000 tokenization_utils_base.py:2985(encode_plus)\n",
      "    51760    0.090    0.000    0.198    0.000 managers.py:959(fast_xs)\n",
      "   155280    0.088    0.000    0.279    0.000 sandbox.py:162(modifies_known_mutable)\n",
      "    51760    0.087    0.000    1.116    0.000 indexing.py:1720(_getitem_axis)\n",
      "    51760    0.084    0.000   17.368    0.000 tokenization_utils_fast.py:554(_encode_plus)\n",
      "    51760    0.082    0.000    0.118    0.000 generic.py:6230(__finalize__)\n",
      "    51760    0.081    0.000    0.173    0.000 tokenization_utils_base.py:2646(_get_padding_truncation_strategies)\n",
      "    51760    0.074    0.000    0.167    0.000 runtime.py:163(__init__)\n",
      "    51760    0.074    0.000   17.774    0.000 tokenization_utils_base.py:2873(_call_one)\n",
      "   155280    0.072    0.000    0.072    0.000 generic.py:6295(__setattr__)\n",
      "   155280    0.070    0.000    0.713    0.000 sandbox.py:402(is_safe_attribute)\n",
      "   517600    0.068    0.000    0.127    0.000 <frozen abc>:117(__instancecheck__)\n",
      "    51760    0.066    0.000    2.156    0.000 tokenization_utils_base.py:204(__init__)\n",
      "    51760    0.065    0.000    0.232    0.000 tokenization_utils_base.py:1293(special_tokens_map)\n",
      "    51760    0.063    0.000    1.243    0.000 indexing.py:1177(__getitem__)\n",
      "   517600    0.059    0.000    0.059    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    51760    0.058    0.000    0.137    0.000 copy.py:128(deepcopy)\n",
      "   155280    0.057    0.000    0.783    0.000 sandbox.py:321(getattr)\n",
      "    51760    0.053    0.000    0.067    0.000 generic.py:278(__init__)\n",
      "   103520    0.053    0.000    1.518    0.000 tokenization_utils_base.py:718(as_tensor)\n",
      "   155280    0.052    0.000    0.364    0.000 sandbox.py:258(is_safe_attribute)\n",
      "    51760    0.051    0.000   20.043    0.000 base_dataset.py:240(tokenize)\n",
      "    51760    0.049    0.000    1.629    0.000 environment.py:1269(render)\n",
      "    51760    0.048    0.000    0.979    0.000 {method 'join' of 'str' objects}\n",
      "   207040    0.047    0.000    0.659    0.000 main.py:161(__init__)\n",
      "    51760    0.047    0.000   17.419    0.000 tokenization_gpt2_fast.py:130(_encode_plus)\n",
      "   226197    0.047    0.000    0.093    0.000 series.py:826(_values)\n",
      "    51760    0.046    0.000    0.092    0.000 <frozen _collections_abc>:941(update)\n",
      "   155280    0.046    0.000    0.108    0.000 _std_types_schema.py:91(to_enum)\n",
      "   277957    0.045    0.000    0.059    0.000 common.py:370(apply_if_callable)\n",
      "   103520    0.045    0.000    0.142    0.000 tokenization_utils_base.py:1215(pad_token_id)\n",
      "   103520    0.043    0.000    0.043    0.000 tokenization_gpt2_fast.py:144(default_chat_template)\n",
      "   207040    0.041    0.000    0.094    0.000 generic.py:42(_instancecheck)\n",
      "    51760    0.041    0.000    1.294    0.000 base_dataset.py:72(raw)\n",
      "   414080    0.041    0.000    0.119    0.000 <frozen _collections_abc>:835(__iter__)\n",
      "   207040    0.040    0.000    0.053    0.000 generic.py:37(_check)\n",
      "   226197    0.040    0.000    0.047    0.000 managers.py:2003(internal_values)\n",
      "    51760    0.039    0.000    0.077    0.000 blocks.py:2709(new_block)\n",
      "    51760    0.039    0.000   21.684    0.000 base_dataset.py:236(preprocess_inputs)\n",
      "   258800    0.039    0.000    0.039    0.000 tokenization_utils_base.py:1083(pad_token)\n",
      "   103520    0.036    0.000    0.081    0.000 tokenization_utils_fast.py:314(convert_tokens_to_ids)\n",
      "   207040    0.035    0.000    0.035    0.000 enum.py:1093(__new__)\n",
      "   207040    0.035    0.000    0.035    0.000 runtime.py:227(resolve_or_missing)\n",
      "        1    0.034    0.034   23.038   23.038 <string>:1(<listcomp>)\n",
      "310564/258801    0.034    0.000    0.045    0.000 {built-in method builtins.len}\n",
      "    51760    0.033    0.000    0.045    0.000 tokenization_utils_fast.py:448(<dictcomp>)\n",
      "   310560    0.031    0.000    0.031    0.000 {method 'startswith' of 'str' objects}\n",
      "    51760    0.030    0.000    0.187    0.000 frame.py:672(_constructor_sliced_from_mgr)\n",
      "   103520    0.029    0.000    0.044    0.000 managers.py:292(arrays)\n",
      "    51760    0.029    0.000    0.094    0.000 indexing.py:1668(_validate_integer)\n",
      "    51760    0.029    0.000    0.036    0.000 copy.py:243(_keep_alive)\n",
      "   362320    0.029    0.000    0.029    0.000 {built-in method builtins.hasattr}\n",
      "    51760    0.028    0.000    0.038    0.000 blocks.py:2667(get_block_type)\n",
      "   414080    0.027    0.000    0.027    0.000 {method 'get' of 'dict' objects}\n",
      "   207040    0.027    0.000    0.027    0.000 {built-in method fromkeys}\n",
      "   207040    0.027    0.000    0.027    0.000 __init__.py:1128(__setitem__)\n",
      "    51760    0.026    0.000    0.029    0.000 range.py:1009(__getitem__)\n",
      "    51760    0.026    0.000    0.035    0.000 generic.py:585(_get_axis)\n",
      "    51760    0.025    0.000    0.099    0.000 generic.py:339(_from_mgr)\n",
      "    51760    0.025    0.000    0.209    0.000 tokenization_utils_fast.py:516(<listcomp>)\n",
      "   103520    0.025    0.000    0.068    0.000 base.py:332(array)\n",
      "   103520    0.025    0.000    0.041    0.000 tokenization_utils_fast.py:333(_convert_token_to_id_with_added_voc)\n",
      "    51760    0.025    0.000   23.003    0.000 base_dataset.py:51(__getitem__)\n",
      "   258800    0.023    0.000    0.023    0.000 {method 'update' of 'dict' objects}\n",
      "    51760    0.022    0.000    0.029    0.000 copy.py:227(_deepcopy_dict)\n",
      "    51760    0.021    0.000    0.601    0.000 environment.py:1375(new_context)\n",
      "   103520    0.021    0.000    0.021    0.000 tokenization_utils_fast.py:538(<listcomp>)\n",
      "   103520    0.021    0.000    0.031    0.000 __init__.py:584(is_tensor)\n",
      "    51760    0.021    0.000    0.118    0.000 common.py:97(is_bool_indexer)\n",
      "    51760    0.020    0.000    0.112    0.000 __init__.py:1111(__init__)\n",
      "   381477    0.019    0.000    0.019    0.000 {built-in method builtins.callable}\n",
      "    51760    0.019    0.000    0.025    0.000 tokenization_utils_base.py:1118(additional_special_tokens)\n",
      "    51760    0.017    0.000    0.023    0.000 enum.py:193(__get__)\n",
      "   310560    0.017    0.000    0.017    0.000 {method 'append' of 'list' objects}\n",
      "    51760    0.017    0.000    0.024    0.000 <frozen _collections_abc>:786(keys)\n",
      "    51760    0.016    0.000    0.019    0.000 nodes.py:74(__init__)\n",
      "   103520    0.016    0.000    0.016    0.000 {method 'token_to_id' of 'tokenizers.Tokenizer' objects}\n",
      "    51760    0.015    0.000    0.114    0.000 frame.py:669(_sliced_from_mgr)\n",
      "    51760    0.015    0.000    0.015    0.000 flags.py:87(allows_duplicate_labels)\n",
      "   207040    0.015    0.000    0.015    0.000 {built-in method builtins.id}\n",
      "    51760    0.014    0.000    0.014    0.000 blocks.py:1253(iget)\n",
      "   103520    0.014    0.000    0.014    0.000 managers.py:304(<listcomp>)\n",
      "    51760    0.014    0.000    0.225    0.000 generic.py:4520(get)\n",
      "   226197    0.014    0.000    0.014    0.000 base.py:6671(_maybe_cast_indexer)\n",
      "    51760    0.014    0.000    0.016    0.000 indexing.py:1166(_check_deprecated_callable_usage)\n",
      "    51760    0.014    0.000    0.014    0.000 flags.py:51(__init__)\n",
      "    51760    0.013    0.000    0.015    0.000 tokenization_utils_base.py:243(__getitem__)\n",
      "   207040    0.013    0.000    0.013    0.000 {method 'items' of 'dict' objects}\n",
      "    51760    0.012    0.000    0.012    0.000 tokenization_utils_base.py:1038(bos_token)\n",
      "    51760    0.012    0.000    0.027    0.000 generic.py:4373(_set_is_copy)\n",
      "    51760    0.011    0.000    0.011    0.000 utils.py:62(is_list_like_indexer)\n",
      "    19157    0.011    0.000    0.011    0.000 {method 'format' of 'str' objects}\n",
      "    51760    0.011    0.000    0.013    0.000 tokenization_utils_base.py:2895(_is_valid_text_input)\n",
      "    51760    0.011    0.000    0.014    0.000 tokenization_utils_base.py:287(items)\n",
      "    51760    0.011    0.000    0.017    0.000 __init__.py:1023(__bool__)\n",
      "    51760    0.011    0.000    0.011    0.000 indexing.py:161(iloc)\n",
      "    51761    0.011    0.000    0.016    0.000 range.py:999(__len__)\n",
      "    51760    0.010    0.000    0.010    0.000 managers.py:1836(__init__)\n",
      "   136123    0.009    0.000    0.009    0.000 typing.py:2268(cast)\n",
      "    51760    0.009    0.000    0.009    0.000 generic.py:571(_get_axis_number)\n",
      "   103520    0.009    0.000    0.009    0.000 tokenization_utils_base.py:3883(_eventual_warn_about_too_long_sequence)\n",
      "   103520    0.009    0.000    0.009    0.000 generic.py:404(flags)\n",
      "    51760    0.009    0.000    0.009    0.000 tokenization_utils_fast.py:540(<listcomp>)\n",
      "    51760    0.008    0.000    0.008    0.000 tokenization_utils_base.py:1071(sep_token)\n",
      "   103520    0.008    0.000    0.008    0.000 tokenization_utils_base.py:3903(_switch_to_input_mode)\n",
      "    51760    0.008    0.000    0.008    0.000 tokenization_utils_base.py:1049(eos_token)\n",
      "    51760    0.007    0.000    0.007    0.000 tokenization_utils_base.py:1060(unk_token)\n",
      "   103520    0.007    0.000    0.007    0.000 {method 'pop' of 'dict' objects}\n",
      "    51760    0.007    0.000    0.007    0.000 managers.py:1939(_block)\n",
      "    51760    0.007    0.000    0.007    0.000 <frozen _collections_abc>:812(__init__)\n",
      "    51760    0.007    0.000    0.007    0.000 {built-in method __new__ of type object at 0x1029bd600}\n",
      "   103520    0.006    0.000    0.006    0.000 {built-in method builtins.iter}\n",
      "    51760    0.006    0.000    0.006    0.000 tokenization_utils_base.py:1094(cls_token)\n",
      "    51760    0.006    0.000    0.006    0.000 enum.py:1255(value)\n",
      "    51760    0.006    0.000    0.006    0.000 {built-in method builtins.any}\n",
      "    51760    0.006    0.000    0.006    0.000 tokenization_utils_base.py:1106(mask_token)\n",
      "    51760    0.006    0.000    0.006    0.000 tokenization_utils_base.py:1128(<listcomp>)\n",
      "    51760    0.006    0.000    0.006    0.000 import_utils.py:290(is_torch_available)\n",
      "    51760    0.005    0.000    0.005    0.000 generic.py:362(attrs)\n",
      "    51760    0.005    0.000    0.005    0.000 runtime.py:182(<dictcomp>)\n",
      "    51760    0.005    0.000    0.005    0.000 tokenization_utils_base.py:1224(pad_token_type_id)\n",
      "    51760    0.005    0.000    0.005    0.000 flags.py:55(allows_duplicate_labels)\n",
      "    51760    0.004    0.000    0.004    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000   23.434   23.434 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:1631(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 base_dataset.py:64(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
     ]
    }
   ],
   "source": [
    "%prun [dataset[i] for i in range(len(dataset))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 21.6536 s\n",
      "File: /Users/oussamaelachqar/source/lema/lema/src/lema/core/types/base_dataset.py\n",
      "Function: __getitem__ at line 51\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    51                                               def __getitem__(self, idx: int) -> Union[Conversation, dict]:\n",
      "    52                                                   \"\"\"Gets the item at the specified index.\n",
      "    53                                           \n",
      "    54                                                   Args:\n",
      "    55                                                       idx (int): The index of the item to retrieve.\n",
      "    56                                           \n",
      "    57                                                   Returns:\n",
      "    58                                                       dict: The item at the specified index.\n",
      "    59                                                   \"\"\"\n",
      "    60     51760 1041049000.0  20113.0      4.8          sample = self.raw(idx)\n",
      "    61     51760        2e+10 398108.2     95.2          processed = self.preprocess_inputs(sample)\n",
      "    62     51760    6509000.0    125.8      0.0          return processed"
     ]
    }
   ],
   "source": [
    "%lprun -f dataset.__getitem__ [dataset[i] for i in range(len(dataset))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3034.42 MiB, increment: 317.41 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit [dataset[i] for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Benchmark with Model Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oussamaelachqar/miniconda3/envs/dev/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 731 ms, sys: 1.02 s, total: 1.75 s\n",
      "Wall time: 624 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 156 ms, sys: 28.9 ms, total: 185 ms\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = AlpacaDataset(tokenizer=tokenizer)\n",
    "collator_fn = DataCollatorForSeq2Seq(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=3, num_workers=0, shuffle=False, collate_fn=collator_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 ms ± 1.97 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Including pre-processing\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(loader))\n",
    "    model.forward(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 ms ± 1.66 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Excluding pre-processing\n",
    "with torch.no_grad():\n",
    "    model.forward(**fixed_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sanity Check Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatqaDataset(tokenizer=tokenizer, subset=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answers                                             [28-yard]\n",
       "messages    [{'content': 'How long was the Lion's longest ...\n",
       "document    To start the season, the Lions traveled south ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.raw(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(id=None, content='Answer the following question with a short span.', role=<Role.SYSTEM: 'system'>),\n",
       " Message(id=None, content='Only use the information from the user provided context to answer the question.', role=<Role.SYSTEM: 'system'>),\n",
       " Message(id=None, content=\"<context>To start the season, the Lions traveled south to Tampa, Florida to take on the Tampa Bay Buccaneers. The Lions scored first in the first quarter with a 23-yard field goal by Jason Hanson. The Buccaneers tied it up with a 38-yard field goal by Connor Barth, then took the lead when Aqib Talib intercepted a pass from Matthew Stafford and ran it in 28 yards. The Lions responded with a 28-yard field goal. In the second quarter, Detroit took the lead with a 36-yard touchdown catch by Calvin Johnson, and later added more points when Tony Scheffler caught an 11-yard TD pass. Tampa Bay responded with a 31-yard field goal just before halftime. The second half was relatively quiet, with each team only scoring one touchdown. First, Detroit's Calvin Johnson caught a 1-yard pass in the third quarter. The game's final points came when Mike Williams of Tampa Bay caught a 5-yard pass.  The Lions won their regular season opener for the first time since 2007</document>\", role=<Role.USER: 'user'>),\n",
       " Message(id=None, content=\"How long was the Lion's longest field goal?\", role=<Role.USER: 'user'>),\n",
       " Message(id=None, content='28-yard', role=<Role.ASSISTANT: 'assistant'>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.conversation(0).messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Answer the following question with a short span.<|endoftext|>Only use the information from the user provided context to answer the question.<|endoftext|><context>To start the season, the Lions traveled south to Tampa, Florida to take on the Tampa Bay Buccaneers. The Lions scored first in the first quarter with a 23-yard field goal by Jason Hanson. The Buccaneers tied it up with a 38-yard field goal by Connor Barth, then took the lead when Aqib Talib intercepted a pass from Matthew Stafford and ran it in 28 yards. The Lions responded with a 28-yard field goal. In the second quarter, Detroit took the lead with a 36-yard touchdown catch by Calvin Johnson, and later added more points when Tony Scheffler caught an 11-yard TD pass. Tampa Bay responded with a 31-yard field goal just before halftime. The second half was relatively quiet, with each team only scoring one touchdown. First, Detroit's Calvin Johnson caught a 1-yard pass in the third quarter. The game's final points came when Mike Williams of Tampa Bay caught a 5-yard pass.  The Lions won their regular season opener for the first time since 2007</document><|endoftext|>How long was the Lion's longest field goal?<|endoftext|>28-yard<|endoftext|>\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.prompt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [33706, 262, 1708, 1808, 351, 257, 1790, 11506, 13, 50256, 10049, 779, 262, 1321, 422, 262, 2836, 2810, 4732, 284, 3280, 262, 1808, 13, 50256, 27, 22866, 29, 2514, 923, 262, 1622, 11, 262, 14536, 14113, 5366, 284, 15528, 11, 4744, 284, 1011, 319, 262, 15528, 4696, 37006, 13, 383, 14536, 7781, 717, 287, 262, 717, 3860, 351, 257, 2242, 12, 9413, 2214, 3061, 416, 8982, 35692, 13, 383, 37006, 8165, 340, 510, 351, 257, 4353, 12, 9413, 2214, 3061, 416, 27599, 44414, 11, 788, 1718, 262, 1085, 618, 317, 80, 571, 7193, 571, 29842, 257, 1208, 422, 9308, 30596, 290, 4966, 340, 287, 2579, 5695, 13, 383, 14536, 7082, 351, 257, 2579, 12, 9413, 2214, 3061, 13, 554, 262, 1218, 3860, 11, 8488, 1718, 262, 1085, 351, 257, 4570, 12, 9413, 10242, 4929, 416, 25017, 5030, 11, 290, 1568, 2087, 517, 2173, 618, 8832, 10011, 487, 1754, 4978, 281, 1367, 12, 9413, 13320, 1208, 13, 15528, 4696, 7082, 351, 257, 3261, 12, 9413, 2214, 3061, 655, 878, 35185, 13, 383, 1218, 2063, 373, 5365, 5897, 11, 351, 1123, 1074, 691, 9689, 530, 10242, 13, 3274, 11, 8488, 338, 25017, 5030, 4978, 257, 352, 12, 9413, 1208, 287, 262, 2368, 3860, 13, 383, 983, 338, 2457, 2173, 1625, 618, 4995, 6484, 286, 15528, 4696, 4978, 257, 642, 12, 9413, 1208, 13, 220, 383, 14536, 1839, 511, 3218, 1622, 21996, 329, 262, 717, 640, 1201, 4343, 3556, 22897, 29, 50256, 2437, 890, 373, 262, 15218, 338, 14069, 2214, 3061, 30, 50256, 2078, 12, 9413, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
