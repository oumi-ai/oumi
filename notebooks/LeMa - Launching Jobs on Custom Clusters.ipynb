{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this tutorial, we'll cover how you can launch LeMa jobs on custom clusters that are not supported out of the box.\n",
    "\n",
    "Specifically, this tutorial is geared towards individuals who have access to a compute cluster that's not hosted on a common cloud provider (e.g. University compute clusters).\n",
    "\n",
    "We'll cover the following topics:\n",
    "1. Prerequisites\n",
    "1. The LeMa Launcher Hierarchy\n",
    "1. Creating a CustomClient Class\n",
    "1. Creating a CustomCluster Class\n",
    "1. Creating a CustomCloud Class\n",
    "1. Registering Your CustomCloud\n",
    "1. Running a Job on Your Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeMa Installation\n",
    "First, let's install LeMa. You can find detailed instructions [here](https://github.com/openlema/lema/blob/main/README.md), but it should be as simple as:\n",
    "\n",
    "```bash\n",
    "pip install -e \".[dev,train]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The LeMa Launcher Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preface\n",
    "Before diving into this tutorial, lets discuss the hierarchy of the LeMa Launcher. At this point, it's worth reading through our tutorial on [Running Jobs Remotely](https://github.com/openlema/lema/blob/main/notebooks/LeMa%20-%20Running%20Jobs%20Remotely.ipynb) to better understand the end-to-end flow of the launcher. Already read it? Great!\n",
    "\n",
    "### Overview\n",
    "At a high level, the LeMa Launcher is composed of 3 tiers of objects: `Clouds`, `Clusters`, and `Clients`. The Launcher holds an instance of each unique `Cloud`. These `Clouds`, in turn, are responsible for creating compute `Clusters`. And `Clusters` coordinate running jobs. All communication with remote APIs happens via the `Client`.\n",
    "\n",
    "#### Clouds\n",
    "A Cloud class must implement the [`BaseCloud`](https://github.com/openlema/lema/blob/main/src/lema/core/types/base_cloud.py) abstract class. The Launcher will only create one instance of each Cloud, so it's important that a single Cloud object is capable of turning up and down multiple clusters.\n",
    "\n",
    "You can find several implementations of Clouds [here](https://github.com/openlema/lema/tree/main/src/lema/launcher/clouds).\n",
    "\n",
    "#### Clusters\n",
    "A Cluster class must implement the [`BaseCluster`](https://github.com/openlema/lema/blob/main/src/lema/core/types/base_cluster.py) abstract class. A cluster represents a single instance of hardware. For a custom clusters (such as having a single super computer), it may be the case that you only need 1 cluster to represent your hardware setup.\n",
    "\n",
    "You can find several implementations of Clusters [here](https://github.com/openlema/lema/tree/main/src/lema/launcher/clusters).\n",
    "\n",
    "#### Clients\n",
    "Clients are a completely optional but highly encouraged class. Clients should encapsulate all logic that calls remote APIs related to your cloud. While this logic could be encapsulated with your Cluster and Cloud classes, having a dedicated class for this purpose greatly simplifies your Cloud and Cluster logic.\n",
    "\n",
    "You can find several implementations of Clients [here](https://github.com/openlema/lema/tree/main/src/lema/launcher/clients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CustomClient Class\n",
    "Let's get started by creating a client for our new cloud, `Foobar`. Let's create a simple client that randomly sets the state of the job on submission. It also supports canceling jobs, and turning down clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 16:38:56,079] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to mps (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 16:38:56.155000 8639990784 torch/distributed/elastic/multiprocessing/redirects.py:28] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "\n",
    "from lema.core.types.base_cluster import JobStatus\n",
    "from lema.core.types.configs import JobConfig\n",
    "\n",
    "\n",
    "class _JobState(Enum):\n",
    "    \"\"\"An enumeration of the possible states of a job.\"\"\"\n",
    "\n",
    "    QUEUED = \"QUEUED\"\n",
    "    RUNNING = \"RUNNING\"\n",
    "    COMPLETED = \"COMPLETED\"\n",
    "    FAILED = \"FAILED\"\n",
    "    CANCELED = \"CANCELED\"\n",
    "\n",
    "\n",
    "class CustomClient:\n",
    "    \"\"\"A client for running jobs locally in a subprocess.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes a new instance of the CustomClient class.\"\"\"\n",
    "        self._jobs = []\n",
    "\n",
    "    def submit_job(self, job: JobConfig) -> JobStatus:\n",
    "        \"\"\"Pretends to run the specified job on this cluster.\"\"\"\n",
    "        job_id = str(len(self._jobs))\n",
    "        name = job.name if job.name else job_id\n",
    "        # Pick a random status\n",
    "        status = random.choice([state for state in _JobState])\n",
    "        job_status = JobStatus(\n",
    "            name=name,\n",
    "            id=job_id,\n",
    "            status=status.value,\n",
    "            cluster=\"\",\n",
    "            metadata=\"\",\n",
    "            done=False,\n",
    "        )\n",
    "        self._jobs.append(job_status)\n",
    "        return job_status\n",
    "\n",
    "    def list_jobs(self) -> List[JobStatus]:\n",
    "        \"\"\"Returns a list of job statuses.\"\"\"\n",
    "        return self._jobs\n",
    "\n",
    "    def get_job(self, job_id: str) -> Optional[JobStatus]:\n",
    "        \"\"\"Gets the specified job's status.\n",
    "\n",
    "        Args:\n",
    "            job_id: The ID of the job to get.\n",
    "\n",
    "        Returns:\n",
    "            The job status if found, None otherwise.\n",
    "        \"\"\"\n",
    "        job_list = self.list_jobs()\n",
    "        for job in job_list:\n",
    "            if job.id == job_id:\n",
    "                return job\n",
    "        return None\n",
    "\n",
    "    def cancel(self, job_id) -> Optional[JobStatus]:\n",
    "        \"\"\"Cancels the specified job.\n",
    "\n",
    "        Args:\n",
    "            job_id: The ID of the job to cancel.\n",
    "\n",
    "        Returns:\n",
    "            The job status if found, None otherwise.\n",
    "        \"\"\"\n",
    "        int_id = int(job_id)\n",
    "        if int_id > len(self._jobs):\n",
    "            return None\n",
    "        job_status = self._jobs[int_id]\n",
    "        job_status.status = _JobState.CANCELED.value\n",
    "        return job_status\n",
    "\n",
    "    def turndown_cluster(self, cluster_name: str):\n",
    "        \"\"\"Turns down the cluster.\"\"\"\n",
    "        print(f\"Turning down cluster {cluster_name}...\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CustomCluster Class\n",
    "Now that we have a client that talk's to our API, we can use the Client to build a Cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional\n",
    "\n",
    "from lema.core.types.base_cluster import BaseCluster\n",
    "\n",
    "\n",
    "class CustomCluster(BaseCluster):\n",
    "    \"\"\"A custom cluster implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, client: CustomClient) -> None:\n",
    "        \"\"\"Initializes a new instance of the CustomCluster class.\"\"\"\n",
    "        self._name = name\n",
    "        self._client = client\n",
    "\n",
    "    def __eq__(self, other: Any) -> bool:\n",
    "        \"\"\"Checks if two LocalClusters are equal.\"\"\"\n",
    "        if not isinstance(other, CustomCluster):\n",
    "            return False\n",
    "        return self.name() == other.name()\n",
    "\n",
    "    def name(self) -> str:\n",
    "        \"\"\"Gets the name of the cluster.\"\"\"\n",
    "        return self._name\n",
    "\n",
    "    def get_job(self, job_id: str) -> Optional[JobStatus]:\n",
    "        \"\"\"Gets the jobs on this cluster if it exists, else returns None.\"\"\"\n",
    "        for job in self.get_jobs():\n",
    "            if job.id == job_id:\n",
    "                return job\n",
    "        return None\n",
    "\n",
    "    def get_jobs(self) -> List[JobStatus]:\n",
    "        \"\"\"Lists the jobs on this cluster.\"\"\"\n",
    "        jobs = self._client.list_jobs()\n",
    "        for job in jobs:\n",
    "            job.cluster = self._name\n",
    "        return jobs\n",
    "\n",
    "    def stop_job(self, job_id: str) -> JobStatus:\n",
    "        \"\"\"Stops the specified job on this cluster.\"\"\"\n",
    "        self._client.cancel(job_id)\n",
    "        job = self.get_job(job_id)\n",
    "        if job is None:\n",
    "            raise RuntimeError(f\"Job {job_id} not found.\")\n",
    "        return job\n",
    "\n",
    "    def run_job(self, job: JobConfig) -> JobStatus:\n",
    "        \"\"\"Runs the specified job on this cluster.\n",
    "\n",
    "        Args:\n",
    "            job: The job to run.\n",
    "\n",
    "        Returns:\n",
    "            The job status.\n",
    "        \"\"\"\n",
    "        job_status = self._client.submit_job(job)\n",
    "        job_status.cluster = self._name\n",
    "        return job_status\n",
    "\n",
    "    def down(self) -> None:\n",
    "        \"\"\"Cancel all jobs and turn down the cluster.\"\"\"\n",
    "        for job in self.get_jobs():\n",
    "            self.stop_job(job.id)\n",
    "        self._client.turndown_cluster(self._name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CustomCloud Class\n",
    "Let's create a CustomCloud to manage our clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lema.core.types.base_cloud import BaseCloud\n",
    "\n",
    "\n",
    "class CustomCloud(BaseCloud):\n",
    "    \"\"\"A resource pool for managing Local jobs.\"\"\"\n",
    "\n",
    "    # The default cluster name. Used when no cluster name is provided.\n",
    "    _DEFAULT_CLUSTER = \"custom\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes a new instance of the LocalCloud class.\"\"\"\n",
    "        # A mapping from cluster names to Local Cluster instances.\n",
    "        self._clusters = {}\n",
    "\n",
    "    def _get_or_create_cluster(self, name: str) -> CustomCluster:\n",
    "        \"\"\"Gets the cluster with the specified name, or creates one if it doesn't exist.\n",
    "\n",
    "        Args:\n",
    "            name: The name of the cluster.\n",
    "\n",
    "        Returns:\n",
    "            LocalCluster: The cluster instance.\n",
    "        \"\"\"\n",
    "        if name not in self._clusters:\n",
    "            self._clusters[name] = CustomCluster(name, CustomClient())\n",
    "        return self._clusters[name]\n",
    "\n",
    "    def up_cluster(self, job: JobConfig, name: Optional[str]) -> JobStatus:\n",
    "        \"\"\"Creates a cluster and starts the provided Job.\"\"\"\n",
    "        # The default cluster.\n",
    "        cluster_name = name or self._DEFAULT_CLUSTER\n",
    "        cluster = self._get_or_create_cluster(cluster_name)\n",
    "        job_status = cluster.run_job(job)\n",
    "        if not job_status:\n",
    "            raise RuntimeError(\"Failed to start job.\")\n",
    "        return job_status\n",
    "\n",
    "    def get_cluster(self, name) -> Optional[BaseCluster]:\n",
    "        \"\"\"Gets the cluster with the specified name, or None if not found.\"\"\"\n",
    "        clusters = self.list_clusters()\n",
    "        for cluster in clusters:\n",
    "            if cluster.name() == name:\n",
    "                return cluster\n",
    "        return None\n",
    "\n",
    "    def list_clusters(self) -> List[BaseCluster]:\n",
    "        \"\"\"Lists the active clusters on this cloud.\"\"\"\n",
    "        return list(self._clusters.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all that's left to do is register your CustomCloud!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering Your CustomCloud\n",
    "By implementing the BaseCloud class, you are now ready to register your cloud with LeMa. First, let's take a look at the clouds that are already registered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['local', 'polaris', 'runpod', 'gcp', 'lambda']\n"
     ]
    }
   ],
   "source": [
    "import lema.launcher as launcher\n",
    "\n",
    "print(launcher.which_clouds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can register your cloud by implementing a builder method. This method must take no arguments and must return a new instance of your CustomCloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lema.core.registry import register_cloud_builder\n",
    "\n",
    "\n",
    "@register_cloud_builder(\"custom\")\n",
    "def Local_cloud_builder() -> CustomCloud:\n",
    "    \"\"\"Builds a LocalCloud instance.\"\"\"\n",
    "    return CustomCloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take another look at our registered clouds now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['local', 'polaris', 'runpod', 'gcp', 'lambda', 'custom']\n"
     ]
    }
   ],
   "source": [
    "print(launcher.which_clouds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our CustomCloud is there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a Job on Your Cloud\n",
    "\n",
    "Let's take our new Cloud for a spin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus(name='test', id='0', status='QUEUED', cluster='first_cluster', metadata='', done=False)\n",
      "JobStatus(name='test', id='0', status='CANCELED', cluster='second_cluster', metadata='', done=False)\n",
      "Canceling the first job...\n",
      "JobStatus(name='test', id='0', status='CANCELED', cluster='first_cluster', metadata='', done=False)\n"
     ]
    }
   ],
   "source": [
    "job = launcher.JobConfig(name=\"test\")\n",
    "job.resources.cloud = \"custom\"\n",
    "\n",
    "first_cluster, job_status = launcher.up(job, \"first_cluster\")\n",
    "print(job_status)\n",
    "second_cluster, second_job_status = launcher.up(job, \"second_cluster\")\n",
    "print(second_job_status)\n",
    "\n",
    "print(\"Canceling the first job...\")\n",
    "print(launcher.stop(job_status.id, job.resources.cloud, job_status.cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's turn down our clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning down cluster first_cluster...\n",
      "Cluster first_cluster is down. Listing jobs...\n",
      "[JobStatus(name='test', id='0', status='CANCELED', cluster='first_cluster', metadata='', done=False)]\n",
      "Turning down cluster second_cluster...\n",
      "Cluster second_cluster is down. Listing jobs...\n",
      "[JobStatus(name='test', id='0', status='CANCELED', cluster='second_cluster', metadata='', done=False)]\n"
     ]
    }
   ],
   "source": [
    "for cluster in launcher.get_cloud(\"custom\").list_clusters():\n",
    "    cluster.down()\n",
    "    print(f\"Cluster {cluster.name()} is down. Listing jobs...\")\n",
    "    print(cluster.get_jobs())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lema",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
