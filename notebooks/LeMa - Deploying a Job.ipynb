{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial we'll take a working [JobConfig](https://github.com/openlema/lema/tree/main/configs/lema/jobs) and deploy it remotely on a cluster of your choice.\n",
    "\n",
    "This guide dovetails nicely with our [Finetuning Tutorial](https://github.com/openlema/lema/blob/main/notebooks/LeMa%20-%20Finetuning%20Tutorial.ipynb) where you create your own TrainingConfig and run it locally. Give it a try if you haven't already!\n",
    "\n",
    "We'll cover the following topics:\n",
    "1. Prerequisites\n",
    "1. Choosing a Cloud\n",
    "1. Preparing Your JobConfig\n",
    "1. Launching Your Job\n",
    "1. \\[Advanced\\] Deploying a Training Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeMa Installation\n",
    "First, let's install lema. You can find detailed instructions [here](https://github.com/openlema/lema/blob/main/README.md), but it should be as simple as:\n",
    "\n",
    "```bash\n",
    "pip install -e \".[dev,train]\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our working directory\n",
    "For our experiments, we'll use the following folder to save our configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tutorial_dir = \"deploy_training_tutorial\"\n",
    "\n",
    "Path(tutorial_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the LeMa Launcher to run remote training. To use the launcher, you need to specify which cloud you'd like to run training on.\n",
    "We'll list the clouds below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['local', 'polaris', 'runpod', 'gcp', 'lambda']\n"
     ]
    }
   ],
   "source": [
    "import oumi.launcher as launcher\n",
    "\n",
    "# Print all available clouds\n",
    "print(launcher.which_clouds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Cloud\n",
    "If you don't have any clouds set up yet, feel free to use the `local` cloud. This will simply execute your job on your current device as if it's a remote cluster. Hardware requirements are ignored for the `local` cloud.\n",
    "\n",
    "#### Other Providers\n",
    "Note that to use a cloud you must already have an account registered with that cloud provider.\n",
    "\n",
    "For example, GCP, RunPod, and Lambda require accounts with billing enabled. Polaris requires an account set up with [ALCF](https://www.alcf.anl.gov/polaris).\n",
    "\n",
    "Once you've picked a cloud, move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Your JobConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by creating your JobConfig. We'll create a config specifically for this tutorial, but there are many other pre-made configs readily available in our [jobs directory](https://github.com/openlema/lema/tree/main/configs/lema/jobs).\n",
    "\n",
    "In the config below, feel free to change `cloud: local` to the cloud you chose in the previous step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy_training_tutorial/job.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $tutorial_dir/job.yaml\n",
    "\n",
    "name: job-tutorial\n",
    "resources:\n",
    "  cloud: local\n",
    "  # Accelerators is ignored for the local cloud.\n",
    "  accelerators: A100\n",
    "\n",
    "# Upload working directory to remote.\n",
    "# If on the local cloud, we CD into the working directory before running the job.\n",
    "working_dir: .\n",
    "\n",
    "envs:\n",
    "  TEST_ENV_VARIABLE: '\"Hello, World!\"'\n",
    "\n",
    "# `setup` will always be executed before `run`.\n",
    "# No setup is required for this job.\n",
    "#setup: |\n",
    "#  echo \"Running setup...\"\n",
    "\n",
    "run: |\n",
    "  set -e  # Exit if any command failed.\n",
    "\n",
    "  echo \"$TEST_ENV_VARIABLE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching Your Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load your JobConfig:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read our JobConfig from the YAML file.\n",
    "job = launcher.JobConfig.from_yaml(str(Path(tutorial_dir) / \"job.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any point you can easily change the cloud where your job will run by modifying the job's `resources.cloud` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set the cloud to use.\n",
    "job.resources.cloud = \"local\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a job config, kicking off your job is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-09 14:17:37,509][lema][rank0][pid:84768][MainThread][WARNING]][local_cluster.py:32] Accelerators are unused for local jobs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: JobStatus(name='job-tutorial', id='0', status='QUEUED', cluster='local', metadata='')\n"
     ]
    }
   ],
   "source": [
    "# You can optionally specify a cluster name here. If not specified, a random name will\n",
    "# be generated. This is also useful for launching multiple jobs on the same cluster.\n",
    "cluster_name = None\n",
    "\n",
    "# Launch the job!\n",
    "cluster, job_status = launcher.up(job, cluster_name)\n",
    "print(f\"Job status: {job_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry if you see any errors from `launcher.up`--you may need to configure permissions to run a job on your specified cloud. The error message should provide you with the proper command to run to authenticate (for GCP this is often `gcloud auth application-default login`).\n",
    "\n",
    "We can quickly check on the status of our job using the `cluster` returned in the previous command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus(name='job-tutorial', id='0', status='COMPLETED', cluster='local', metadata='Job finished at 2024-08-09T14:17:42.537384')\n"
     ]
    }
   ],
   "source": [
    "print(cluster.get_job(job_status.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're done with the cluster, let's turn it down to stop billing for non-local clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\[Advanced\\] Deploying a Training Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our [Finetuning Tutorial](https://github.com/openlema/lema/blob/main/notebooks/LeMa%20-%20Finetuning%20Tutorial.ipynb), we created and saved a TrainingConfig. We then invoked training by running\n",
    "```shell\n",
    "oumi-train -c \"$tutorial_dir/train.yaml\"\n",
    "```\n",
    "\n",
    "You can also run that command as a job! Simply update the \"run\" section of the JobConfig with your desired command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_your_train_config = Path(tutorial_dir) / \"train.yaml\"  # Make sure this exists!\n",
    "\n",
    "# Set the `run` command to run your training script.\n",
    "job.run = f'oumi-train -c \"{path_to_your_train_config}\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now your job will run your training config when executed!\n",
    "\n",
    "For a more in-depth overview of the fields in JobConfig, please see our [Running Jobs Remotely tutorial](https://github.com/openlema/lema/blob/main/notebooks/LeMa%20-%20Running%20Jobs%20Remotely.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lema",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
