name: "GPU Tests"

on:
  schedule:
    - cron: '0 */8 * * *' # Every 8 hours
  workflow_dispatch:
  pull_request:
    paths-ignore:
      - 'docs/**'
      - 'notebooks/**'
      - 'configs/**'
      - 'scripts/**'
      - 'README.md'

env:
  NCCL_DEBUG: INFO

jobs:
  gpu-tests:
    permissions:
      contents: 'read'
    runs-on: linux-gpu-runner

    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        # Checkout using commit hash to make "no-commit-to-branch" test pass.
        ref: ${{ github.sha }}

    - name: Install uv
      uses: astral-sh/setup-uv@v2
      with:
        enable-cache: true
        cache-dependency-glob: "pyproject.toml"

    - name: "Set up Python"
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install Dependencies
      run: |
        # Install in system python as we're in a sandbox env
        # Install in verbose mode to see what's going on
        # BUILD_TRITON=0 prevents Triton compilation issues on T4 GPUs
        BUILD_TRITON=0 uv pip install -e '.[ci_gpu]' hf_transfer --system
      env:
        # Disable Triton flash attention at runtime for T4 compatibility
        VLLM_USE_TRITON_FLASH_ATTN: "False"

    - name: Install VLLM for CPU (VLLM tests are CPU-only)
      run: |
        # Uninstall GPU VLLM and install CPU version for integration tests
        # All VLLM tests have been converted to CPU-only to avoid CUDA compatibility issues
        uv pip uninstall vllm --system
        VLLM_TARGET_DEVICE=cpu uv pip install vllm==0.10.1.1 --no-cache --system

    - name: Download Test Data
      run: |
        ./tests/scripts/predownload_for_github_gpu_tests.sh

    - name: Run GPU tests
      run: |
        nvidia-smi

        cd ./tests/integration/
        pytest -s -m "not e2e and not e2e_eternal and not multi_gpu" --durations=50 --timeout=300
      env:
        # Force VLLM to use CPU backend despite GPU availability
        VLLM_TARGET_DEVICE: cpu
