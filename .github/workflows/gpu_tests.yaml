name: "GPU Tests"

on:
  schedule:
    - cron: "0 */8 * * *" # Every 8 hours
  workflow_dispatch:
  merge_group:
  pull_request:
    paths:
      - "tests/integration/**"
      - "pyproject.toml"

env:
  SETUPTOOLS_SCM_PRETEND_VERSION_FOR_OUMI: v0.0.1
  NCCL_DEBUG: INFO
  DO_NOT_TRACK: "1"

jobs:
  gpu-tests:
    permissions:
      contents: "read"
    runs-on: linux-gpu-runner
    strategy:
      fail-fast: false
      matrix:
        transformers-version: ["v4", "v5"]
        include:
          - transformers-version: "v4"
            transformers-spec: "transformers>=4.57,<5.0"
            # v4 uses huggingface_hub<1.0, so don't force >=1.0
            hf-hub-spec: ""
            uv-override: ""
          - transformers-version: "v5"
            transformers-spec: "transformers>=5.0,<5.2"
            # v5 uses huggingface_hub>=1.0
            hf-hub-spec: "huggingface_hub>=1.0"
            # Override vLLM's transformers<5 constraint
            uv-override: "--override /tmp/overrides.txt"
    name: gpu-tests (transformers ${{ matrix.transformers-version }})

    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          # Checkout using commit hash to make "no-commit-to-branch" test pass.
          ref: ${{ github.sha }}
          # Need full history for setuptools-scm to detect version
          fetch-depth: 0

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4 wget software-properties-common

      - name: Install CUDA Toolkit
        run: |
          # Install CUDA toolkit from NVIDIA (Ubuntu 24.04)
          wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
          sudo dpkg -i cuda-keyring_1.1-1_all.deb
          sudo apt-get update
          sudo apt-get install -y cuda-toolkit-12-6

          # Set CUDA_HOME
          echo "CUDA_HOME=/usr/local/cuda-12.6" >> $GITHUB_ENV
          echo "PATH=/usr/local/cuda-12.6/bin:$PATH" >> $GITHUB_ENV
          echo "LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64:$LD_LIBRARY_PATH" >> $GITHUB_ENV

      - name: "Set up Python"
        uses: actions/setup-python@v6
        with:
          python-version: "3.11"

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"

      - name: Create override file for transformers v5
        if: matrix.transformers-version == 'v5'
        run: |
          # Override vLLM's transformers<5 constraint to allow transformers v5
          echo "transformers>=5.0" > /tmp/overrides.txt

      - name: Install Dependencies
        env:
          UV_OVERRIDE: ${{ matrix.uv-override }}
          HF_HUB_SPEC: ${{ matrix.hf-hub-spec }}
        run: |
          # Install in system python as we're in a sandbox env
          # Install in verbose mode to see what's going on
          # Note: For v4, we don't force huggingface_hub>=1.0 since transformers v4 requires <1.0
          # For v5, we use --override to bypass vLLM's transformers<5 constraint
          if [ -n "$HF_HUB_SPEC" ]; then
            uv pip install --system $UV_OVERRIDE -e '.[ci_gpu]' hf_transfer "$HF_HUB_SPEC"
          else
            uv pip install --system $UV_OVERRIDE -e '.[ci_gpu]' hf_transfer
          fi

      - name: Install specific transformers version
        env:
          TRANSFORMERS_SPEC: ${{ matrix.transformers-spec }}
        run: |
          # Install the specific transformers version for this matrix job
          uv pip install --system "$TRANSFORMERS_SPEC"
          python -c "import transformers; print(f'Transformers version: {transformers.__version__}')"

      - name: Cache HuggingFace Models
        uses: actions/cache@v5
        with:
          path: |
            ~/.cache/huggingface
          key: hf-models-${{ runner.os }}-${{ hashFiles('tests/scripts/predownload_for_github_gpu_tests.sh') }}
          restore-keys: |
            hf-models-${{ runner.os }}-

      - name: Download Test Data
        run: |
          ./tests/scripts/predownload_for_github_gpu_tests.sh

      - name: Verify CUDA environment
        run: |
          echo "=== CUDA Environment Check ==="
          nvidia-smi
          echo "CUDA_HOME: $CUDA_HOME"
          nvcc --version

      - name: Run GPU tests
        run: |
          cd ./tests/integration/
          pytest -s -m "not e2e and not e2e_eternal and not multi_gpu" --durations=50 --timeout=300
