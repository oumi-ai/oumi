{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "LeMa - Train From CLI Example",
            "type": "debugpy",
            "request": "launch",
            "module": "lema.train",
            "args": [
                "data.train.datasets.0.dataset_name=yahma/alpaca-cleaned",
                "data.train.datasets.0.preprocessing_function_name=alpaca",
                "data.train.datasets.0.target_col=prompt",
                "model.model_name=openai-community/gpt2",
                "model.trust_remote_code=true",
                "training.trainer_type=TRL_SFT",
                "training.max_steps=3",
                "training.logging_steps=3",
                "training.enable_wandb=false",
                "training.enable_tensorboard=false",
                "training.output_dir=tmp"
            ],
            "justMyCode": true
        },
        {
            "name": "LeMa - Train From Config Example",
            "type": "debugpy",
            "request": "launch",
            "module": "lema.train",
            "args": [
                "-c",
                "configs/lema/phi3.lora.yaml"
            ],
            "justMyCode": true
        },
        {
            "name": "LeMa - Pretrain From Config Example",
            "type": "debugpy",
            "request": "launch",
            "module": "lema.train",
            "args": [
                "-c",
                "configs/lema/gpt2.pt.mac.yaml"
            ],
            "justMyCode": true
        },
        {
            "name": "Lema Distributed",
            "type": "debugpy",
            "module": "torch.distributed.run",
            "request": "launch",
            "console": "integratedTerminal",
            "args": [
                "--standalone",
                "--nproc_per_node",
                "4",
                "-m",
                "lema.train",
                "-c",
                "configs/lema/gpt2.pt.yaml"
            ]
        },
        {
            "name": "LeMa - Inference From CLI Example",
            "type": "debugpy",
            "request": "launch",
            "module": "lema.infer",
            "args": [
                "--interactive",
                "model.model_name=openai-community/gpt2",
                "model.trust_remote_code=true",
                "generation.max_new_tokens=16"
            ],
            "justMyCode": true
        },
        {
            "name": "LeMa - Evaluate with custom LeMa framework from config example",
            "type": "debugpy",
            "request": "launch",
            "module": "lema.evaluate",
            "args": [
                "-c",
                "configs/lema/phi3.eval.lema.mac.yaml"
            ],
            "justMyCode": true
        },
        {
            "name": "LeMa - Evaluate with the LM Harness framework from config example",
            "type": "debugpy",
            "request": "launch",
            "module": "lema.evaluate",
            "args": [
                "-c",
                "configs/lema/phi3.eval.lm_harness.yaml"
            ],
            "justMyCode": true
        },
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        }
    ]
}
