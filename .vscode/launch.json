{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Oumi - Train From CLI Example",
            "type": "debugpy",
            "request": "launch",
            "module": "oumi.train",
            "args": [
                "data.train.datasets=[{'dataset_name':'yahma/alpaca-cleaned', 'preprocessing_function_name': 'alpaca'}]",
                "data.train.target_col=prompt",
                "model.model_name=openai-community/gpt2",
                "model.trust_remote_code=true",
                "training.trainer_type=TRL_SFT",
                "training.max_steps=3",
                "training.logging_steps=3",
                "training.enable_wandb=false",
                "training.enable_tensorboard=false",
                "training.output_dir=tmp"
            ],
            "justMyCode": true
        },
        {
            "name": "Oumi - Train From Config Example",
            "type": "debugpy",
            "request": "launch",
            "module": "oumi.train",
            "args": [
                "-c",
                "configs/oumi/phi3.lora.yaml"
            ],
            "justMyCode": true
        },
        {
            "name": "Oumi - Judge",
            "type": "debugpy",
            "request": "launch",
            "module": "oumi.judge",
            "args": [
                "--config-name",
                "oumi/v1_xml_local",
                "--dataset-name",
                "yahma/alpaca-cleaned"
            ],
            "justMyCode": true
        },
        {
            "name": "Oumi - Pretrain From Config Example",
            "type": "debugpy",
            "request": "launch",
            "module": "oumi.train",
            "args": [
                "-c",
                "configs/oumi/gpt2.pt.mac.yaml"
            ],
            "justMyCode": true
        },
        {
            "name": "Oumi Distributed",
            "type": "debugpy",
            "module": "torch.distributed.run",
            "request": "launch",
            "console": "integratedTerminal",
            "args": [
                "--standalone",
                "--nproc_per_node",
                "4",
                "-m",
                "oumi.train",
                "-c",
                "configs/oumi/gpt2.pt.yaml"
            ]
        },
        {
            "name": "Oumi Distributed - Accelerate",
            "type": "debugpy",
            "module": "accelerate.commands.launch",
            "request": "launch",
            "console": "integratedTerminal",
            "args": [
                "--num_machines",
                "1",
                "--machine_rank",
                "0",
                "--num_processes",
                "8",
                "--use_fsdp",
                "--config_file",
                "configs/accelerate/llama8b.fsdp.yaml",
                "-m",
                "oumi.train",
                "-c",
                "configs/oumi/llama8b.sft.yaml",
                "training.max_steps=2",
                "training.save_steps=1",
                "training.save_final_model=true",
                "training.enable_wandb=false",
                "training.enable_tensorboard=false"
            ]
        },
        {
            "name": "Oumi - Inference From CLI Example",
            "type": "debugpy",
            "request": "launch",
            "module": "oumi.infer",
            "args": [
                "--interactive",
                "model.model_name=openai-community/gpt2",
                "model.trust_remote_code=true",
                "generation.max_new_tokens=16"
            ],
            "justMyCode": true
        },
        {
            "name": "Oumi - Evaluate with custom Oumi framework from config example",
            "type": "debugpy",
            "request": "launch",
            "module": "oumi.evaluate",
            "args": [
                "-c",
                "configs/oumi/phi3.eval.oumi.mac.yaml"
            ],
            "justMyCode": true
        },
        {
            "name": "Oumi - Evaluate with the LM Harness framework from config example",
            "type": "debugpy",
            "request": "launch",
            "module": "oumi.evaluate",
            "args": [
                "-c",
                "configs/oumi/phi3.eval.lm_harness.yaml"
            ],
            "justMyCode": true
        },
        {
            "name": "Python Debugger: Minimal Multimodal Training",
            "type": "debugpy",
            "request": "launch",
            "program": "scripts/benchmarks/minimal_multimodal_training.py",
            "args": [
                "--model-name",
                "llava-hf/llava-1.5-7b-hf",
                "--dataset-name",
                "coco_captions"
            ],
            "justMyCode": true
        },
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        }
    ]
}
