# Inference Engines in Oumi

## Introduction

- Overview of inference engines in Oumi

## Types of Inference Engines

- PyTorch inference engine
- ONNX Runtime
- TensorRT

## Selecting an Inference Engine

- Factors to consider when choosing an engine

## Setting Up Inference Engines

- Installation and configuration

## Using Inference Engines

- Basic usage examples
- Advanced features

## Performance Comparison

- Benchmarking different inference engines

## Best Practices

- Tips for optimal use of inference engines

## Troubleshooting

- Common issues and their solutions
