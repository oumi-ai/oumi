{
  "generated_at": "2025-08-29T22:22:54.778Z",
  "version": "1.0",
  "total_configs": 108,
  "configs": [
    {
      "id": "projects_coalm_8b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/projects/coalm/8b_infer.yaml",
      "relative_path": "projects/coalm/8b_infer.yaml",
      "display_name": "coalm - 8b",
      "model_name": "uiuc-convai/CoALM-8B",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "coalm",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_deepseek_r1_inference_distill_llama_8b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/deepseek_r1/inference/distill_llama_8b_infer.yaml",
      "relative_path": "recipes/deepseek_r1/inference/distill_llama_8b_infer.yaml",
      "display_name": "deepseek_r1 - distill_llama_8b",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "deepseek_r1",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_deepseek_r1_inference_distill_qwen_32b_gguf_macos_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/deepseek_r1/inference/distill_qwen_32b_gguf_macos_infer.yaml",
      "relative_path": "recipes/deepseek_r1/inference/distill_qwen_32b_gguf_macos_infer.yaml",
      "display_name": "deepseek_r1 - distill_qwen_32b_gguf_macos",
      "model_name": "unsloth/DeepSeek-R1-Distill-Qwen-32B-GGUF",
      "engine": "LLAMACPP",
      "context_length": 8192,
      "model_family": "deepseek_r1",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_falcon_h1_inference_7b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/falcon_h1/inference/7b_infer.yaml",
      "relative_path": "recipes/falcon_h1/inference/7b_infer.yaml",
      "display_name": "falcon_h1 - 7b",
      "model_name": "tiiuae/Falcon-H1-7B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "falcon_h1",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_gemma3_inference_3n_e4b_it_gguf_macos_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gemma3/inference/3n_e4b_it_gguf_macos_infer.yaml",
      "relative_path": "recipes/gemma3/inference/3n_e4b_it_gguf_macos_infer.yaml",
      "display_name": "gemma3 - 3n_e4b_it_gguf_macos",
      "model_name": "unsloth/gemma-3n-E4B-it-GGUF",
      "engine": "LLAMACPP",
      "context_length": 16384,
      "model_family": "gemma3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_glm4_inference_air_gguf_macos_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/glm4/inference/air_gguf_macos_infer.yaml",
      "relative_path": "recipes/glm4/inference/air_gguf_macos_infer.yaml",
      "display_name": "glm4 - air_gguf_macos",
      "model_name": "unsloth/GLM-4.5-Air-GGUF",
      "engine": "LLAMACPP",
      "context_length": 8192,
      "model_family": "glm4",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_llama3_1_inference_8b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_1/inference/8b_infer.yaml",
      "relative_path": "recipes/llama3_1/inference/8b_infer.yaml",
      "display_name": "llama3_1 - 8b",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "llama3_1",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_llama3_3_inference_nemotron_super_49b_gguf_macos_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_3/inference/nemotron_super_49b_gguf_macos_infer.yaml",
      "relative_path": "recipes/llama3_3/inference/nemotron_super_49b_gguf_macos_infer.yaml",
      "display_name": "llama3_3 - nemotron_super_49b_gguf_macos",
      "model_name": "bartowski/nvidia_Llama-3_3-Nemotron-Super-49B-v1-GGUF",
      "engine": "LLAMACPP",
      "context_length": 8192,
      "model_family": "llama3_3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_llama4_inference_maverick_instruct_together_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama4/inference/maverick_instruct_together_infer.yaml",
      "relative_path": "recipes/llama4/inference/maverick_instruct_together_infer.yaml",
      "display_name": "llama4 - maverick_instruct_together",
      "model_name": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "engine": "TOGETHER",
      "context_length": 2048,
      "model_family": "llama4",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_llama4_inference_scout_instruct_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama4/inference/scout_instruct_infer.yaml",
      "relative_path": "recipes/llama4/inference/scout_instruct_infer.yaml",
      "display_name": "llama4 - scout_instruct",
      "model_name": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "llama4",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_llama4_inference_scout_instruct_gguf_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama4/inference/scout_instruct_gguf_infer.yaml",
      "relative_path": "recipes/llama4/inference/scout_instruct_gguf_infer.yaml",
      "display_name": "llama4 - scout_instruct_gguf",
      "model_name": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "llama4",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_llama4_inference_scout_instruct_gguf_macos_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama4/inference/scout_instruct_gguf_macos_infer.yaml",
      "relative_path": "recipes/llama4/inference/scout_instruct_gguf_macos_infer.yaml",
      "display_name": "llama4 - scout_instruct_gguf_macos",
      "model_name": "unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF",
      "engine": "LLAMACPP",
      "context_length": 8192,
      "model_family": "llama4",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_llama4_inference_scout_instruct_together_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama4/inference/scout_instruct_together_infer.yaml",
      "relative_path": "recipes/llama4/inference/scout_instruct_together_infer.yaml",
      "display_name": "llama4 - scout_instruct_together",
      "model_name": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "engine": "TOGETHER",
      "context_length": 2048,
      "model_family": "llama4",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_llama4_inference_scout_instruct_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama4/inference/scout_instruct_vllm_infer.yaml",
      "relative_path": "recipes/llama4/inference/scout_instruct_vllm_infer.yaml",
      "display_name": "llama4 - scout_instruct_vllm",
      "model_name": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "engine": "VLLM",
      "context_length": 2048,
      "model_family": "llama4",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_1.7b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/1.7b_infer.yaml",
      "relative_path": "recipes/qwen3/inference/1.7b_infer.yaml",
      "display_name": "qwen3 - 1.7b",
      "model_name": "Qwen/Qwen3-1.7B",
      "engine": "NATIVE",
      "context_length": 32768,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_30b_a3b_instruct_gguf_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/30b_a3b_instruct_gguf_infer.yaml",
      "relative_path": "recipes/qwen3/inference/30b_a3b_instruct_gguf_infer.yaml",
      "display_name": "qwen3 - 30b_a3b_instruct_gguf",
      "model_name": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_30b_a3b_instruct_gguf_macos_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/30b_a3b_instruct_gguf_macos_infer.yaml",
      "relative_path": "recipes/qwen3/inference/30b_a3b_instruct_gguf_macos_infer.yaml",
      "display_name": "qwen3 - 30b_a3b_instruct_gguf_macos",
      "model_name": "unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF",
      "engine": "LLAMACPP",
      "context_length": 8192,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_30b_a3b_instruct_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/30b_a3b_instruct_vllm_infer.yaml",
      "relative_path": "recipes/qwen3/inference/30b_a3b_instruct_vllm_infer.yaml",
      "display_name": "qwen3 - 30b_a3b_instruct_vllm",
      "model_name": "Qwen/Qwen3-30B-A3B-Instruct",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_4b_instruct_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/4b_instruct_infer.yaml",
      "relative_path": "recipes/qwen3/inference/4b_instruct_infer.yaml",
      "display_name": "qwen3 - 4b_instruct",
      "model_name": "Qwen/Qwen3-4B-Instruct-2507",
      "engine": "NATIVE",
      "context_length": 16384,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_4b_instruct_gguf_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/4b_instruct_gguf_infer.yaml",
      "relative_path": "recipes/qwen3/inference/4b_instruct_gguf_infer.yaml",
      "display_name": "qwen3 - 4b_instruct_gguf",
      "model_name": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "engine": "VLLM",
      "context_length": 16384,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_4b_instruct_gguf_macos_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/4b_instruct_gguf_macos_infer.yaml",
      "relative_path": "recipes/qwen3/inference/4b_instruct_gguf_macos_infer.yaml",
      "display_name": "qwen3 - 4b_instruct_gguf_macos",
      "model_name": "unsloth/Qwen3-4B-Instruct-2507-GGUF",
      "engine": "LLAMACPP",
      "context_length": 16384,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_4b_instruct_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/4b_instruct_vllm_infer.yaml",
      "relative_path": "recipes/qwen3/inference/4b_instruct_vllm_infer.yaml",
      "display_name": "qwen3 - 4b_instruct_vllm",
      "model_name": "Qwen/Qwen3-4B-Instruct-2507",
      "engine": "VLLM",
      "context_length": 16384,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_inference_8b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/8b_infer.yaml",
      "relative_path": "recipes/qwen3/inference/8b_infer.yaml",
      "display_name": "qwen3 - 8b",
      "model_name": "Qwen/Qwen3-8B",
      "engine": "NATIVE",
      "context_length": 32768,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_coder_inference_30b_a3b_instruct_gguf_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3_coder/inference/30b_a3b_instruct_gguf_infer.yaml",
      "relative_path": "recipes/qwen3_coder/inference/30b_a3b_instruct_gguf_infer.yaml",
      "display_name": "qwen3_coder - 30b_a3b_instruct_gguf",
      "model_name": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "qwen3_coder",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_coder_inference_30b_a3b_instruct_gguf_macos_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3_coder/inference/30b_a3b_instruct_gguf_macos_infer.yaml",
      "relative_path": "recipes/qwen3_coder/inference/30b_a3b_instruct_gguf_macos_infer.yaml",
      "display_name": "qwen3_coder - 30b_a3b_instruct_gguf_macos",
      "model_name": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "engine": "LLAMACPP",
      "context_length": 8192,
      "model_family": "qwen3_coder",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "recipes_qwen3_coder_inference_30b_a3b_instruct_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3_coder/inference/30b_a3b_instruct_vllm_infer.yaml",
      "relative_path": "recipes/qwen3_coder/inference/30b_a3b_instruct_vllm_infer.yaml",
      "display_name": "qwen3_coder - 30b_a3b_instruct_vllm",
      "model_name": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "qwen3_coder",
      "size_category": "medium",
      "recommended": true
    },
    {
      "id": "apis_anthropic_infer_claude_3_5_sonnet",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/anthropic/infer_claude_3_5_sonnet.yaml",
      "relative_path": "apis/anthropic/infer_claude_3_5_sonnet.yaml",
      "display_name": "ANTHROPIC - infer_claude_3_5_sonnet",
      "model_name": "claude-3-5-sonnet-latest",
      "engine": "ANTHROPIC",
      "context_length": 2048,
      "model_family": "anthropic",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_anthropic_infer_claude_3_7_sonnet",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/anthropic/infer_claude_3_7_sonnet.yaml",
      "relative_path": "apis/anthropic/infer_claude_3_7_sonnet.yaml",
      "display_name": "ANTHROPIC - infer_claude_3_7_sonnet",
      "model_name": "claude-3-7-sonnet-latest",
      "engine": "ANTHROPIC",
      "context_length": 2048,
      "model_family": "anthropic",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_anthropic_infer_claude_opus_4_1",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/anthropic/infer_claude_opus_4_1.yaml",
      "relative_path": "apis/anthropic/infer_claude_opus_4_1.yaml",
      "display_name": "ANTHROPIC - infer_claude_opus_4_1",
      "model_name": "claude-opus-4-1-20250805",
      "engine": "ANTHROPIC",
      "context_length": 2048,
      "model_family": "anthropic",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "projects_coalm_70b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/projects/coalm/70b_infer.yaml",
      "relative_path": "projects/coalm/70b_infer.yaml",
      "display_name": "coalm - 70b",
      "model_name": "uiuc-convai/CoALM-70B",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "coalm",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_deepseek_r1_inference_671b_together_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/deepseek_r1/inference/671b_together_infer.yaml",
      "relative_path": "recipes/deepseek_r1/inference/671b_together_infer.yaml",
      "display_name": "deepseek_r1 - 671b_together",
      "model_name": "deepseek-ai/DeepSeek-R1",
      "engine": "TOGETHER",
      "context_length": 2048,
      "model_family": "deepseek_r1",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "recipes_deepseek_r1_inference_distill_llama_70b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/deepseek_r1/inference/distill_llama_70b_infer.yaml",
      "relative_path": "recipes/deepseek_r1/inference/distill_llama_70b_infer.yaml",
      "display_name": "deepseek_r1 - distill_llama_70b",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "deepseek_r1",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_deepseek_r1_inference_distill_qwen_1_5b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/deepseek_r1/inference/distill_qwen_1_5b_infer.yaml",
      "relative_path": "recipes/deepseek_r1/inference/distill_qwen_1_5b_infer.yaml",
      "display_name": "deepseek_r1 - distill_qwen_1_5b",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "deepseek_r1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_deepseek_r1_inference_distill_qwen_32b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/deepseek_r1/inference/distill_qwen_32b_infer.yaml",
      "relative_path": "recipes/deepseek_r1/inference/distill_qwen_32b_infer.yaml",
      "display_name": "deepseek_r1 - distill_qwen_32b",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "deepseek_r1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_deepseek_r1_inference_distill_qwen_32b_gguf_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/deepseek_r1/inference/distill_qwen_32b_gguf_infer.yaml",
      "relative_path": "recipes/deepseek_r1/inference/distill_qwen_32b_gguf_infer.yaml",
      "display_name": "deepseek_r1 - distill_qwen_32b_gguf",
      "model_name": "unsloth/DeepSeek-R1-Distill-Qwen-32B-GGUF",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "deepseek_r1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_deepseek_r1_inference_distill_qwen_32b_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/deepseek_r1/inference/distill_qwen_32b_vllm_infer.yaml",
      "relative_path": "recipes/deepseek_r1/inference/distill_qwen_32b_vllm_infer.yaml",
      "display_name": "deepseek_r1 - distill_qwen_32b_vllm",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "deepseek_r1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_falcon_h1_inference_0_5b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/falcon_h1/inference/0_5b_infer.yaml",
      "relative_path": "recipes/falcon_h1/inference/0_5b_infer.yaml",
      "display_name": "falcon_h1 - 0_5b",
      "model_name": "tiiuae/Falcon-H1-0.5B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "falcon_h1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_falcon_h1_inference_1_5b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/falcon_h1/inference/1_5b_infer.yaml",
      "relative_path": "recipes/falcon_h1/inference/1_5b_infer.yaml",
      "display_name": "falcon_h1 - 1_5b",
      "model_name": "tiiuae/Falcon-H1-1.5B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "falcon_h1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_falcon_h1_inference_1_5b_deep_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/falcon_h1/inference/1_5b_deep_infer.yaml",
      "relative_path": "recipes/falcon_h1/inference/1_5b_deep_infer.yaml",
      "display_name": "falcon_h1 - 1_5b_deep",
      "model_name": "tiiuae/Falcon-H1-1.5B-Deep-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "falcon_h1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_falcon_h1_inference_34b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/falcon_h1/inference/34b_infer.yaml",
      "relative_path": "recipes/falcon_h1/inference/34b_infer.yaml",
      "display_name": "falcon_h1 - 34b",
      "model_name": "tiiuae/Falcon-H1-34B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "falcon_h1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_falcon_h1_inference_3b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/falcon_h1/inference/3b_infer.yaml",
      "relative_path": "recipes/falcon_h1/inference/3b_infer.yaml",
      "display_name": "falcon_h1 - 3b",
      "model_name": "tiiuae/Falcon-H1-3B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "falcon_h1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_gemini_infer_gemini_1_5_pro",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/gemini/infer_gemini_1_5_pro.yaml",
      "relative_path": "apis/gemini/infer_gemini_1_5_pro.yaml",
      "display_name": "GEMINI - infer_gemini_1_5_pro",
      "model_name": "gemini-1.5-pro",
      "engine": "GOOGLE_GEMINI",
      "context_length": 2048,
      "model_family": "gemini",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_gemini_infer_gemini_2_5_pro",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/gemini/infer_gemini_2_5_pro.yaml",
      "relative_path": "apis/gemini/infer_gemini_2_5_pro.yaml",
      "display_name": "GEMINI - infer_gemini_2_5_pro",
      "model_name": "gemini-2.5-pro",
      "engine": "GOOGLE_GEMINI",
      "context_length": 2048,
      "model_family": "gemini",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_gemma3_inference_3n_e4b_it_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gemma3/inference/3n_e4b_it_infer.yaml",
      "relative_path": "recipes/gemma3/inference/3n_e4b_it_infer.yaml",
      "display_name": "gemma3 - 3n_e4b_it",
      "model_name": "google/gemma-3n-E4B-it",
      "engine": "NATIVE",
      "context_length": 16384,
      "model_family": "gemma3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_gemma3_inference_3n_e4b_it_gguf_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gemma3/inference/3n_e4b_it_gguf_infer.yaml",
      "relative_path": "recipes/gemma3/inference/3n_e4b_it_gguf_infer.yaml",
      "display_name": "gemma3 - 3n_e4b_it_gguf",
      "model_name": "unsloth/gemma-3n-E4B-it-GGUF",
      "engine": "VLLM",
      "context_length": 16384,
      "model_family": "gemma3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_gemma3_inference_3n_e4b_it_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gemma3/inference/3n_e4b_it_vllm_infer.yaml",
      "relative_path": "recipes/gemma3/inference/3n_e4b_it_vllm_infer.yaml",
      "display_name": "gemma3 - 3n_e4b_it_vllm",
      "model_name": "google/gemma-3n-E4B-it",
      "engine": "VLLM",
      "context_length": 16384,
      "model_family": "gemma3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_glm4_inference_air_gguf_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/glm4/inference/air_gguf_infer.yaml",
      "relative_path": "recipes/glm4/inference/air_gguf_infer.yaml",
      "display_name": "glm4 - air_gguf",
      "model_name": "unsloth/GLM-4.5-Air-GGUF",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "glm4",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_glm4_inference_air_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/glm4/inference/air_vllm_infer.yaml",
      "relative_path": "recipes/glm4/inference/air_vllm_infer.yaml",
      "display_name": "glm4 - air_vllm",
      "model_name": "THUDM/glm-4-9b-chat",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "glm4",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_gpt_oss_inference_120b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gpt_oss/inference/120b_infer.yaml",
      "relative_path": "recipes/gpt_oss/inference/120b_infer.yaml",
      "display_name": "gpt_oss - 120b",
      "model_name": "openai/gpt-oss-120b",
      "engine": "NATIVE",
      "context_length": 131072,
      "model_family": "gpt_oss",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_gpt_oss_inference_120b_together_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gpt_oss/inference/120b_together_infer.yaml",
      "relative_path": "recipes/gpt_oss/inference/120b_together_infer.yaml",
      "display_name": "gpt_oss - 120b_together",
      "model_name": "openai/gpt-oss-120b",
      "engine": "TOGETHER",
      "context_length": 2048,
      "model_family": "gpt_oss",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_gpt_oss_inference_120b_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gpt_oss/inference/120b_vllm_infer.yaml",
      "relative_path": "recipes/gpt_oss/inference/120b_vllm_infer.yaml",
      "display_name": "gpt_oss - 120b_vllm",
      "model_name": "openai/gpt-oss-120b",
      "engine": "VLLM",
      "context_length": 2048,
      "model_family": "gpt_oss",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_gpt_oss_inference_20b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gpt_oss/inference/20b_infer.yaml",
      "relative_path": "recipes/gpt_oss/inference/20b_infer.yaml",
      "display_name": "gpt_oss - 20b",
      "model_name": "openai/gpt-oss-20b",
      "engine": "NATIVE",
      "context_length": 131072,
      "model_family": "gpt_oss",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_gpt_oss_inference_20b_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gpt_oss/inference/20b_vllm_infer.yaml",
      "relative_path": "recipes/gpt_oss/inference/20b_vllm_infer.yaml",
      "display_name": "gpt_oss - 20b_vllm",
      "model_name": "openai/gpt-oss-20b",
      "engine": "VLLM",
      "context_length": 2048,
      "model_family": "gpt_oss",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_gpt2_inference_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/gpt2/inference/infer.yaml",
      "relative_path": "recipes/gpt2/inference/infer.yaml",
      "display_name": "gpt2 - infer",
      "model_name": "openai-community/gpt2",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "gpt2",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_llama3_1_inference_70b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_1/inference/70b_infer.yaml",
      "relative_path": "recipes/llama3_1/inference/70b_infer.yaml",
      "display_name": "llama3_1 - 70b",
      "model_name": "meta-llama/Llama-3.1-70B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "llama3_1",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_llama3_1_inference_8b_rvllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_1/inference/8b_rvllm_infer.yaml",
      "relative_path": "recipes/llama3_1/inference/8b_rvllm_infer.yaml",
      "display_name": "llama3_1 - 8b_rvllm",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "engine": "REMOTE_VLLM",
      "context_length": 2048,
      "model_family": "llama3_1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_llama3_1_inference_8b_sglang_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_1/inference/8b_sglang_infer.yaml",
      "relative_path": "recipes/llama3_1/inference/8b_sglang_infer.yaml",
      "display_name": "llama3_1 - 8b_sglang",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "engine": "SGLANG",
      "context_length": 2048,
      "model_family": "llama3_1",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_llama3_2_inference_1b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_2/inference/1b_infer.yaml",
      "relative_path": "recipes/llama3_2/inference/1b_infer.yaml",
      "display_name": "llama3_2 - 1b",
      "model_name": "meta-llama/Llama-3.2-1B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "llama3_2",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "recipes_llama3_2_inference_1b_sglang_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_2/inference/1b_sglang_infer.yaml",
      "relative_path": "recipes/llama3_2/inference/1b_sglang_infer.yaml",
      "display_name": "llama3_2 - 1b_sglang",
      "model_name": "meta-llama/Llama-3.2-1B-Instruct",
      "engine": "SGLANG",
      "context_length": 2048,
      "model_family": "llama3_2",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "recipes_llama3_2_inference_1b_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_2/inference/1b_vllm_infer.yaml",
      "relative_path": "recipes/llama3_2/inference/1b_vllm_infer.yaml",
      "display_name": "llama3_2 - 1b_vllm",
      "model_name": "meta-llama/Llama-3.2-1B-Instruct",
      "engine": "VLLM",
      "context_length": 2048,
      "model_family": "llama3_2",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "recipes_llama3_2_inference_3b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_2/inference/3b_infer.yaml",
      "relative_path": "recipes/llama3_2/inference/3b_infer.yaml",
      "display_name": "llama3_2 - 3b",
      "model_name": "meta-llama/Llama-3.2-3B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "llama3_2",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_llama3_2_inference_3b_sglang_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_2/inference/3b_sglang_infer.yaml",
      "relative_path": "recipes/llama3_2/inference/3b_sglang_infer.yaml",
      "display_name": "llama3_2 - 3b_sglang",
      "model_name": "meta-llama/Llama-3.2-3B-Instruct",
      "engine": "SGLANG",
      "context_length": 2048,
      "model_family": "llama3_2",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_llama3_2_inference_3b_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_2/inference/3b_vllm_infer.yaml",
      "relative_path": "recipes/llama3_2/inference/3b_vllm_infer.yaml",
      "display_name": "llama3_2 - 3b_vllm",
      "model_name": "meta-llama/Llama-3.2-3B-Instruct",
      "engine": "VLLM",
      "context_length": 2048,
      "model_family": "llama3_2",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_llama3_3_inference_70b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_3/inference/70b_infer.yaml",
      "relative_path": "recipes/llama3_3/inference/70b_infer.yaml",
      "display_name": "llama3_3 - 70b",
      "model_name": "meta-llama/Llama-3.3-70B-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "llama3_3",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_llama3_3_inference_70b_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_3/inference/70b_vllm_infer.yaml",
      "relative_path": "recipes/llama3_3/inference/70b_vllm_infer.yaml",
      "display_name": "llama3_3 - 70b_vllm",
      "model_name": "meta-llama/Llama-3.3-70B-Instruct",
      "engine": "VLLM",
      "context_length": 2048,
      "model_family": "llama3_3",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_llama3_3_inference_nemotron_super_49b_gguf_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_3/inference/nemotron_super_49b_gguf_infer.yaml",
      "relative_path": "recipes/llama3_3/inference/nemotron_super_49b_gguf_infer.yaml",
      "display_name": "llama3_3 - nemotron_super_49b_gguf",
      "model_name": "bartowski/nvidia_Llama-3_3-Nemotron-Super-49B-v1-GGUF",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "llama3_3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_llama3_3_inference_nemotron_super_49b_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/llama3_3/inference/nemotron_super_49b_vllm_infer.yaml",
      "relative_path": "recipes/llama3_3/inference/nemotron_super_49b_vllm_infer.yaml",
      "display_name": "llama3_3 - nemotron_super_49b_vllm",
      "model_name": "nvidia/Llama-3.3-Nemotron-Super-49B-v1",
      "engine": "VLLM",
      "context_length": 8192,
      "model_family": "llama3_3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_chatgpt_4o_latest",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_chatgpt_4o_latest.yaml",
      "relative_path": "apis/openai/infer_chatgpt_4o_latest.yaml",
      "display_name": "OPENAI - infer_chatgpt_4o_latest",
      "model_name": "chatgpt-4o-latest",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_4_1",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_4_1.yaml",
      "relative_path": "apis/openai/infer_gpt_4_1.yaml",
      "display_name": "OPENAI - infer_gpt_4_1",
      "model_name": "gpt-4.1",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_4_1_mini",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_4_1_mini.yaml",
      "relative_path": "apis/openai/infer_gpt_4_1_mini.yaml",
      "display_name": "OPENAI - infer_gpt_4_1_mini",
      "model_name": "gpt-4.1-mini",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_4o",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_4o.yaml",
      "relative_path": "apis/openai/infer_gpt_4o.yaml",
      "display_name": "OPENAI - infer_gpt_4o",
      "model_name": "gpt-4o",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_4o_mini",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_4o_mini.yaml",
      "relative_path": "apis/openai/infer_gpt_4o_mini.yaml",
      "display_name": "OPENAI - infer_gpt_4o_mini",
      "model_name": "gpt-4o-mini",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_5",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_5.yaml",
      "relative_path": "apis/openai/infer_gpt_5.yaml",
      "display_name": "OPENAI - infer_gpt_5",
      "model_name": "gpt-5",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_5_chat_latest",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_5_chat_latest.yaml",
      "relative_path": "apis/openai/infer_gpt_5_chat_latest.yaml",
      "display_name": "OPENAI - infer_gpt_5_chat_latest",
      "model_name": "gpt-5-chat-latest",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_5_mini",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_5_mini.yaml",
      "relative_path": "apis/openai/infer_gpt_5_mini.yaml",
      "display_name": "OPENAI - infer_gpt_5_mini",
      "model_name": "gpt-5-mini",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_5_nano",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_5_nano.yaml",
      "relative_path": "apis/openai/infer_gpt_5_nano.yaml",
      "display_name": "OPENAI - infer_gpt_5_nano",
      "model_name": "gpt-5-nano",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_gpt_o1_preview",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_gpt_o1_preview.yaml",
      "relative_path": "apis/openai/infer_gpt_o1_preview.yaml",
      "display_name": "OPENAI - infer_gpt_o1_preview",
      "model_name": "o1-preview",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_o1",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_o1.yaml",
      "relative_path": "apis/openai/infer_o1.yaml",
      "display_name": "OPENAI - infer_o1",
      "model_name": "o1",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_o1_mini",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_o1_mini.yaml",
      "relative_path": "apis/openai/infer_o1_mini.yaml",
      "display_name": "OPENAI - infer_o1_mini",
      "model_name": "o1-mini",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_openai_infer_o3_mini",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/openai/infer_o3_mini.yaml",
      "relative_path": "apis/openai/infer_o3_mini.yaml",
      "display_name": "OPENAI - infer_o3_mini",
      "model_name": "o3-mini",
      "engine": "OPENAI",
      "context_length": 2048,
      "model_family": "openai",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_phi4_inference_reasoning_plus_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/phi4/inference/reasoning_plus_infer.yaml",
      "relative_path": "recipes/phi4/inference/reasoning_plus_infer.yaml",
      "display_name": "phi4 - reasoning_plus",
      "model_name": "microsoft/Phi-4-reasoning-plus",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "phi4",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_qwen3_inference_0.6b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/0.6b_infer.yaml",
      "relative_path": "recipes/qwen3/inference/0.6b_infer.yaml",
      "display_name": "qwen3 - 0.6b",
      "model_name": "Qwen/Qwen3-0.6B",
      "engine": "NATIVE",
      "context_length": 32768,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_qwen3_inference_14b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/14b_infer.yaml",
      "relative_path": "recipes/qwen3/inference/14b_infer.yaml",
      "display_name": "qwen3 - 14b",
      "model_name": "Qwen/Qwen3-14B",
      "engine": "NATIVE",
      "context_length": 32768,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_qwen3_inference_235b_a22b_together_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/235b_a22b_together_infer.yaml",
      "relative_path": "recipes/qwen3/inference/235b_a22b_together_infer.yaml",
      "display_name": "qwen3 - 235b_a22b_together",
      "model_name": "Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
      "engine": "TOGETHER",
      "context_length": 2048,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_qwen3_inference_30b_a3b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/30b_a3b_infer.yaml",
      "relative_path": "recipes/qwen3/inference/30b_a3b_infer.yaml",
      "display_name": "qwen3 - 30b_a3b",
      "model_name": "Qwen/Qwen3-30B-A3B",
      "engine": "NATIVE",
      "context_length": 32768,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_qwen3_inference_32b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/32b_infer.yaml",
      "relative_path": "recipes/qwen3/inference/32b_infer.yaml",
      "display_name": "qwen3 - 32b",
      "model_name": "Qwen/Qwen3-32B",
      "engine": "NATIVE",
      "context_length": 32768,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_qwen3_inference_4b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwen3/inference/4b_infer.yaml",
      "relative_path": "recipes/qwen3/inference/4b_infer.yaml",
      "display_name": "qwen3 - 4b",
      "model_name": "Qwen/Qwen3-4B",
      "engine": "NATIVE",
      "context_length": 32768,
      "model_family": "qwen3",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_qwq_inference_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/qwq/inference/infer.yaml",
      "relative_path": "recipes/qwq/inference/infer.yaml",
      "display_name": "qwq - infer",
      "model_name": "Qwen/QwQ-32B",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "qwq",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_smollm_inference_135m_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/smollm/inference/135m_infer.yaml",
      "relative_path": "recipes/smollm/inference/135m_infer.yaml",
      "display_name": "smollm - 135m",
      "model_name": "HuggingFaceTB/SmolLM2-135M-Instruct",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "smollm",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "examples_bulk_inference_gcp_job",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/examples/bulk_inference/gcp_job.yaml",
      "relative_path": "examples/bulk_inference/gcp_job.yaml",
      "display_name": "unknown - gcp_job",
      "model_name": "Unknown Model",
      "engine": "NATIVE",
      "context_length": 2048,
      "model_family": "unknown",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "apis_vertex_infer_llama_3_1_405b",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/vertex/infer_llama_3_1_405b.yaml",
      "relative_path": "apis/vertex/infer_llama_3_1_405b.yaml",
      "display_name": "VERTEX - infer_llama_3_1_405b",
      "model_name": "meta/llama-3.1-405b-instruct-maas",
      "engine": "GOOGLE_VERTEX",
      "context_length": 2048,
      "model_family": "vertex",
      "size_category": "xl",
      "recommended": false
    },
    {
      "id": "apis_vertex_infer_llama_3_3_70b",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/apis/vertex/infer_llama_3_3_70b.yaml",
      "relative_path": "apis/vertex/infer_llama_3_3_70b.yaml",
      "display_name": "VERTEX - infer_llama_3_3_70b",
      "model_name": "meta/llama-3.3-70b-instruct-maas",
      "engine": "GOOGLE_VERTEX",
      "context_length": 2048,
      "model_family": "vertex",
      "size_category": "large",
      "recommended": false
    },
    {
      "id": "recipes_vision_llama3_2_vision_inference_11b_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/llama3_2_vision/inference/11b_infer.yaml",
      "relative_path": "recipes/vision/llama3_2_vision/inference/11b_infer.yaml",
      "display_name": "vision - 11b",
      "model_name": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "engine": "NATIVE",
      "context_length": 1024,
      "model_family": "vision",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "recipes_vision_llama3_2_vision_inference_11b_rvllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/llama3_2_vision/inference/11b_rvllm_infer.yaml",
      "relative_path": "recipes/vision/llama3_2_vision/inference/11b_rvllm_infer.yaml",
      "display_name": "vision - 11b_rvllm",
      "model_name": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "engine": "REMOTE_VLLM",
      "context_length": 1024,
      "model_family": "vision",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "recipes_vision_llama3_2_vision_inference_11b_sglang_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/llama3_2_vision/inference/11b_sglang_infer.yaml",
      "relative_path": "recipes/vision/llama3_2_vision/inference/11b_sglang_infer.yaml",
      "display_name": "vision - 11b_sglang",
      "model_name": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "engine": "SGLANG",
      "context_length": 1024,
      "model_family": "vision",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "recipes_vision_llama3_2_vision_inference_11b_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/llama3_2_vision/inference/11b_vllm_infer.yaml",
      "relative_path": "recipes/vision/llama3_2_vision/inference/11b_vllm_infer.yaml",
      "display_name": "vision - 11b_vllm",
      "model_name": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "engine": "VLLM",
      "context_length": 1024,
      "model_family": "vision",
      "size_category": "small",
      "recommended": false
    },
    {
      "id": "recipes_vision_llava_7b_inference_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/llava_7b/inference/infer.yaml",
      "relative_path": "recipes/vision/llava_7b/inference/infer.yaml",
      "display_name": "vision - infer",
      "model_name": "llava-hf/llava-1.5-7b-hf",
      "engine": "NATIVE",
      "context_length": 1024,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_phi4_inference_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/phi4/inference/infer.yaml",
      "relative_path": "recipes/vision/phi4/inference/infer.yaml",
      "display_name": "vision - infer",
      "model_name": "microsoft/Phi-4-multimodal-instruct",
      "engine": "NATIVE",
      "context_length": 4096,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_qwen2_5_vl_3b_inference_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/qwen2_5_vl_3b/inference/infer.yaml",
      "relative_path": "recipes/vision/qwen2_5_vl_3b/inference/infer.yaml",
      "display_name": "vision - infer",
      "model_name": "Qwen/Qwen2.5-VL-3B-Instruct",
      "engine": "NATIVE",
      "context_length": 4096,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_qwen2_vl_2b_inference_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/qwen2_vl_2b/inference/infer.yaml",
      "relative_path": "recipes/vision/qwen2_vl_2b/inference/infer.yaml",
      "display_name": "vision - infer",
      "model_name": "Qwen/Qwen2-VL-2B-Instruct",
      "engine": "NATIVE",
      "context_length": 4096,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_smolvlm_inference_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/smolvlm/inference/infer.yaml",
      "relative_path": "recipes/vision/smolvlm/inference/infer.yaml",
      "display_name": "vision - infer",
      "model_name": "HuggingFaceTB/SmolVLM-Instruct",
      "engine": "NATIVE",
      "context_length": 3072,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_qwen2_vl_2b_inference_sglang_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/qwen2_vl_2b/inference/sglang_infer.yaml",
      "relative_path": "recipes/vision/qwen2_vl_2b/inference/sglang_infer.yaml",
      "display_name": "vision - sglang",
      "model_name": "Qwen/Qwen2-VL-2B-Instruct",
      "engine": "SGLANG",
      "context_length": 4096,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_llava_7b_inference_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/llava_7b/inference/vllm_infer.yaml",
      "relative_path": "recipes/vision/llava_7b/inference/vllm_infer.yaml",
      "display_name": "vision - vllm",
      "model_name": "llava-hf/llava-1.5-7b-hf",
      "engine": "VLLM",
      "context_length": 1024,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_phi3_inference_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/phi3/inference/vllm_infer.yaml",
      "relative_path": "recipes/vision/phi3/inference/vllm_infer.yaml",
      "display_name": "vision - vllm",
      "model_name": "microsoft/Phi-3-vision-128k-instruct",
      "engine": "VLLM",
      "context_length": 4096,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_phi4_inference_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/phi4/inference/vllm_infer.yaml",
      "relative_path": "recipes/vision/phi4/inference/vllm_infer.yaml",
      "display_name": "vision - vllm",
      "model_name": "microsoft/Phi-4-multimodal-instruct",
      "engine": "VLLM",
      "context_length": 4096,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_qwen2_5_vl_3b_inference_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/qwen2_5_vl_3b/inference/vllm_infer.yaml",
      "relative_path": "recipes/vision/qwen2_5_vl_3b/inference/vllm_infer.yaml",
      "display_name": "vision - vllm",
      "model_name": "Qwen/Qwen2.5-VL-3B-Instruct",
      "engine": "VLLM",
      "context_length": 4096,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_qwen2_vl_2b_inference_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/qwen2_vl_2b/inference/vllm_infer.yaml",
      "relative_path": "recipes/vision/qwen2_vl_2b/inference/vllm_infer.yaml",
      "display_name": "vision - vllm",
      "model_name": "Qwen/Qwen2-VL-2B-Instruct",
      "engine": "VLLM",
      "context_length": 4096,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    },
    {
      "id": "recipes_vision_smolvlm_inference_vllm_infer",
      "config_path": "/Users/benjaminfeuer/Library/CloudStorage/GoogleDrive-penfever@gmail.com/My Drive/Current Projects/oumi/oumi/configs/recipes/vision/smolvlm/inference/vllm_infer.yaml",
      "relative_path": "recipes/vision/smolvlm/inference/vllm_infer.yaml",
      "display_name": "vision - vllm",
      "model_name": "HuggingFaceTB/SmolVLM-Instruct",
      "engine": "VLLM",
      "context_length": 3072,
      "model_family": "vision",
      "size_category": "medium",
      "recommended": false
    }
  ]
}