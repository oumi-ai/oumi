# Class: oumi.core.configs.JobConfig
# https://github.com/oumi-ai/oumi/blob/main/src/oumi/core/configs/job_config.py

# Sample command:
# oumi launch up --config tests/scripts/e2e_tests_job.yaml --cluster oumi-e2e-tests-cluster
name: oumi-e2e-tests

resources:
  cloud: gcp
  accelerators: "A100:4" # "A100:1", "A100-80GB:1", "A100-80GB:4"
  use_spot: false
  disk_size: 1000 # Disk size in GBs

num_nodes: 1 # Set it to N for multi-node training.

working_dir: .

file_mounts:
  ~/.netrc: ~/.netrc # WandB credentials
  ~/.cache/huggingface/token: ~/.cache/huggingface/token # HF credentials

envs:
  WANDB_PROJECT: oumi-e2e-tests
  ACCELERATE_LOG_LEVEL: info
  TOKENIZERS_PARALLELISM: false
  # https://pytorch.org/docs/stable/notes/cuda.html#optimizing-memory-usage-with-pytorch-cuda-alloc-conf
  PYTORCH_CUDA_ALLOC_CONF: "garbage_collection_threshold:0.8,max_split_size_mb:128"
  ENABLE_OUMI_UNIT_TESTS: "false"
  ENABLE_OUMI_INTEGRATION_TESTS: "false"
  ENABLE_OUMI_E2E_TESTS: "true"
  CUDA_LAUNCH_BLOCKING: 1
  IAP_CLIENT_ID: ${env:IAP_CLIENT_ID}
  BACKEND_URL: ${env:BACKEND_URL}
  TARGET_SERVICE_ACCOUNT: ${env:TARGET_SERVICE_ACCOUNT}
  RP_API_KEY: ${env:RP_API_KEY}
  TEST_LAUNCH_NAME: ${env:TEST_LAUNCH_NAME}

run: |
  set -xe  # Exit if any command failed.
  source "./configs/examples/misc/sky_init.sh"

  pip install git+https://github.com/oumi-ai/test-proxy.git
  pip install pytest-reportportal

  pip install -e ".[ci_gpu]" hf_transfer
  pip install -U flash-attn --no-build-isolation

  echo "Node ${SKYPILOT_NODE_RANK} starting..."
  echo "Unit tests: ${ENABLE_OUMI_UNIT_TESTS}"
  echo "Integration tests: ${ENABLE_OUMI_INTEGRATION_TESTS}"
  echo "e2e tests: ${ENABLE_OUMI_E2E_TESTS}"

  nvidia-smi

  echo "$(oumi env)"

  GPU_MULTIPLICITY_MARKER="single_gpu"
  if test ${OUMI_TOTAL_NUM_GPUS} -gt 1; then
    GPU_MULTIPLICITY_MARKER="multi_gpu"
  fi

  ROOT_DIR="$(pwd)"

  python -m test-proxy.main &
  sleep 2

  if "${ENABLE_OUMI_UNIT_TESTS}"; then
    cd "${ROOT_DIR}/tests/unit/"
    echo "Running all unit tests..."
    pytest -s -vv --durations=50 --timeout=300 -o rp_endpoint=http://localhost:8080 -o rp_project=oumi -o rp_launch_attributes="test_type:unit" -o rp_launch="${TEST_LAUNCH_NAME}_unit" --reportportal
  fi

  if "${ENABLE_OUMI_INTEGRATION_TESTS}"; then
    cd "${ROOT_DIR}/tests/integration/"
    echo "Running all integration tests..."
    pytest -s -vv --durations=50 --timeout=300 -o rp_endpoint=http://localhost:8080 -o rp_project=oumi -o rp_launch_attributes="test_type:integration" -o rp_launch="${TEST_LAUNCH_NAME}_integration" --reportportal
  fi

  if "${ENABLE_OUMI_E2E_TESTS}"; then
    cd "${ROOT_DIR}/tests/"
    echo "Running all tests: e2e and ${GPU_MULTIPLICITY_MARKER}..."
    pytest -s -vv -m "e2e and ${GPU_MULTIPLICITY_MARKER}" --durations=50 --timeout=1200 -o rp_endpoint=http://localhost:8080 -o rp_project=oumi -o rp_launch_attributes="test_type:e2e" -o rp_launch="${TEST_LAUNCH_NAME}_e2e" --reportportal
  fi

  echo "Node ${SKYPILOT_NODE_RANK} is all done!"
